[
  {
    "objectID": "posts/image/2021-02-09-09. CNNwithTextDataset.html",
    "href": "posts/image/2021-02-09-09. CNNwithTextDataset.html",
    "title": "08. CNN with Text",
    "section": "",
    "text": "import pandas as pd\nimport tensorflow as tf\n\n# 데이터를 준비합니다.\npath = \"https://raw.githubusercontent.com/blackdew/ml-tensorflow/master/data/csv/boston.csv\"\ndf = pd.read_csv(path)\n\nx_train = df[['crim', 'zn', 'indus', 'chas', 'nox', 'rm', 'age', 'dis',\n              'rad', 'tax','ptratio', 'b', 'lstat']]\ny_train = df[['medv']]\nprint(x_train.shape, y_train.shape)\n\n# 모델을 준비합니다.\nX = tf.keras.Input(shape=[13])\nH = tf.keras.layers.Dense(5, activation=\"relu\")(X)\nY = tf.keras.layers.Dense(1)(H)\nmodel = tf.keras.Model(X, Y)\nmodel.compile(loss='mse')\n\n# 모델을 학습합니다.\nmodel.fit(x_train, y_train, epochs=10)\n\n(506, 13) (506, 1)\nEpoch 1/10\n16/16 [==============================] - 1s 5ms/step - loss: 7995.8369\nEpoch 2/10\n16/16 [==============================] - 0s 4ms/step - loss: 3660.6780\nEpoch 3/10\n16/16 [==============================] - 0s 4ms/step - loss: 2083.4761\nEpoch 4/10\n16/16 [==============================] - 0s 4ms/step - loss: 1223.1989\nEpoch 5/10\n16/16 [==============================] - 0s 5ms/step - loss: 682.9676\nEpoch 6/10\n16/16 [==============================] - 0s 5ms/step - loss: 386.6265\nEpoch 7/10\n16/16 [==============================] - 0s 4ms/step - loss: 257.0114\nEpoch 8/10\n16/16 [==============================] - 0s 5ms/step - loss: 221.1516\nEpoch 9/10\n16/16 [==============================] - 0s 4ms/step - loss: 204.3957\nEpoch 10/10\n16/16 [==============================] - 0s 5ms/step - loss: 191.5367\n\n\n&lt;keras.src.callbacks.History at 0x1600e9cc590&gt;\n\n\n\nimport tensorflow as tf\n\n# 데이터를 준비합니다.\n(x_train, y_train), _ = tf.keras.datasets.mnist.load_data()\nx_train = x_train.reshape(60000, 28, 28, 1)\ny_train = tf.keras.utils.to_categorical(y_train)\nprint(x_train.shape, y_train.shape)\n\n# 모델을 만듭니다.\nX = tf.keras.Input(shape=[28, 28, 1])\n\nH = tf.keras.layers.Conv2D(32, 3, padding=\"same\")(X)\nH = tf.keras.layers.Activation('relu')(H)\nH = tf.keras.layers.MaxPool2D()(H)\n\nH = tf.keras.layers.Flatten()(H)\nH = tf.keras.layers.Dense(120, activation=\"relu\")(H)\nH = tf.keras.layers.Dense(84, activation=\"relu\")(H)\nY = tf.keras.layers.Dense(10, activation=\"softmax\")(H)\n\nmodel = tf.keras.Model(X, Y)\nmodel.compile(loss=\"categorical_crossentropy\",\n              metrics=\"accuracy\")\n\n# 모델을 학습합니다.\nmodel.fit(x_train, y_train, epochs=10)"
  },
  {
    "objectID": "posts/image/2021-02-09-09. CNNwithTextDataset.html#with-simplernn",
    "href": "posts/image/2021-02-09-09. CNNwithTextDataset.html#with-simplernn",
    "title": "08. CNN with Text",
    "section": "with SimpleRNN",
    "text": "with SimpleRNN\n\n# 모델 생성\nX = tf.keras.layers.Input(shape=[28, 28])\nH = tf.keras.layers.SimpleRNN(32)(X)\nY = tf.keras.layers.Dense(10, activation=\"softmax\")(H)\n\nmodel = tf.keras.Model(X, Y)\nmodel.compile(loss=\"sparse_categorical_crossentropy\",\n              metrics=\"accuracy\")\nmodel.summary()\n\n\n# 학습\nmodel.fit(x_train, y_train, epochs=10,\n          batch_size=128, validation_split=0.2)\n\n# 평가\nmodel.evaluate(x_test, y_test)"
  },
  {
    "objectID": "posts/image/2021-02-09-09. CNNwithTextDataset.html#with-lstm",
    "href": "posts/image/2021-02-09-09. CNNwithTextDataset.html#with-lstm",
    "title": "08. CNN with Text",
    "section": "with LSTM",
    "text": "with LSTM\n\n# 모델 생성\nX = tf.keras.layers.Input(shape=[28, 28])\nH = tf.keras.layers.LSTM(32)(X)\nY = tf.keras.layers.Dense(10, activation=\"softmax\")(H)\n\nmodel = tf.keras.Model(X, Y)\nmodel.compile(loss=\"sparse_categorical_crossentropy\",\n              metrics=\"accuracy\")\nmodel.summary()\n\n\n# 학습\nmodel.fit(x_train, y_train, epochs=10,\n          batch_size=128, validation_split=0.2)\n\n# 평가\nmodel.evaluate(x_test, y_test)"
  },
  {
    "objectID": "posts/image/2021-02-09-09. CNNwithTextDataset.html#리뷰-글-출력",
    "href": "posts/image/2021-02-09-09. CNNwithTextDataset.html#리뷰-글-출력",
    "title": "08. CNN with Text",
    "section": "리뷰 글 출력",
    "text": "리뷰 글 출력\n\nword2index = tf.keras.datasets.imdb.get_word_index()\nindex2word = dict((i, w) for w, i in word2index.items())\nprint(sorted(list(index2word.items()))[:10])\n\n\ndecoded = \" \".join(index2word[i] for i in x_train[1])\nprint(x_train[1][:10])\nprint(decoded[:50])"
  },
  {
    "objectID": "posts/image/2021-02-09-09. CNNwithTextDataset.html#with-simplernn-embedding",
    "href": "posts/image/2021-02-09-09. CNNwithTextDataset.html#with-simplernn-embedding",
    "title": "08. CNN with Text",
    "section": "with SimpleRNN + Embedding",
    "text": "with SimpleRNN + Embedding\n\nimport tensorflow as tf\n\nX = tf.keras.Input(shape=[20])\nH = tf.keras.layers.Embedding(88585, 28)(X)\nH = tf.keras.layers.SimpleRNN(32)(H)\nY = tf.keras.layers.Dense(1, activation=\"sigmoid\")(H)\n\nmodel = tf.keras.Model(X, Y)\nmodel.compile(loss=\"binary_crossentropy\", metrics=\"accuracy\")\n\nmodel.summary()\n\n\nmodel.fit(x_train, y_train, epochs=10, batch_size=128, validation_split=0.2)"
  },
  {
    "objectID": "posts/image/2021-02-09-09. CNNwithTextDataset.html#with-hidden-sequences",
    "href": "posts/image/2021-02-09-09. CNNwithTextDataset.html#with-hidden-sequences",
    "title": "08. CNN with Text",
    "section": "with Hidden Sequences",
    "text": "with Hidden Sequences\n\nimport tensorflow as tf\n\nX = tf.keras.Input(shape=[20])\n\nH = tf.keras.layers.Embedding(88585, 28)(X)\nH = tf.keras.layers.SimpleRNN(32, return_sequences=True)(H)\nH = tf.keras.layers.GlobalAveragePooling1D()(H)\nY = tf.keras.layers.Dense(1, activation=\"sigmoid\")(H)\n\nmodel = tf.keras.Model(X, Y)\nmodel.compile(loss=\"binary_crossentropy\", metrics=\"accuracy\")\n\nmodel.summary()\n\n\nmodel.fit(x_train, y_train, epochs=10, batch_size=128, validation_split=0.2)"
  },
  {
    "objectID": "posts/image/2021-02-09-09. CNNwithTextDataset.html#with-transformer",
    "href": "posts/image/2021-02-09-09. CNNwithTextDataset.html#with-transformer",
    "title": "08. CNN with Text",
    "section": "with Transformer",
    "text": "with Transformer\n\nimport tensorflow as tf\n\nX = tf.keras.Input(shape=[20])\n\nH = tf.keras.layers.Embedding(88585, 28)(X)\nH = tf.keras.layers.SimpleRNN(32, return_sequences=True)(H)\n\n# Transformer::self-attentions\nH1 = tf.keras.layers.MultiHeadAttention(2, 16)(H, H)\nH = tf.keras.layers.BatchNormalization()(H + H1)\n\n# Transformer::feed-forward\nH1 = tf.keras.layers.Dense(32, activation='swish')(H)\nH = tf.keras.layers.BatchNormalization()(H + H1)\n\nH = tf.keras.layers.GlobalAveragePooling1D()(H)\nY = tf.keras.layers.Dense(1, activation=\"sigmoid\")(H)\n\nmodel = tf.keras.Model(X, Y)\nmodel.compile(loss=\"binary_crossentropy\", metrics=\"accuracy\")\n\nmodel.summary()\n\n\nmodel.fit(x_train, y_train, epochs=10, batch_size=128, validation_split=0.2)"
  },
  {
    "objectID": "posts/image/2021-02-09-09. CNNwithTextDataset.html#한글-세팅",
    "href": "posts/image/2021-02-09-09. CNNwithTextDataset.html#한글-세팅",
    "title": "08. CNN with Text",
    "section": "한글 세팅",
    "text": "한글 세팅\n\n!pip install konlpy\n!sudo apt-get install -y fonts-nanum\n!sudo fc-cache -fv\n!rm ~/.cache/matplotlib -rf\n\n\n!ls /usr/share/fonts/truetype/nanum\n\n\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\n# import matplotlib.font_manager as fm\n\n# Colab 의 한글 폰트 설정\nplt.rc('font', family='NanumBarunGothic')\n\n# 유니코드에서  음수 부호설정\nmpl.rc('axes', unicode_minus=False)"
  },
  {
    "objectID": "posts/image/2021-02-09-09. CNNwithTextDataset.html#토큰화",
    "href": "posts/image/2021-02-09-09. CNNwithTextDataset.html#토큰화",
    "title": "08. CNN with Text",
    "section": "토큰화",
    "text": "토큰화\n\nimport nltk\n\n# 말뭉치 다운로드\nnltk.download('punkt')\n\n# 텍스트 토큰화 (Tokenization)\ntokens1 = nltk.tokenize.word_tokenize(text1)\nprint(tokens1)\n\n['Natural', 'language', 'processing', '(', 'NLP', ')', 'is', 'a', 'field', 'of', 'computer', 'science', ',', 'artificial', 'intelligence', ',', 'and', 'computational', 'linguistics', 'concerned', 'with', 'the', 'interactions', 'between', 'computers', 'and', 'human', '(', 'natural', ')', 'languages', '.']\n\n\n[nltk_data] Downloading package punkt to /root/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n\n\n\nfrom konlpy.tag import Okt\n\n# KoNLPy에서 Okt 형태소 분석기를 사용\nokt = Okt()\n\n# 텍스트 토큰화 (Tokenization)\ntokens2 = okt.morphs(text2)\nprint(tokens2)\n\n['자연어', '처리', '(', 'Natural', 'Language', 'Processing', ',', 'NLP', ')', '는', '\\n', '인간', '의', '언어', '현상', '을', '컴퓨터', '와', '같은', '기계', '를', '이용', '하여', '\\n', '모사', '할', '수', '있도록', '하는', '인공', '지능', '의', '하위', '분야', '중', '하나', '입니다', '.']"
  },
  {
    "objectID": "posts/image/2021-02-09-09. CNNwithTextDataset.html#정제-정규화",
    "href": "posts/image/2021-02-09-09. CNNwithTextDataset.html#정제-정규화",
    "title": "08. CNN with Text",
    "section": "정제 & 정규화",
    "text": "정제 & 정규화\n\n# 정제 (Cleaning) 및 정규화 (Normalization)\n\ncleaned_tokens1 = [token.lower() for token in tokens1 if token.isalnum()]\nprint(cleaned_tokens1)\n\ncleaned_tokens2 = [token for token in tokens2 if token.isalnum()]\nprint(cleaned_tokens2)\n\n\n# 어간 추출 (Stemming)\nstemmer1 = nltk.stem.PorterStemmer()\nstemmed_tokens1 = [stemmer1.stem(token) for token in cleaned_tokens1]\nprint(stemmed_tokens1)\n\n# 표제어 추출 (Lemmatization)\nnltk.download('wordnet')\nlemmatizer1 = nltk.stem.WordNetLemmatizer()\nlemmatized_tokens1 = [lemmatizer1.lemmatize(token) for token in cleaned_tokens1]\nprint(lemmatizer1)"
  },
  {
    "objectID": "posts/image/2021-02-09-09. CNNwithTextDataset.html#불용어-제거",
    "href": "posts/image/2021-02-09-09. CNNwithTextDataset.html#불용어-제거",
    "title": "08. CNN with Text",
    "section": "불용어 제거",
    "text": "불용어 제거\n\n# 불용어 (Stopword) 제거\n\nnltk.download('stopwords')\nstop_words1 = set(nltk.corpus.stopwords.words('english'))\nfiltered_tokens1 = [token for token in lemmatized_tokens1 if token not in stop_words1]\nprint(filtered_tokens1)\n\nstop_words2 = set([\"은\", \"는\", \"이\", \"가\", \"을\", \"를\"])\nfiltered_tokens2 = [token for token in cleaned_tokens2 if token not in stop_words2]\nprint(filtered_tokens2)"
  },
  {
    "objectID": "posts/image/2021-02-09-09. CNNwithTextDataset.html#wordcloud",
    "href": "posts/image/2021-02-09-09. CNNwithTextDataset.html#wordcloud",
    "title": "08. CNN with Text",
    "section": "WordCloud",
    "text": "WordCloud\n\nfrom wordcloud import WordCloud\n\n# 워드클라우드 생성\nwordcloud1 = WordCloud(width=800, height=400, background_color='white')\n# 폰트 변경\nwordcloud1.font_path = '/usr/share/fonts/truetype/nanum/NanumBarunGothic.ttf'\n\nwordcloud1.generate(' '.join(filtered_tokens1))\nwordcloud1.to_file(\"wordcloud1.png\")\n\n# 워드클라우드 출력\nplt.axis('off')\nplt.imshow(wordcloud1)\nplt.show()\n\n\n# 워드클라우드 생성\nwordcloud2 = WordCloud(width=800, height=400, background_color='white')\n# 폰트 변경\nwordcloud2.font_path = '/usr/share/fonts/truetype/nanum/NanumBarunGothic.ttf'\n\nwordcloud2.generate(' '.join(filtered_tokens2))\nwordcloud2.to_file(\"wordcloud1.png\")\n\n# 워드클라우드 출력\nplt.axis('off')\nplt.imshow(wordcloud2)\nplt.show()\n\n\nfrom wordcloud import WordCloud\nimport matplotlib.pyplot as plt\n\n# 워드클라우드 출력\nplt.imshow(wordcloud2, interpolation='bilinear')\nplt.axis('off')\nplt.show()"
  },
  {
    "objectID": "posts/image/2021-02-07-07. PretrainedModel.html",
    "href": "posts/image/2021-02-07-07. PretrainedModel.html",
    "title": "06. pretrained Model (1)",
    "section": "",
    "text": "사전훈련 모델 정보\n\n\n\n\nfrom tensorflow.keras.applications.vgg16 import VGG16, preprocess_input, decode_predictions\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n\n\n\n\n“잘 만들어진” 모델 바로 가져오기!\n\n\nmodel = VGG16(include_top=True,       # VGG16 모델의 아웃풋 레이어까지 전부 불러오기\n              weights='imagenet',     # ImageNet 데이터를 기반으로 학습된 가중치 불러오기\n              input_shape=(224,224,3) # 모델에 들어가는 데이터의 형태\n              )\n\nDownloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels.h5\n553467096/553467096 [==============================] - 25s 0us/step\n\n\n\nmodel.summary()\n\nModel: \"vgg16\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n                                                                 \n block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n                                                                 \n block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n                                                                 \n block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n                                                                 \n block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n                                                                 \n block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n                                                                 \n block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n                                                                 \n block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n                                                                 \n block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n                                                                 \n block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n                                                                 \n block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n                                                                 \n block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n                                                                 \n block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n                                                                 \n block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n                                                                 \n block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n                                                                 \n block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n                                                                 \n block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n                                                                 \n block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n                                                                 \n block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n                                                                 \n flatten (Flatten)           (None, 25088)             0         \n                                                                 \n fc1 (Dense)                 (None, 4096)              102764544 \n                                                                 \n fc2 (Dense)                 (None, 4096)              16781312  \n                                                                 \n predictions (Dense)         (None, 1000)              4097000   \n                                                                 \n=================================================================\nTotal params: 138357544 (527.79 MB)\nTrainable params: 138357544 (527.79 MB)\nNon-trainable params: 0 (0.00 Byte)\n_________________________________________________________________\n\n\n\nfrom tensorflow.keras.utils import plot_model\n\n\nplot_model(model, show_shapes=True, show_layer_names=True)\n\n\n\n\n\n아웃풋 레이어를 보면 노드가 1000개!\n분류 가능한 이미지가 1000개라는 뜻!\n구경하러 가자"
  },
  {
    "objectID": "posts/image/2021-02-07-07. PretrainedModel.html#library-loading",
    "href": "posts/image/2021-02-07-07. PretrainedModel.html#library-loading",
    "title": "06. pretrained Model (1)",
    "section": "",
    "text": "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input, decode_predictions\n\nimport numpy as np\nimport matplotlib.pyplot as plt"
  },
  {
    "objectID": "posts/image/2021-02-07-07. PretrainedModel.html#load-pretrained-model",
    "href": "posts/image/2021-02-07-07. PretrainedModel.html#load-pretrained-model",
    "title": "06. pretrained Model (1)",
    "section": "",
    "text": "“잘 만들어진” 모델 바로 가져오기!\n\n\nmodel = VGG16(include_top=True,       # VGG16 모델의 아웃풋 레이어까지 전부 불러오기\n              weights='imagenet',     # ImageNet 데이터를 기반으로 학습된 가중치 불러오기\n              input_shape=(224,224,3) # 모델에 들어가는 데이터의 형태\n              )\n\nDownloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels.h5\n553467096/553467096 [==============================] - 25s 0us/step\n\n\n\nmodel.summary()\n\nModel: \"vgg16\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n                                                                 \n block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n                                                                 \n block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n                                                                 \n block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n                                                                 \n block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n                                                                 \n block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n                                                                 \n block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n                                                                 \n block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n                                                                 \n block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n                                                                 \n block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n                                                                 \n block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n                                                                 \n block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n                                                                 \n block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n                                                                 \n block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n                                                                 \n block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n                                                                 \n block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n                                                                 \n block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n                                                                 \n block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n                                                                 \n block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n                                                                 \n flatten (Flatten)           (None, 25088)             0         \n                                                                 \n fc1 (Dense)                 (None, 4096)              102764544 \n                                                                 \n fc2 (Dense)                 (None, 4096)              16781312  \n                                                                 \n predictions (Dense)         (None, 1000)              4097000   \n                                                                 \n=================================================================\nTotal params: 138357544 (527.79 MB)\nTrainable params: 138357544 (527.79 MB)\nNon-trainable params: 0 (0.00 Byte)\n_________________________________________________________________\n\n\n\nfrom tensorflow.keras.utils import plot_model\n\n\nplot_model(model, show_shapes=True, show_layer_names=True)\n\n\n\n\n\n아웃풋 레이어를 보면 노드가 1000개!\n분류 가능한 이미지가 1000개라는 뜻!\n구경하러 가자"
  },
  {
    "objectID": "posts/image/2021-02-07-07. PretrainedModel.html#connect-colaboratory-with-my-google-drive",
    "href": "posts/image/2021-02-07-07. PretrainedModel.html#connect-colaboratory-with-my-google-drive",
    "title": "06. pretrained Model (1)",
    "section": "Connect Colaboratory with my Google Drive",
    "text": "Connect Colaboratory with my Google Drive\n\nfrom google.colab import drive\ndrive.mount('/content/drive')\n\nMounted at /content/drive\n\n\n\n!ls\n\ndrive  model.png  sample_data\n\n\n\n!cd /content/drive/MyDrive/my_data; ls\n\ndatasets  img1  model.png     my_mnist   MyPjt  transfer\nhandmade  img2  my_first_save.h5  my_mnist2  temp"
  },
  {
    "objectID": "posts/image/2021-02-07-07. PretrainedModel.html#load-image",
    "href": "posts/image/2021-02-07-07. PretrainedModel.html#load-image",
    "title": "06. pretrained Model (1)",
    "section": "Load Image",
    "text": "Load Image\n\n업로드 한 이미지 하나를 불러와 확인해본다\n\n\nimport glob\nfrom tensorflow.keras.preprocessing import image\n\n\nfiles = glob.glob('/content/drive/MyDrive/my_data/img1/*')\nfiles\n\n['/content/drive/MyDrive/my_data/img1/puppy-1903313_960_720.jpg',\n '/content/drive/MyDrive/my_data/img1/puppy-2785074_960_720.jpg',\n '/content/drive/MyDrive/my_data/img1/dog-4390885_960_720.jpg',\n '/content/drive/MyDrive/my_data/img1/dog-2561134_960_720.jpg',\n '/content/drive/MyDrive/my_data/img1/dog-1728494_960_720.webp',\n '/content/drive/MyDrive/my_data/img1/cat-2083492_960_720.jpg',\n '/content/drive/MyDrive/my_data/img1/maine-coon-694730_960_720.jpg',\n '/content/drive/MyDrive/my_data/img1/cat-2536662_960_720.jpg',\n '/content/drive/MyDrive/my_data/img1/tiger-2535888_960_720.jpg',\n '/content/drive/MyDrive/my_data/img1/cat-1151519_960_720.jpg',\n '/content/drive/MyDrive/my_data/img1/woman-3169726_960_720.jpg',\n '/content/drive/MyDrive/my_data/img1/suit-673697_960_720.jpg',\n '/content/drive/MyDrive/my_data/img1/happy-1836445_960_720.jpg',\n '/content/drive/MyDrive/my_data/img1/art-1851483_960_720.jpg',\n '/content/drive/MyDrive/my_data/img1/notebook-581128_960_720.jpg',\n '/content/drive/MyDrive/my_data/img1/coffee-2714970_960_720.jpg',\n '/content/drive/MyDrive/my_data/img1/coffee-1324126_960_720.jpg']\n\n\n\nimg = image.load_img(files[-1], color_mode='rgb', target_size = (224,224) )\nimg = image.img_to_array(img)\nimg = img.reshape((-1,224,224,3))\nprint(f'preprocess 전: 최대값={np.max(img)}, 최소값={np.min(img)}')\n\nimg = preprocess_input(img)\nprint(f'preprocess 후: 최대값={np.max(img)}, 최소값={np.min(img)}')\n\nfeatures = model.predict(img)\nprint(decode_predictions(features, top=3))\n\nplt.imshow(image.load_img(files[-1]))\nplt.show()\n\npreprocess 전: 최대값=255.0, 최소값=0.0\npreprocess 후: 최대값=151.06100463867188, 최소값=-123.68000030517578\n1/1 [==============================] - 8s 8s/step\nDownloading data from https://storage.googleapis.com/download.tensorflow.org/data/imagenet_class_index.json\n35363/35363 [==============================] - 0s 0us/step\n[[('n04332243', 'strainer', 0.2240853), ('n03000134', 'chainlink_fence', 0.10095732), ('n02999410', 'chain', 0.024076866)]]"
  },
  {
    "objectID": "posts/image/2021-02-07-07. PretrainedModel.html#load-images",
    "href": "posts/image/2021-02-07-07. PretrainedModel.html#load-images",
    "title": "06. pretrained Model (1)",
    "section": "Load Images",
    "text": "Load Images\n\n업로드 한 이미지 전체를 확인해본다\n\n\nimages = []\n\nfor path in files :\n    img = image.load_img(path, grayscale=False, target_size=(224,224) )\n    img = image.img_to_array(img)\n    img = preprocess_input(img)\n    images.append(img)\n\nimages = np.array(images)\n\n\nfeatures = model.predict(images)\npredictions = decode_predictions(features, top=3)\n\nfor i in range(images.shape[0]) :\n    print(predictions[i])\n    plt.imshow(image.load_img(files[i]))\n    plt.show()\n\nOutput hidden; open in https://colab.research.google.com to view.\n\n\n\n임의의 이미지에 대한 모델 적용\n\nimport glob\n\n\nfiles = glob.glob('/content/drive/MyDrive/my_data/img2/*')\nfiles\n\n['/content/drive/MyDrive/my_data/img2/puppies1.JPG',\n '/content/drive/MyDrive/my_data/img2/puppies2.jpg',\n '/content/drive/MyDrive/my_data/img2/puppies3.jfif',\n '/content/drive/MyDrive/my_data/img2/puppies4.webp',\n '/content/drive/MyDrive/my_data/img2/puppies5.jpg']\n\n\n\nimages = []\n\nfor path in files :\n    img = image.load_img(path, grayscale=False, target_size=(224,224) )\n    img = image.img_to_array(img)\n    img = preprocess_input(img)\n    images.append(img)\n\nimages = np.array(images)\n\n\nfeatures = model.predict(images)\npredictions = decode_predictions(features, top=3)\n\nfor i in range(images.shape[0]) :\n    print(predictions[i])\n    plt.imshow(image.load_img(files[i]))\n    plt.show()\n\n1/1 [==============================] - 1s 1s/step\n[('n02090622', 'borzoi', 0.31328258), ('n02110341', 'dalmatian', 0.26708207), ('n02091134', 'whippet', 0.2337371)]\n[('n02091635', 'otterhound', 0.94553703), ('n02096051', 'Airedale', 0.0132075725), ('n02088466', 'bloodhound', 0.010801472)]\n[('n02113023', 'Pembroke', 0.8097092), ('n02085620', 'Chihuahua', 0.07340224), ('n02113186', 'Cardigan', 0.041669823)]\n[('n02091831', 'Saluki', 0.47179848), ('n02099712', 'Labrador_retriever', 0.18313958), ('n02099601', 'golden_retriever', 0.06457339)]\n[('n02100583', 'vizsla', 0.5242368), ('n02099601', 'golden_retriever', 0.12659168), ('n02102318', 'cocker_spaniel', 0.031939697)]"
  },
  {
    "objectID": "posts/image/2021-02-03-05. ImageAugmentation3.html",
    "href": "posts/image/2021-02-03-05. ImageAugmentation3.html",
    "title": "04. image DA (3)",
    "section": "",
    "text": "import numpy as np\nimport matplotlib.pyplot as plt\n\nfrom tensorflow.keras.datasets.cifar100 import load_data\n\n\n(train_x, train_y), (test_x, test_y) = load_data()\n# (train_x, train_y), (test_x, test_y) = load_data(label_mode='coarse')\n\nDownloading data from https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n169001437/169001437 [==============================] - 4s 0us/step\n\n\n\nnp.unique(train_y)\n\narray([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n       34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,\n       51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67,\n       68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84,\n       85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99])\n\n\n\nlabel_dict = {0:'apple', 1: 'aquarium_fish', 2: 'baby', 3: 'bear', 4: 'beaver', 5: 'bed', 6: 'bee', 7: 'beetle', 8: 'bicycle', 9: 'bottle',\n              10: 'bowl', 11: 'boy',12: 'bridge',13: 'bus',14: 'butterfly',15: 'camel',16: 'can',17: 'castle',18: 'caterpillar',19: 'cattle',\n              20: 'chair',21: 'chimpanzee',22: 'clock',23: 'cloud',24: 'cockroach',25: 'couch',26: 'cra',27: 'crocodile',28: 'cup',29: 'dinosaur',\n              30: 'dolphin',31: 'elephant',32: 'flatfish',33: 'forest',34: 'fox',35: 'girl',36: 'hamster',37: 'house',38: 'kangaroo',39: 'keyboard',\n              40: 'lamp',41: 'lawn_mower',42: 'leopard',43: 'lion',44: 'lizard',45: 'lobster',46: 'man',47: 'maple_tree',48: 'motorcycle',49: 'mountain',\n              50: 'mouse',51: 'mushroom',52: 'oak_tree',53: 'orange',54: 'orchid',55: 'otter',56: 'palm_tree',57: 'pear',58: 'pickup_truck',59: 'pine_tree',\n              60: 'plain',61: 'plate',62: 'poppy',63: 'porcupine',64: 'possum',65: 'rabbit',66: 'raccoon',67: 'ray',68: 'road',69: 'rocket',\n              70: 'rose',71: 'sea',72: 'seal',73: 'shark',74: 'shrew',75: 'skunk',76: 'skyscraper',77: 'snail',78: 'snake',79: 'spider',\n              80: 'squirrel',81: 'streetcar',82: 'sunflower',83: 'sweet_pepper',84: 'table',85: 'tank',86: 'telephone',87: 'television',88: 'tiger',89: 'tractor',\n              90: 'train',91: 'trout',92: 'tulip',93: 'turtle',94: 'wardrobe',95: 'whale',96: 'willow_tree',97: 'wolf',98: 'woman',99: 'worm'\n            }\n\nlabel_dict[0]\n\n'apple'\n\n\n\n데이터 살펴보기\n\n\nrand_i = np.random.randint(0, train_x.shape[0])\n\nplt.title(f'idx: {rand_i} , class: { label_dict[train_y[rand_i][0]] }')\nplt.imshow( train_x[rand_i] )\nplt.show()\n\n\n\n\n\nrows = 5\nfig, axes = plt.subplots(rows, len(label_dict), figsize=(len(label_dict), rows) )\n\nfor img_id in range(len(label_dict)) :\n    imgs = train_x[train_y.reshape(-1)==img_id]\n    imgs_len = len(imgs)\n\n    for row_i in range(rows) :\n        axe = axes[row_i, img_id]\n        axe.imshow( imgs[np.random.randint(imgs_len)], interpolation='none' )\n        axe.axis('off')\n\nplt.tight_layout()\nplt.show()\n\nOutput hidden; open in https://colab.research.google.com to view.\n\n\n\n\n\n\nData split\n\ntraining set : test set = 8 : 2\ntraining set : validation set = 8 : 2\n재현을 위한 난수 고정 : 2023\n\n\n\nfrom sklearn.model_selection import train_test_split as tts\n\n\ntrain_x, val_x, train_y, val_y = tts(train_x, train_y, test_size=0.2, random_state=2023)\n\n\ntrain_x.shape, train_y.shape\n\n((40000, 32, 32, 3), (40000, 1))\n\n\n\nScaling\n\nmin-max scaling (선택사항)\n\nRGB 정보 전체를 min-max\nR 따로 G 따로 B 따로 min-max, 그 후 하나로 통합\n\n\n\n\n# min-max scaling 1번 방법\nmax_n, min_n = train_x.max(), train_x.min()\nmax_n, min_n\n\n(255, 0)\n\n\n\ntrain_x_mm1 = (train_x - min_n) / (max_n - min_n)\nval_x_mm1 = (val_x - min_n) / (max_n - min_n)\ntest_x_mm1 = (test_x - min_n) / (max_n - min_n)\n\n\ntrain_x_mm1.max(), train_x_mm1.min()\n\n(1.0, 0.0)\n\n\n\n# min-max scaling 2번 방법\ntr_r_max, tr_r_min = train_x[:,:,:,0].max(), train_x[:,:,:,0].min()\ntr_g_max, tr_g_min = train_x[:,:,:,1].max(), train_x[:,:,:,1].min()\ntr_b_max, tr_b_min = train_x[:,:,:,2].max(), train_x[:,:,:,2].min()\n\n\ntrain_r_mm = (train_x[:,:,:,0] - tr_r_min) / (tr_r_max - tr_r_min)\ntrain_g_mm = (train_x[:,:,:,1] - tr_g_min) / (tr_g_max - tr_g_min)\ntrain_b_mm = (train_x[:,:,:,2] - tr_b_min) / (tr_b_max - tr_b_min)\n\n\ntrain_x_mm = np.stack((train_r_mm, train_g_mm, train_b_mm), axis=3)\n\n\ntrain_x_mm.shape\n\n(40000, 32, 32, 3)\n\n\n\nval_r_mm = (val_x[:,:,:,0] - tr_r_min) / (tr_r_max - tr_r_min)\nval_g_mm = (val_x[:,:,:,1] - tr_g_min) / (tr_g_max - tr_g_min)\nval_b_mm = (val_x[:,:,:,2] - tr_b_min) / (tr_b_max - tr_b_min)\n\n\nval_x_mm = np.stack((val_r_mm, val_g_mm, val_b_mm), axis=3)\n\n\nval_x_mm.shape\n\n(10000, 32, 32, 3)\n\n\n\ntest_r_mm = (test_x[:,:,:,0] - tr_r_min) / (tr_r_max - tr_r_min)\ntest_g_mm = (test_x[:,:,:,1] - tr_g_min) / (tr_g_max - tr_g_min)\ntest_b_mm = (test_x[:,:,:,2] - tr_b_min) / (tr_b_max - tr_b_min)\n\n\ntest_x_mm = np.stack((test_r_mm, test_g_mm, test_b_mm), axis=3)\n\n\ntest_x_mm.shape\n\n(10000, 32, 32, 3)\n\n\n\nOne-hot encoding\n\n\ntrain_y.shape\ntrain_y\n\n\nclass_n = len(np.unique(train_y))\n\n\nfrom tensorflow.keras.utils import to_categorical\n\n\ntrain_y = to_categorical(train_y, class_n)\nval_y = to_categorical(val_y, class_n)\ntest_y = to_categorical(test_y, class_n)\n\n\nData shape 재확인\n\n\ntrain_x_mm.shape, train_y.shape\n\n((40000, 32, 32, 3), (40000, 100))\n\n\n\ntrain_y[0]\n\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n      dtype=float32)\n\n\n\n\n\n\nImageDataGenerator : 전체 옵션 참고\n.flow( )\n\n\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\n\ntrainIDG = ImageDataGenerator(rotation_range=15,\n                              width_shift_range=0.2,\n                              height_shift_range=0.2,\n                              shear_range=0.15,\n                              zoom_range=0.15,\n                              )\n\nvalIDG = ImageDataGenerator()\n\n\nflow_trainIDG = trainIDG.flow(train_x_mm, train_y)\nflow_valIDG = valIDG.flow(val_x_mm, val_y)\n\n\n\n\n\n조건\n\nSequential API, Functiona API 중 택일.\n이 구조를 미니 버전으로 활용해봐도 좋다.\nDropOut, BatchNormalization 등의 기능도 같이 활용해보자.\nEarly Stopping을 사용할 것.\n\n\n\nimport tensorflow as tf\nfrom tensorflow import keras\n\nfrom tensorflow.keras.backend import clear_session\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input, Dense, Flatten, BatchNormalization, Dropout\nfrom tensorflow.keras.layers import Conv2D, MaxPool2D\n\n\n# Functional API\n# 1. 세션 클리어\nclear_session()\n\n# 2. 레이어 엮기\nil = Input(shape=(32,32,3) )\n\nhl = Conv2D(filters=64,        # 새롭게 제작하려는 feature map의 수! 서로 다른 filter의 수\n            kernel_size=(3,3), # Conv filter의 가로세로 사이즈\n            strides=(1,1),     # Conv filter의 이동 보폭\n            padding='same',    # 1. 이전 feature map 사이즈 유지 | 2. 외곽 정보 더 반영\n            activation='relu'  # 명시 주의!\n            )(il)\nhl = Conv2D(filters=64,        # 새롭게 제작하려는 feature map의 수! 서로 다른 filter의 수\n            kernel_size=(3,3), # Conv filter의 가로세로 사이즈\n            strides=(1,1),     # Conv filter의 이동 보폭\n            padding='same',    # 1. 이전 feature map 사이즈 유지 | 2. 외곽 정보 더 반영\n            activation='relu'  # 명시 주의!\n            )(hl)\nhl = MaxPool2D(pool_size=(2,2),# Pool filter 가로세로 사이즈\n               strides=(2,2)   # Pool filter의 이동 보폭\n               )(hl)\nhl = BatchNormalization()(hl)\nhl = Dropout(0.5)(hl)\n\nhl = Conv2D(filters=128,        # 새롭게 제작하려는 feature map의 수! 서로 다른 filter의 수\n            kernel_size=(3,3), # Conv filter의 가로세로 사이즈\n            strides=(1,1),     # Conv filter의 이동 보폭\n            padding='same',    # 1. 이전 feature map 사이즈 유지 | 2. 외곽 정보 더 반영\n            activation='relu'  # 명시 주의!\n            )(hl)\nhl = Conv2D(filters=128,        # 새롭게 제작하려는 feature map의 수! 서로 다른 filter의 수\n            kernel_size=(3,3), # Conv filter의 가로세로 사이즈\n            strides=(1,1),     # Conv filter의 이동 보폭\n            padding='same',    # 1. 이전 feature map 사이즈 유지 | 2. 외곽 정보 더 반영\n            activation='relu'  # 명시 주의!\n            )(hl)\nhl = MaxPool2D(pool_size=(2,2),# Pool filter 가로세로 사이즈\n               strides=(2,2)   # Pool filter의 이동 보폭\n               )(hl)\nhl = BatchNormalization()(hl)\nhl = Dropout(0.5)(hl)\n\nhl = Flatten()(hl)\nhl = Dense(1024, activation='relu')(hl)\nol = Dense(100, activation='softmax')(hl)\n\n# 3. 모델 시작과 끝 지정\nmodel = Model(il, ol)\n\n# 4. 컴파일\nmodel.compile(optimizer='adam', loss=keras.losses.categorical_crossentropy,\n              metrics=['accuracy'])\n\n\nmodel.summary()\n\nModel: \"model\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n input_1 (InputLayer)        [(None, 32, 32, 3)]       0         \n                                                                 \n conv2d (Conv2D)             (None, 32, 32, 64)        1792      \n                                                                 \n conv2d_1 (Conv2D)           (None, 32, 32, 64)        36928     \n                                                                 \n max_pooling2d (MaxPooling2  (None, 16, 16, 64)        0         \n D)                                                              \n                                                                 \n batch_normalization (Batch  (None, 16, 16, 64)        256       \n Normalization)                                                  \n                                                                 \n dropout (Dropout)           (None, 16, 16, 64)        0         \n                                                                 \n conv2d_2 (Conv2D)           (None, 16, 16, 128)       73856     \n                                                                 \n conv2d_3 (Conv2D)           (None, 16, 16, 128)       147584    \n                                                                 \n max_pooling2d_1 (MaxPoolin  (None, 8, 8, 128)         0         \n g2D)                                                            \n                                                                 \n batch_normalization_1 (Bat  (None, 8, 8, 128)         512       \n chNormalization)                                                \n                                                                 \n dropout_1 (Dropout)         (None, 8, 8, 128)         0         \n                                                                 \n flatten (Flatten)           (None, 8192)              0         \n                                                                 \n dense (Dense)               (None, 1024)              8389632   \n                                                                 \n dense_1 (Dense)             (None, 100)               102500    \n                                                                 \n=================================================================\nTotal params: 8753060 (33.39 MB)\nTrainable params: 8752676 (33.39 MB)\nNon-trainable params: 384 (1.50 KB)\n_________________________________________________________________\n\n\n\nEarly Stopping\n\n\nfrom tensorflow.keras.callbacks import EarlyStopping\n\n\nes = EarlyStopping(monitor='val_loss',       # 얼리스토핑 적용할 관측 대상\n                   min_delta=0,              # 임계값.\n                   patience=3,               # 성능 개선 미발생시 몇 epoch 더 진행할 것인가.\n                   verbose=1,\n                   restore_best_weights=True # 가장 성능 좋은 epoch의 가중치로 되돌림\n                   )\n\n\n.fit( )\n\nData Augmentation 과정에서 생성한 ImageDataGenerator를 사용해야 한다.\n\n\n\nmodel.fit(flow_trainIDG,                # 위에서 만든 ImageDataGenerator 사용!\n          validation_data=flow_valIDG,  # validation data도 ImageDataGenerator 사용!\n          epochs=10000, verbose=1,\n          callbacks=[es]                # 얼리스토핑 적용!\n          )\n\nEpoch 1/10000\n1250/1250 [==============================] - 45s 26ms/step - loss: 4.0804 - accuracy: 0.0841 - val_loss: 4.0402 - val_accuracy: 0.1054\nEpoch 2/10000\n1250/1250 [==============================] - 32s 26ms/step - loss: 3.5838 - accuracy: 0.1485 - val_loss: 3.4358 - val_accuracy: 0.1836\nEpoch 3/10000\n1250/1250 [==============================] - 31s 25ms/step - loss: 3.3809 - accuracy: 0.1827 - val_loss: 3.6172 - val_accuracy: 0.1628\nEpoch 4/10000\n1250/1250 [==============================] - 32s 25ms/step - loss: 3.2250 - accuracy: 0.2094 - val_loss: 3.0372 - val_accuracy: 0.2392\nEpoch 5/10000\n1250/1250 [==============================] - 31s 25ms/step - loss: 3.1083 - accuracy: 0.2301 - val_loss: 3.2196 - val_accuracy: 0.2268\nEpoch 6/10000\n1250/1250 [==============================] - 31s 25ms/step - loss: 3.0036 - accuracy: 0.2521 - val_loss: 2.9238 - val_accuracy: 0.2734\nEpoch 7/10000\n1250/1250 [==============================] - 32s 26ms/step - loss: 2.9174 - accuracy: 0.2672 - val_loss: 2.6553 - val_accuracy: 0.3242\nEpoch 8/10000\n1250/1250 [==============================] - 32s 25ms/step - loss: 2.8519 - accuracy: 0.2797 - val_loss: 2.7759 - val_accuracy: 0.3153\nEpoch 9/10000\n1250/1250 [==============================] - 31s 25ms/step - loss: 2.7779 - accuracy: 0.2913 - val_loss: 2.5782 - val_accuracy: 0.3433\nEpoch 10/10000\n1250/1250 [==============================] - 32s 26ms/step - loss: 2.7133 - accuracy: 0.3062 - val_loss: 2.6364 - val_accuracy: 0.3373\nEpoch 11/10000\n 151/1250 [==&gt;...........................] - ETA: 24s - loss: 2.6425 - accuracy: 0.3239\n\n\nKeyboardInterrupt: ignored\n\n\n\n.evaluate( )\n\n\nmodel.evaluate(test_x_mm, test_y)\n\n313/313 [==============================] - 1s 4ms/step - loss: 2.8866 - accuracy: 0.3080\n\n\n[2.886594533920288, 0.30799999833106995]\n\n\n\n.predict( )\n\n\ny_pred = model.predict(test_x_mm)\n\n313/313 [==============================] - 1s 3ms/step\n\n\n\n# 원핫 인코딩 한 것을 다시 묶어주는 코드\n# 평가 지표 및 실제 데이터 확인을 위해 필요\n\ny_pred_arg = np.argmax(y_pred, axis=1)\ntest_y_arg = np.argmax(test_y, axis=1)\n\n\ny_pred_arg[0]\n\n79\n\n\n\ntest_y_arg[0]\n\n49\n\n\n\n평가 지표\n\n\nfrom sklearn.metrics import accuracy_score, classification_report\n\n\naccuracy_score(test_y_arg, y_pred_arg)\n\n0.308\n\n\n\nprint( classification_report(test_y_arg, y_pred_arg, target_names=list(label_dict.values())) )\n\n               precision    recall  f1-score   support\n\n        apple       0.81      0.46      0.59       100\naquarium_fish       0.62      0.24      0.35       100\n         baby       0.32      0.20      0.25       100\n         bear       0.38      0.12      0.18       100\n       beaver       0.12      0.08      0.10       100\n          bed       0.47      0.21      0.29       100\n          bee       0.25      0.47      0.33       100\n       beetle       0.34      0.47      0.39       100\n      bicycle       0.33      0.32      0.32       100\n       bottle       0.77      0.20      0.32       100\n         bowl       0.34      0.13      0.19       100\n          boy       0.49      0.23      0.31       100\n       bridge       0.52      0.23      0.32       100\n          bus       0.46      0.19      0.27       100\n    butterfly       0.33      0.10      0.15       100\n        camel       0.25      0.16      0.20       100\n          can       0.63      0.24      0.35       100\n       castle       0.51      0.31      0.39       100\n  caterpillar       0.50      0.08      0.14       100\n       cattle       0.38      0.18      0.24       100\n        chair       0.41      0.69      0.51       100\n   chimpanzee       0.50      0.30      0.37       100\n        clock       0.20      0.30      0.24       100\n        cloud       0.61      0.53      0.57       100\n    cockroach       0.43      0.57      0.49       100\n        couch       0.35      0.13      0.19       100\n          cra       0.17      0.37      0.23       100\n    crocodile       0.19      0.13      0.15       100\n          cup       0.61      0.35      0.45       100\n     dinosaur       0.26      0.39      0.31       100\n      dolphin       0.34      0.33      0.34       100\n     elephant       0.42      0.18      0.25       100\n     flatfish       0.37      0.18      0.24       100\n       forest       0.54      0.38      0.45       100\n          fox       0.09      0.15      0.11       100\n         girl       0.26      0.05      0.08       100\n      hamster       0.28      0.29      0.29       100\n        house       0.40      0.35      0.37       100\n     kangaroo       0.12      0.13      0.12       100\n     keyboard       0.14      0.65      0.23       100\n         lamp       0.50      0.17      0.25       100\n   lawn_mower       0.73      0.60      0.66       100\n      leopard       0.07      0.75      0.13       100\n         lion       0.16      0.23      0.19       100\n       lizard       0.14      0.12      0.13       100\n      lobster       0.14      0.12      0.13       100\n          man       0.37      0.15      0.21       100\n   maple_tree       0.35      0.40      0.38       100\n   motorcycle       0.49      0.59      0.53       100\n     mountain       0.47      0.40      0.43       100\n        mouse       0.17      0.07      0.10       100\n     mushroom       0.20      0.36      0.26       100\n     oak_tree       0.26      0.89      0.40       100\n       orange       0.60      0.71      0.65       100\n       orchid       0.60      0.37      0.46       100\n        otter       0.03      0.01      0.01       100\n    palm_tree       0.55      0.44      0.49       100\n         pear       0.60      0.25      0.35       100\n pickup_truck       0.67      0.06      0.11       100\n    pine_tree       0.22      0.15      0.18       100\n        plain       0.85      0.71      0.77       100\n        plate       0.35      0.49      0.40       100\n        poppy       0.56      0.40      0.47       100\n    porcupine       0.32      0.23      0.27       100\n       possum       0.17      0.06      0.09       100\n       rabbit       0.11      0.01      0.02       100\n      raccoon       0.17      0.05      0.08       100\n          ray       0.28      0.36      0.32       100\n         road       0.82      0.69      0.75       100\n       rocket       0.78      0.43      0.55       100\n         rose       0.40      0.52      0.45       100\n          sea       0.62      0.56      0.59       100\n         seal       0.17      0.08      0.11       100\n        shark       0.36      0.41      0.38       100\n        shrew       0.16      0.26      0.20       100\n        skunk       0.57      0.64      0.60       100\n   skyscraper       0.75      0.44      0.55       100\n        snail       0.25      0.13      0.17       100\n        snake       0.17      0.22      0.19       100\n       spider       0.41      0.30      0.34       100\n     squirrel       0.00      0.00      0.00       100\n    streetcar       0.26      0.41      0.32       100\n    sunflower       0.90      0.64      0.75       100\n sweet_pepper       0.45      0.25      0.32       100\n        table       0.43      0.10      0.16       100\n         tank       0.34      0.38      0.36       100\n    telephone       0.43      0.44      0.44       100\n   television       0.65      0.32      0.43       100\n        tiger       0.10      0.64      0.18       100\n      tractor       0.37      0.46      0.41       100\n        train       0.38      0.06      0.10       100\n        trout       0.47      0.55      0.51       100\n        tulip       0.29      0.19      0.23       100\n       turtle       0.14      0.09      0.11       100\n     wardrobe       0.72      0.54      0.62       100\n        whale       0.50      0.16      0.24       100\n  willow_tree       0.27      0.28      0.28       100\n         wolf       0.20      0.18      0.19       100\n        woman       0.18      0.06      0.09       100\n         worm       0.27      0.15      0.19       100\n\n     accuracy                           0.31     10000\n    macro avg       0.38      0.31      0.31     10000\n weighted avg       0.38      0.31      0.31     10000\n\n\n\n\n\n\n\n실제 데이터 확인\n\n\nrand_idx = np.random.randint(0, len(y_pred_arg))\ntest_idx = test_y_arg[rand_idx]\npred_idx = y_pred_arg[rand_idx]\nclass_prob = np.floor( y_pred[rand_idx]*100 )\n\nprint(f'idx = {rand_idx}')\nprint(f'해당 인덱스의 이미지는 {label_dict[test_idx]}')\nprint(f'모델의 예측 : {label_dict[pred_idx]}')\nprint(f'모델의 클래스별 확률 : ')\nprint('-------------------')\nfor idx, val in enumerate( list(label_dict.values()) ) :\n    print(val, class_prob[idx])\nprint('=================================================')\n\nif test_y_arg[rand_idx] == y_pred_arg[rand_idx] :\n    print('정답')\nelse :\n    print('땡')\n\nplt.imshow(test_x[rand_idx])\nplt.show()\n\nidx = 7957\n해당 인덱스의 이미지는 keyboard\n모델의 예측 : leopard\n모델의 클래스별 확률 : \n-------------------\napple 0.0\naquarium_fish 0.0\nbaby 0.0\nbear 3.0\nbeaver 7.0\nbed 0.0\nbee 0.0\nbeetle 0.0\nbicycle 0.0\nbottle 0.0\nbowl 0.0\nboy 0.0\nbridge 9.0\nbus 0.0\nbutterfly 0.0\ncamel 0.0\ncan 0.0\ncastle 1.0\ncaterpillar 0.0\ncattle 3.0\nchair 0.0\nchimpanzee 9.0\nclock 0.0\ncloud 0.0\ncockroach 0.0\ncouch 0.0\ncra 0.0\ncrocodile 0.0\ncup 0.0\ndinosaur 2.0\ndolphin 0.0\nelephant 5.0\nflatfish 0.0\nforest 0.0\nfox 0.0\ngirl 0.0\nhamster 0.0\nhouse 1.0\nkangaroo 2.0\nkeyboard 0.0\nlamp 0.0\nlawn_mower 0.0\nleopard 10.0\nlion 0.0\nlizard 0.0\nlobster 0.0\nman 0.0\nmaple_tree 0.0\nmotorcycle 0.0\nmountain 0.0\nmouse 1.0\nmushroom 1.0\noak_tree 0.0\norange 0.0\norchid 0.0\notter 2.0\npalm_tree 0.0\npear 0.0\npickup_truck 0.0\npine_tree 0.0\nplain 0.0\nplate 0.0\npoppy 0.0\nporcupine 1.0\npossum 4.0\nrabbit 0.0\nraccoon 6.0\nray 0.0\nroad 0.0\nrocket 0.0\nrose 0.0\nsea 0.0\nseal 2.0\nshark 0.0\nshrew 2.0\nskunk 0.0\nskyscraper 0.0\nsnail 0.0\nsnake 0.0\nspider 0.0\nsquirrel 3.0\nstreetcar 0.0\nsunflower 0.0\nsweet_pepper 0.0\ntable 0.0\ntank 1.0\ntelephone 0.0\ntelevision 0.0\ntiger 0.0\ntractor 0.0\ntrain 0.0\ntrout 0.0\ntulip 0.0\nturtle 0.0\nwardrobe 0.0\nwhale 0.0\nwillow_tree 0.0\nwolf 1.0\nwoman 0.0\nworm 0.0\n=================================================\n땡\n\n\n\n\n\n\n틀린 이미지만 확인해보기\n\n\ntemp = (test_y_arg == y_pred_arg)\nfalse_idx = np.where(temp==False)[0]\nfalse_len = len(false_idx)\nfalse_len\n\n6920\n\n\n\nrand_idx = false_idx[np.random.randint(0, false_len)]\ntest_idx = test_y_arg[rand_idx]\npred_idx = y_pred_arg[rand_idx]\nclass_prob = np.floor( y_pred[rand_idx]*100 )\n\nprint(f'idx = {rand_idx}')\nprint(f'해당 인덱스의 이미지는 {label_dict[test_idx]}')\nprint(f'모델의 예측 : {label_dict[pred_idx]}')\nprint(f'모델의 클래스별 확률 : ')\nprint('-------------------')\nfor idx, val in enumerate( list(label_dict.values()) ) :\n    print(val, class_prob[idx])\nprint('=================================================')\n\nif test_y_arg[rand_idx] == y_pred_arg[rand_idx] :\n    print('정답')\nelse :\n    print('땡')\n\nplt.imshow(test_x[rand_idx] )\nplt.show()\n\nidx = 8604\n해당 인덱스의 이미지는 camel\n모델의 예측 : kangaroo\n모델의 클래스별 확률 : \n-------------------\napple 0.0\naquarium_fish 0.0\nbaby 0.0\nbear 0.0\nbeaver 3.0\nbed 0.0\nbee 0.0\nbeetle 0.0\nbicycle 0.0\nbottle 0.0\nbowl 0.0\nboy 0.0\nbridge 0.0\nbus 0.0\nbutterfly 0.0\ncamel 1.0\ncan 0.0\ncastle 0.0\ncaterpillar 0.0\ncattle 12.0\nchair 0.0\nchimpanzee 0.0\nclock 0.0\ncloud 0.0\ncockroach 0.0\ncouch 0.0\ncra 0.0\ncrocodile 0.0\ncup 0.0\ndinosaur 1.0\ndolphin 0.0\nelephant 0.0\nflatfish 0.0\nforest 0.0\nfox 14.0\ngirl 0.0\nhamster 0.0\nhouse 0.0\nkangaroo 39.0\nkeyboard 0.0\nlamp 0.0\nlawn_mower 0.0\nleopard 1.0\nlion 0.0\nlizard 0.0\nlobster 0.0\nman 0.0\nmaple_tree 0.0\nmotorcycle 0.0\nmountain 0.0\nmouse 0.0\nmushroom 0.0\noak_tree 0.0\norange 0.0\norchid 0.0\notter 0.0\npalm_tree 0.0\npear 0.0\npickup_truck 0.0\npine_tree 0.0\nplain 0.0\nplate 0.0\npoppy 0.0\nporcupine 1.0\npossum 0.0\nrabbit 1.0\nraccoon 0.0\nray 0.0\nroad 0.0\nrocket 0.0\nrose 0.0\nsea 0.0\nseal 0.0\nshark 0.0\nshrew 5.0\nskunk 0.0\nskyscraper 0.0\nsnail 0.0\nsnake 0.0\nspider 1.0\nsquirrel 0.0\nstreetcar 0.0\nsunflower 0.0\nsweet_pepper 0.0\ntable 0.0\ntank 0.0\ntelephone 0.0\ntelevision 0.0\ntiger 4.0\ntractor 0.0\ntrain 0.0\ntrout 0.0\ntulip 0.0\nturtle 0.0\nwardrobe 0.0\nwhale 0.0\nwillow_tree 0.0\nwolf 0.0\nwoman 0.0\nworm 0.0\n=================================================\n땡"
  },
  {
    "objectID": "posts/image/2021-02-03-05. ImageAugmentation3.html#data-loading",
    "href": "posts/image/2021-02-03-05. ImageAugmentation3.html#data-loading",
    "title": "04. image DA (3)",
    "section": "",
    "text": "import numpy as np\nimport matplotlib.pyplot as plt\n\nfrom tensorflow.keras.datasets.cifar100 import load_data\n\n\n(train_x, train_y), (test_x, test_y) = load_data()\n# (train_x, train_y), (test_x, test_y) = load_data(label_mode='coarse')\n\nDownloading data from https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n169001437/169001437 [==============================] - 4s 0us/step\n\n\n\nnp.unique(train_y)\n\narray([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n       34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,\n       51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67,\n       68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84,\n       85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99])\n\n\n\nlabel_dict = {0:'apple', 1: 'aquarium_fish', 2: 'baby', 3: 'bear', 4: 'beaver', 5: 'bed', 6: 'bee', 7: 'beetle', 8: 'bicycle', 9: 'bottle',\n              10: 'bowl', 11: 'boy',12: 'bridge',13: 'bus',14: 'butterfly',15: 'camel',16: 'can',17: 'castle',18: 'caterpillar',19: 'cattle',\n              20: 'chair',21: 'chimpanzee',22: 'clock',23: 'cloud',24: 'cockroach',25: 'couch',26: 'cra',27: 'crocodile',28: 'cup',29: 'dinosaur',\n              30: 'dolphin',31: 'elephant',32: 'flatfish',33: 'forest',34: 'fox',35: 'girl',36: 'hamster',37: 'house',38: 'kangaroo',39: 'keyboard',\n              40: 'lamp',41: 'lawn_mower',42: 'leopard',43: 'lion',44: 'lizard',45: 'lobster',46: 'man',47: 'maple_tree',48: 'motorcycle',49: 'mountain',\n              50: 'mouse',51: 'mushroom',52: 'oak_tree',53: 'orange',54: 'orchid',55: 'otter',56: 'palm_tree',57: 'pear',58: 'pickup_truck',59: 'pine_tree',\n              60: 'plain',61: 'plate',62: 'poppy',63: 'porcupine',64: 'possum',65: 'rabbit',66: 'raccoon',67: 'ray',68: 'road',69: 'rocket',\n              70: 'rose',71: 'sea',72: 'seal',73: 'shark',74: 'shrew',75: 'skunk',76: 'skyscraper',77: 'snail',78: 'snake',79: 'spider',\n              80: 'squirrel',81: 'streetcar',82: 'sunflower',83: 'sweet_pepper',84: 'table',85: 'tank',86: 'telephone',87: 'television',88: 'tiger',89: 'tractor',\n              90: 'train',91: 'trout',92: 'tulip',93: 'turtle',94: 'wardrobe',95: 'whale',96: 'willow_tree',97: 'wolf',98: 'woman',99: 'worm'\n            }\n\nlabel_dict[0]\n\n'apple'\n\n\n\n데이터 살펴보기\n\n\nrand_i = np.random.randint(0, train_x.shape[0])\n\nplt.title(f'idx: {rand_i} , class: { label_dict[train_y[rand_i][0]] }')\nplt.imshow( train_x[rand_i] )\nplt.show()\n\n\n\n\n\nrows = 5\nfig, axes = plt.subplots(rows, len(label_dict), figsize=(len(label_dict), rows) )\n\nfor img_id in range(len(label_dict)) :\n    imgs = train_x[train_y.reshape(-1)==img_id]\n    imgs_len = len(imgs)\n\n    for row_i in range(rows) :\n        axe = axes[row_i, img_id]\n        axe.imshow( imgs[np.random.randint(imgs_len)], interpolation='none' )\n        axe.axis('off')\n\nplt.tight_layout()\nplt.show()\n\nOutput hidden; open in https://colab.research.google.com to view."
  },
  {
    "objectID": "posts/image/2021-02-03-05. ImageAugmentation3.html#data-preprocessing",
    "href": "posts/image/2021-02-03-05. ImageAugmentation3.html#data-preprocessing",
    "title": "04. image DA (3)",
    "section": "",
    "text": "Data split\n\ntraining set : test set = 8 : 2\ntraining set : validation set = 8 : 2\n재현을 위한 난수 고정 : 2023\n\n\n\nfrom sklearn.model_selection import train_test_split as tts\n\n\ntrain_x, val_x, train_y, val_y = tts(train_x, train_y, test_size=0.2, random_state=2023)\n\n\ntrain_x.shape, train_y.shape\n\n((40000, 32, 32, 3), (40000, 1))\n\n\n\nScaling\n\nmin-max scaling (선택사항)\n\nRGB 정보 전체를 min-max\nR 따로 G 따로 B 따로 min-max, 그 후 하나로 통합\n\n\n\n\n# min-max scaling 1번 방법\nmax_n, min_n = train_x.max(), train_x.min()\nmax_n, min_n\n\n(255, 0)\n\n\n\ntrain_x_mm1 = (train_x - min_n) / (max_n - min_n)\nval_x_mm1 = (val_x - min_n) / (max_n - min_n)\ntest_x_mm1 = (test_x - min_n) / (max_n - min_n)\n\n\ntrain_x_mm1.max(), train_x_mm1.min()\n\n(1.0, 0.0)\n\n\n\n# min-max scaling 2번 방법\ntr_r_max, tr_r_min = train_x[:,:,:,0].max(), train_x[:,:,:,0].min()\ntr_g_max, tr_g_min = train_x[:,:,:,1].max(), train_x[:,:,:,1].min()\ntr_b_max, tr_b_min = train_x[:,:,:,2].max(), train_x[:,:,:,2].min()\n\n\ntrain_r_mm = (train_x[:,:,:,0] - tr_r_min) / (tr_r_max - tr_r_min)\ntrain_g_mm = (train_x[:,:,:,1] - tr_g_min) / (tr_g_max - tr_g_min)\ntrain_b_mm = (train_x[:,:,:,2] - tr_b_min) / (tr_b_max - tr_b_min)\n\n\ntrain_x_mm = np.stack((train_r_mm, train_g_mm, train_b_mm), axis=3)\n\n\ntrain_x_mm.shape\n\n(40000, 32, 32, 3)\n\n\n\nval_r_mm = (val_x[:,:,:,0] - tr_r_min) / (tr_r_max - tr_r_min)\nval_g_mm = (val_x[:,:,:,1] - tr_g_min) / (tr_g_max - tr_g_min)\nval_b_mm = (val_x[:,:,:,2] - tr_b_min) / (tr_b_max - tr_b_min)\n\n\nval_x_mm = np.stack((val_r_mm, val_g_mm, val_b_mm), axis=3)\n\n\nval_x_mm.shape\n\n(10000, 32, 32, 3)\n\n\n\ntest_r_mm = (test_x[:,:,:,0] - tr_r_min) / (tr_r_max - tr_r_min)\ntest_g_mm = (test_x[:,:,:,1] - tr_g_min) / (tr_g_max - tr_g_min)\ntest_b_mm = (test_x[:,:,:,2] - tr_b_min) / (tr_b_max - tr_b_min)\n\n\ntest_x_mm = np.stack((test_r_mm, test_g_mm, test_b_mm), axis=3)\n\n\ntest_x_mm.shape\n\n(10000, 32, 32, 3)\n\n\n\nOne-hot encoding\n\n\ntrain_y.shape\ntrain_y\n\n\nclass_n = len(np.unique(train_y))\n\n\nfrom tensorflow.keras.utils import to_categorical\n\n\ntrain_y = to_categorical(train_y, class_n)\nval_y = to_categorical(val_y, class_n)\ntest_y = to_categorical(test_y, class_n)\n\n\nData shape 재확인\n\n\ntrain_x_mm.shape, train_y.shape\n\n((40000, 32, 32, 3), (40000, 100))\n\n\n\ntrain_y[0]\n\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n      dtype=float32)"
  },
  {
    "objectID": "posts/image/2021-02-03-05. ImageAugmentation3.html#image-data-augmentation",
    "href": "posts/image/2021-02-03-05. ImageAugmentation3.html#image-data-augmentation",
    "title": "04. image DA (3)",
    "section": "",
    "text": "ImageDataGenerator : 전체 옵션 참고\n.flow( )\n\n\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\n\ntrainIDG = ImageDataGenerator(rotation_range=15,\n                              width_shift_range=0.2,\n                              height_shift_range=0.2,\n                              shear_range=0.15,\n                              zoom_range=0.15,\n                              )\n\nvalIDG = ImageDataGenerator()\n\n\nflow_trainIDG = trainIDG.flow(train_x_mm, train_y)\nflow_valIDG = valIDG.flow(val_x_mm, val_y)"
  },
  {
    "objectID": "posts/image/2021-02-03-05. ImageAugmentation3.html#modeling-cnn",
    "href": "posts/image/2021-02-03-05. ImageAugmentation3.html#modeling-cnn",
    "title": "04. image DA (3)",
    "section": "",
    "text": "조건\n\nSequential API, Functiona API 중 택일.\n이 구조를 미니 버전으로 활용해봐도 좋다.\nDropOut, BatchNormalization 등의 기능도 같이 활용해보자.\nEarly Stopping을 사용할 것.\n\n\n\nimport tensorflow as tf\nfrom tensorflow import keras\n\nfrom tensorflow.keras.backend import clear_session\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input, Dense, Flatten, BatchNormalization, Dropout\nfrom tensorflow.keras.layers import Conv2D, MaxPool2D\n\n\n# Functional API\n# 1. 세션 클리어\nclear_session()\n\n# 2. 레이어 엮기\nil = Input(shape=(32,32,3) )\n\nhl = Conv2D(filters=64,        # 새롭게 제작하려는 feature map의 수! 서로 다른 filter의 수\n            kernel_size=(3,3), # Conv filter의 가로세로 사이즈\n            strides=(1,1),     # Conv filter의 이동 보폭\n            padding='same',    # 1. 이전 feature map 사이즈 유지 | 2. 외곽 정보 더 반영\n            activation='relu'  # 명시 주의!\n            )(il)\nhl = Conv2D(filters=64,        # 새롭게 제작하려는 feature map의 수! 서로 다른 filter의 수\n            kernel_size=(3,3), # Conv filter의 가로세로 사이즈\n            strides=(1,1),     # Conv filter의 이동 보폭\n            padding='same',    # 1. 이전 feature map 사이즈 유지 | 2. 외곽 정보 더 반영\n            activation='relu'  # 명시 주의!\n            )(hl)\nhl = MaxPool2D(pool_size=(2,2),# Pool filter 가로세로 사이즈\n               strides=(2,2)   # Pool filter의 이동 보폭\n               )(hl)\nhl = BatchNormalization()(hl)\nhl = Dropout(0.5)(hl)\n\nhl = Conv2D(filters=128,        # 새롭게 제작하려는 feature map의 수! 서로 다른 filter의 수\n            kernel_size=(3,3), # Conv filter의 가로세로 사이즈\n            strides=(1,1),     # Conv filter의 이동 보폭\n            padding='same',    # 1. 이전 feature map 사이즈 유지 | 2. 외곽 정보 더 반영\n            activation='relu'  # 명시 주의!\n            )(hl)\nhl = Conv2D(filters=128,        # 새롭게 제작하려는 feature map의 수! 서로 다른 filter의 수\n            kernel_size=(3,3), # Conv filter의 가로세로 사이즈\n            strides=(1,1),     # Conv filter의 이동 보폭\n            padding='same',    # 1. 이전 feature map 사이즈 유지 | 2. 외곽 정보 더 반영\n            activation='relu'  # 명시 주의!\n            )(hl)\nhl = MaxPool2D(pool_size=(2,2),# Pool filter 가로세로 사이즈\n               strides=(2,2)   # Pool filter의 이동 보폭\n               )(hl)\nhl = BatchNormalization()(hl)\nhl = Dropout(0.5)(hl)\n\nhl = Flatten()(hl)\nhl = Dense(1024, activation='relu')(hl)\nol = Dense(100, activation='softmax')(hl)\n\n# 3. 모델 시작과 끝 지정\nmodel = Model(il, ol)\n\n# 4. 컴파일\nmodel.compile(optimizer='adam', loss=keras.losses.categorical_crossentropy,\n              metrics=['accuracy'])\n\n\nmodel.summary()\n\nModel: \"model\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n input_1 (InputLayer)        [(None, 32, 32, 3)]       0         \n                                                                 \n conv2d (Conv2D)             (None, 32, 32, 64)        1792      \n                                                                 \n conv2d_1 (Conv2D)           (None, 32, 32, 64)        36928     \n                                                                 \n max_pooling2d (MaxPooling2  (None, 16, 16, 64)        0         \n D)                                                              \n                                                                 \n batch_normalization (Batch  (None, 16, 16, 64)        256       \n Normalization)                                                  \n                                                                 \n dropout (Dropout)           (None, 16, 16, 64)        0         \n                                                                 \n conv2d_2 (Conv2D)           (None, 16, 16, 128)       73856     \n                                                                 \n conv2d_3 (Conv2D)           (None, 16, 16, 128)       147584    \n                                                                 \n max_pooling2d_1 (MaxPoolin  (None, 8, 8, 128)         0         \n g2D)                                                            \n                                                                 \n batch_normalization_1 (Bat  (None, 8, 8, 128)         512       \n chNormalization)                                                \n                                                                 \n dropout_1 (Dropout)         (None, 8, 8, 128)         0         \n                                                                 \n flatten (Flatten)           (None, 8192)              0         \n                                                                 \n dense (Dense)               (None, 1024)              8389632   \n                                                                 \n dense_1 (Dense)             (None, 100)               102500    \n                                                                 \n=================================================================\nTotal params: 8753060 (33.39 MB)\nTrainable params: 8752676 (33.39 MB)\nNon-trainable params: 384 (1.50 KB)\n_________________________________________________________________\n\n\n\nEarly Stopping\n\n\nfrom tensorflow.keras.callbacks import EarlyStopping\n\n\nes = EarlyStopping(monitor='val_loss',       # 얼리스토핑 적용할 관측 대상\n                   min_delta=0,              # 임계값.\n                   patience=3,               # 성능 개선 미발생시 몇 epoch 더 진행할 것인가.\n                   verbose=1,\n                   restore_best_weights=True # 가장 성능 좋은 epoch의 가중치로 되돌림\n                   )\n\n\n.fit( )\n\nData Augmentation 과정에서 생성한 ImageDataGenerator를 사용해야 한다.\n\n\n\nmodel.fit(flow_trainIDG,                # 위에서 만든 ImageDataGenerator 사용!\n          validation_data=flow_valIDG,  # validation data도 ImageDataGenerator 사용!\n          epochs=10000, verbose=1,\n          callbacks=[es]                # 얼리스토핑 적용!\n          )\n\nEpoch 1/10000\n1250/1250 [==============================] - 45s 26ms/step - loss: 4.0804 - accuracy: 0.0841 - val_loss: 4.0402 - val_accuracy: 0.1054\nEpoch 2/10000\n1250/1250 [==============================] - 32s 26ms/step - loss: 3.5838 - accuracy: 0.1485 - val_loss: 3.4358 - val_accuracy: 0.1836\nEpoch 3/10000\n1250/1250 [==============================] - 31s 25ms/step - loss: 3.3809 - accuracy: 0.1827 - val_loss: 3.6172 - val_accuracy: 0.1628\nEpoch 4/10000\n1250/1250 [==============================] - 32s 25ms/step - loss: 3.2250 - accuracy: 0.2094 - val_loss: 3.0372 - val_accuracy: 0.2392\nEpoch 5/10000\n1250/1250 [==============================] - 31s 25ms/step - loss: 3.1083 - accuracy: 0.2301 - val_loss: 3.2196 - val_accuracy: 0.2268\nEpoch 6/10000\n1250/1250 [==============================] - 31s 25ms/step - loss: 3.0036 - accuracy: 0.2521 - val_loss: 2.9238 - val_accuracy: 0.2734\nEpoch 7/10000\n1250/1250 [==============================] - 32s 26ms/step - loss: 2.9174 - accuracy: 0.2672 - val_loss: 2.6553 - val_accuracy: 0.3242\nEpoch 8/10000\n1250/1250 [==============================] - 32s 25ms/step - loss: 2.8519 - accuracy: 0.2797 - val_loss: 2.7759 - val_accuracy: 0.3153\nEpoch 9/10000\n1250/1250 [==============================] - 31s 25ms/step - loss: 2.7779 - accuracy: 0.2913 - val_loss: 2.5782 - val_accuracy: 0.3433\nEpoch 10/10000\n1250/1250 [==============================] - 32s 26ms/step - loss: 2.7133 - accuracy: 0.3062 - val_loss: 2.6364 - val_accuracy: 0.3373\nEpoch 11/10000\n 151/1250 [==&gt;...........................] - ETA: 24s - loss: 2.6425 - accuracy: 0.3239\n\n\nKeyboardInterrupt: ignored\n\n\n\n.evaluate( )\n\n\nmodel.evaluate(test_x_mm, test_y)\n\n313/313 [==============================] - 1s 4ms/step - loss: 2.8866 - accuracy: 0.3080\n\n\n[2.886594533920288, 0.30799999833106995]\n\n\n\n.predict( )\n\n\ny_pred = model.predict(test_x_mm)\n\n313/313 [==============================] - 1s 3ms/step\n\n\n\n# 원핫 인코딩 한 것을 다시 묶어주는 코드\n# 평가 지표 및 실제 데이터 확인을 위해 필요\n\ny_pred_arg = np.argmax(y_pred, axis=1)\ntest_y_arg = np.argmax(test_y, axis=1)\n\n\ny_pred_arg[0]\n\n79\n\n\n\ntest_y_arg[0]\n\n49\n\n\n\n평가 지표\n\n\nfrom sklearn.metrics import accuracy_score, classification_report\n\n\naccuracy_score(test_y_arg, y_pred_arg)\n\n0.308\n\n\n\nprint( classification_report(test_y_arg, y_pred_arg, target_names=list(label_dict.values())) )\n\n               precision    recall  f1-score   support\n\n        apple       0.81      0.46      0.59       100\naquarium_fish       0.62      0.24      0.35       100\n         baby       0.32      0.20      0.25       100\n         bear       0.38      0.12      0.18       100\n       beaver       0.12      0.08      0.10       100\n          bed       0.47      0.21      0.29       100\n          bee       0.25      0.47      0.33       100\n       beetle       0.34      0.47      0.39       100\n      bicycle       0.33      0.32      0.32       100\n       bottle       0.77      0.20      0.32       100\n         bowl       0.34      0.13      0.19       100\n          boy       0.49      0.23      0.31       100\n       bridge       0.52      0.23      0.32       100\n          bus       0.46      0.19      0.27       100\n    butterfly       0.33      0.10      0.15       100\n        camel       0.25      0.16      0.20       100\n          can       0.63      0.24      0.35       100\n       castle       0.51      0.31      0.39       100\n  caterpillar       0.50      0.08      0.14       100\n       cattle       0.38      0.18      0.24       100\n        chair       0.41      0.69      0.51       100\n   chimpanzee       0.50      0.30      0.37       100\n        clock       0.20      0.30      0.24       100\n        cloud       0.61      0.53      0.57       100\n    cockroach       0.43      0.57      0.49       100\n        couch       0.35      0.13      0.19       100\n          cra       0.17      0.37      0.23       100\n    crocodile       0.19      0.13      0.15       100\n          cup       0.61      0.35      0.45       100\n     dinosaur       0.26      0.39      0.31       100\n      dolphin       0.34      0.33      0.34       100\n     elephant       0.42      0.18      0.25       100\n     flatfish       0.37      0.18      0.24       100\n       forest       0.54      0.38      0.45       100\n          fox       0.09      0.15      0.11       100\n         girl       0.26      0.05      0.08       100\n      hamster       0.28      0.29      0.29       100\n        house       0.40      0.35      0.37       100\n     kangaroo       0.12      0.13      0.12       100\n     keyboard       0.14      0.65      0.23       100\n         lamp       0.50      0.17      0.25       100\n   lawn_mower       0.73      0.60      0.66       100\n      leopard       0.07      0.75      0.13       100\n         lion       0.16      0.23      0.19       100\n       lizard       0.14      0.12      0.13       100\n      lobster       0.14      0.12      0.13       100\n          man       0.37      0.15      0.21       100\n   maple_tree       0.35      0.40      0.38       100\n   motorcycle       0.49      0.59      0.53       100\n     mountain       0.47      0.40      0.43       100\n        mouse       0.17      0.07      0.10       100\n     mushroom       0.20      0.36      0.26       100\n     oak_tree       0.26      0.89      0.40       100\n       orange       0.60      0.71      0.65       100\n       orchid       0.60      0.37      0.46       100\n        otter       0.03      0.01      0.01       100\n    palm_tree       0.55      0.44      0.49       100\n         pear       0.60      0.25      0.35       100\n pickup_truck       0.67      0.06      0.11       100\n    pine_tree       0.22      0.15      0.18       100\n        plain       0.85      0.71      0.77       100\n        plate       0.35      0.49      0.40       100\n        poppy       0.56      0.40      0.47       100\n    porcupine       0.32      0.23      0.27       100\n       possum       0.17      0.06      0.09       100\n       rabbit       0.11      0.01      0.02       100\n      raccoon       0.17      0.05      0.08       100\n          ray       0.28      0.36      0.32       100\n         road       0.82      0.69      0.75       100\n       rocket       0.78      0.43      0.55       100\n         rose       0.40      0.52      0.45       100\n          sea       0.62      0.56      0.59       100\n         seal       0.17      0.08      0.11       100\n        shark       0.36      0.41      0.38       100\n        shrew       0.16      0.26      0.20       100\n        skunk       0.57      0.64      0.60       100\n   skyscraper       0.75      0.44      0.55       100\n        snail       0.25      0.13      0.17       100\n        snake       0.17      0.22      0.19       100\n       spider       0.41      0.30      0.34       100\n     squirrel       0.00      0.00      0.00       100\n    streetcar       0.26      0.41      0.32       100\n    sunflower       0.90      0.64      0.75       100\n sweet_pepper       0.45      0.25      0.32       100\n        table       0.43      0.10      0.16       100\n         tank       0.34      0.38      0.36       100\n    telephone       0.43      0.44      0.44       100\n   television       0.65      0.32      0.43       100\n        tiger       0.10      0.64      0.18       100\n      tractor       0.37      0.46      0.41       100\n        train       0.38      0.06      0.10       100\n        trout       0.47      0.55      0.51       100\n        tulip       0.29      0.19      0.23       100\n       turtle       0.14      0.09      0.11       100\n     wardrobe       0.72      0.54      0.62       100\n        whale       0.50      0.16      0.24       100\n  willow_tree       0.27      0.28      0.28       100\n         wolf       0.20      0.18      0.19       100\n        woman       0.18      0.06      0.09       100\n         worm       0.27      0.15      0.19       100\n\n     accuracy                           0.31     10000\n    macro avg       0.38      0.31      0.31     10000\n weighted avg       0.38      0.31      0.31     10000"
  },
  {
    "objectID": "posts/image/2021-02-03-05. ImageAugmentation3.html#visualization",
    "href": "posts/image/2021-02-03-05. ImageAugmentation3.html#visualization",
    "title": "04. image DA (3)",
    "section": "",
    "text": "실제 데이터 확인\n\n\nrand_idx = np.random.randint(0, len(y_pred_arg))\ntest_idx = test_y_arg[rand_idx]\npred_idx = y_pred_arg[rand_idx]\nclass_prob = np.floor( y_pred[rand_idx]*100 )\n\nprint(f'idx = {rand_idx}')\nprint(f'해당 인덱스의 이미지는 {label_dict[test_idx]}')\nprint(f'모델의 예측 : {label_dict[pred_idx]}')\nprint(f'모델의 클래스별 확률 : ')\nprint('-------------------')\nfor idx, val in enumerate( list(label_dict.values()) ) :\n    print(val, class_prob[idx])\nprint('=================================================')\n\nif test_y_arg[rand_idx] == y_pred_arg[rand_idx] :\n    print('정답')\nelse :\n    print('땡')\n\nplt.imshow(test_x[rand_idx])\nplt.show()\n\nidx = 7957\n해당 인덱스의 이미지는 keyboard\n모델의 예측 : leopard\n모델의 클래스별 확률 : \n-------------------\napple 0.0\naquarium_fish 0.0\nbaby 0.0\nbear 3.0\nbeaver 7.0\nbed 0.0\nbee 0.0\nbeetle 0.0\nbicycle 0.0\nbottle 0.0\nbowl 0.0\nboy 0.0\nbridge 9.0\nbus 0.0\nbutterfly 0.0\ncamel 0.0\ncan 0.0\ncastle 1.0\ncaterpillar 0.0\ncattle 3.0\nchair 0.0\nchimpanzee 9.0\nclock 0.0\ncloud 0.0\ncockroach 0.0\ncouch 0.0\ncra 0.0\ncrocodile 0.0\ncup 0.0\ndinosaur 2.0\ndolphin 0.0\nelephant 5.0\nflatfish 0.0\nforest 0.0\nfox 0.0\ngirl 0.0\nhamster 0.0\nhouse 1.0\nkangaroo 2.0\nkeyboard 0.0\nlamp 0.0\nlawn_mower 0.0\nleopard 10.0\nlion 0.0\nlizard 0.0\nlobster 0.0\nman 0.0\nmaple_tree 0.0\nmotorcycle 0.0\nmountain 0.0\nmouse 1.0\nmushroom 1.0\noak_tree 0.0\norange 0.0\norchid 0.0\notter 2.0\npalm_tree 0.0\npear 0.0\npickup_truck 0.0\npine_tree 0.0\nplain 0.0\nplate 0.0\npoppy 0.0\nporcupine 1.0\npossum 4.0\nrabbit 0.0\nraccoon 6.0\nray 0.0\nroad 0.0\nrocket 0.0\nrose 0.0\nsea 0.0\nseal 2.0\nshark 0.0\nshrew 2.0\nskunk 0.0\nskyscraper 0.0\nsnail 0.0\nsnake 0.0\nspider 0.0\nsquirrel 3.0\nstreetcar 0.0\nsunflower 0.0\nsweet_pepper 0.0\ntable 0.0\ntank 1.0\ntelephone 0.0\ntelevision 0.0\ntiger 0.0\ntractor 0.0\ntrain 0.0\ntrout 0.0\ntulip 0.0\nturtle 0.0\nwardrobe 0.0\nwhale 0.0\nwillow_tree 0.0\nwolf 1.0\nwoman 0.0\nworm 0.0\n=================================================\n땡\n\n\n\n\n\n\n틀린 이미지만 확인해보기\n\n\ntemp = (test_y_arg == y_pred_arg)\nfalse_idx = np.where(temp==False)[0]\nfalse_len = len(false_idx)\nfalse_len\n\n6920\n\n\n\nrand_idx = false_idx[np.random.randint(0, false_len)]\ntest_idx = test_y_arg[rand_idx]\npred_idx = y_pred_arg[rand_idx]\nclass_prob = np.floor( y_pred[rand_idx]*100 )\n\nprint(f'idx = {rand_idx}')\nprint(f'해당 인덱스의 이미지는 {label_dict[test_idx]}')\nprint(f'모델의 예측 : {label_dict[pred_idx]}')\nprint(f'모델의 클래스별 확률 : ')\nprint('-------------------')\nfor idx, val in enumerate( list(label_dict.values()) ) :\n    print(val, class_prob[idx])\nprint('=================================================')\n\nif test_y_arg[rand_idx] == y_pred_arg[rand_idx] :\n    print('정답')\nelse :\n    print('땡')\n\nplt.imshow(test_x[rand_idx] )\nplt.show()\n\nidx = 8604\n해당 인덱스의 이미지는 camel\n모델의 예측 : kangaroo\n모델의 클래스별 확률 : \n-------------------\napple 0.0\naquarium_fish 0.0\nbaby 0.0\nbear 0.0\nbeaver 3.0\nbed 0.0\nbee 0.0\nbeetle 0.0\nbicycle 0.0\nbottle 0.0\nbowl 0.0\nboy 0.0\nbridge 0.0\nbus 0.0\nbutterfly 0.0\ncamel 1.0\ncan 0.0\ncastle 0.0\ncaterpillar 0.0\ncattle 12.0\nchair 0.0\nchimpanzee 0.0\nclock 0.0\ncloud 0.0\ncockroach 0.0\ncouch 0.0\ncra 0.0\ncrocodile 0.0\ncup 0.0\ndinosaur 1.0\ndolphin 0.0\nelephant 0.0\nflatfish 0.0\nforest 0.0\nfox 14.0\ngirl 0.0\nhamster 0.0\nhouse 0.0\nkangaroo 39.0\nkeyboard 0.0\nlamp 0.0\nlawn_mower 0.0\nleopard 1.0\nlion 0.0\nlizard 0.0\nlobster 0.0\nman 0.0\nmaple_tree 0.0\nmotorcycle 0.0\nmountain 0.0\nmouse 0.0\nmushroom 0.0\noak_tree 0.0\norange 0.0\norchid 0.0\notter 0.0\npalm_tree 0.0\npear 0.0\npickup_truck 0.0\npine_tree 0.0\nplain 0.0\nplate 0.0\npoppy 0.0\nporcupine 1.0\npossum 0.0\nrabbit 1.0\nraccoon 0.0\nray 0.0\nroad 0.0\nrocket 0.0\nrose 0.0\nsea 0.0\nseal 0.0\nshark 0.0\nshrew 5.0\nskunk 0.0\nskyscraper 0.0\nsnail 0.0\nsnake 0.0\nspider 1.0\nsquirrel 0.0\nstreetcar 0.0\nsunflower 0.0\nsweet_pepper 0.0\ntable 0.0\ntank 0.0\ntelephone 0.0\ntelevision 0.0\ntiger 4.0\ntractor 0.0\ntrain 0.0\ntrout 0.0\ntulip 0.0\nturtle 0.0\nwardrobe 0.0\nwhale 0.0\nwillow_tree 0.0\nwolf 0.0\nwoman 0.0\nworm 0.0\n=================================================\n땡"
  },
  {
    "objectID": "posts/image/2021-02-01-03. ImageAugmentation1.html",
    "href": "posts/image/2021-02-01-03. ImageAugmentation1.html",
    "title": "02. image DA (1)",
    "section": "",
    "text": "from tensorflow.keras.preprocessing.image import load_img\nfrom tensorflow.keras.preprocessing.image import img_to_array\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n\n# !wget -O Batman.webp https://github.com/DrKAI/image/raw/main/Batman01.webp\n!wget -O Batman.jpg https://ichef.bbci.co.uk/news/640/cpsprodpb/C120/production/_104304494_mediaitem104304493.jpg\n\n--2023-09-15 04:59:17--  https://ichef.bbci.co.uk/news/640/cpsprodpb/C120/production/_104304494_mediaitem104304493.jpg\nResolving ichef.bbci.co.uk (ichef.bbci.co.uk)... 23.197.20.140, 2600:141b:e800:1482::f33, 2600:141b:e800:1480::f33, ...\nConnecting to ichef.bbci.co.uk (ichef.bbci.co.uk)|23.197.20.140|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 24770 (24K) [image/jpeg]\nSaving to: ‘Batman.jpg’\n\nBatman.jpg          100%[===================&gt;]  24.19K  --.-KB/s    in 0.02s   \n\n2023-09-15 04:59:17 (1.00 MB/s) - ‘Batman.jpg’ saved [24770/24770]\n\n\n\n\nimage_org = load_img(\"Batman.jpg\")\nimage = img_to_array(image_org)\nimage.shape  # height, width, channel\n\n(360, 640, 3)\n\n\n\nplt.figure(figsize=(12,8))\n# plt.imshow(image)\nplt.imshow(image/255)\nplt.show()\n\n\n\n\n\nimage = np.expand_dims(image, axis=0) # 데이터 개수를 담당할 차원 추가\n\n\nimage.shape\n\n(1, 360, 640, 3)\n\n\n\n\n\n전체 옵션 참고\n\n\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\n\naug = ImageDataGenerator(rotation_range=30,      # 이미지 회전\n                         width_shift_range=0.3,  # 이미지 좌우 이동\n                         height_shift_range=0.3, # 이미지 상하 이동\n                         zoom_range=0.2,         # 확대/축소 범위\n                         shear_range=0.2,        # 비스듬히 늘림\n                         horizontal_flip=True,   # 가로 전환\n                        #  vertical_flip=True,     # 세로 전환\n                         fill_mode='nearest')    # 마지막 옵션 주의하자. 이미지 회전, 이동, 축소할 때 발생하는 공간을 채우는 방식\n\n\nimageGen = aug.flow(image, # 이미지 어레이를 받아서.\n                    batch_size=1,\n                    save_to_dir='output',\n                    save_prefix='image',\n                    save_format='jpg' )\n\n\n!mkdir output\n\nmkdir: cannot create directory ‘output’: File exists\n\n\n\n!ls output\n\n\ntotal = 0\n\nfor image in imageGen:\n    # 루프가 돌면서 이미지가 한장씩 생성된다.\n    total += 1\n    # 20장 채우면 멈추자\n    if total == 20:\n        break\n\n\n!ls output\n\nimage_0_1125.jpg  image_0_3787.jpg  image_0_6552.jpg  image_0_8717.jpg\nimage_0_2228.jpg  image_0_3902.jpg  image_0_6647.jpg  image_0_874.jpg\nimage_0_2764.jpg  image_0_3948.jpg  image_0_7317.jpg  image_0_8943.jpg\nimage_0_3212.jpg  image_0_5149.jpg  image_0_8481.jpg  image_0_9553.jpg\nimage_0_3598.jpg  image_0_6426.jpg  image_0_8573.jpg  image_0_9653.jpg\n\n\n\nimport os\n\n\nplt.figure(figsize=(12,8))\n# plt.imshow(image)   # 차원 추가하여서 실행 X\nplt.imshow(image_org)\nplt.show()\n\n\n\n\n\nrows, cols = 5, 4\nfig, axes = plt.subplots(rows, cols, figsize=(10, 20))\noutput_files = os.listdir('output')\n\nfor idx, ax in enumerate(axes.flat):  # flatten한 axes에 대해 인덱스와 함께 순회\n    img = plt.imread( './output/'+output_files[idx] )\n    ax.imshow( img )\n    ax.axis('off')\n\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "posts/image/2021-02-01-03. ImageAugmentation1.html#imagedatagenerator",
    "href": "posts/image/2021-02-01-03. ImageAugmentation1.html#imagedatagenerator",
    "title": "02. image DA (1)",
    "section": "",
    "text": "전체 옵션 참고\n\n\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\n\naug = ImageDataGenerator(rotation_range=30,      # 이미지 회전\n                         width_shift_range=0.3,  # 이미지 좌우 이동\n                         height_shift_range=0.3, # 이미지 상하 이동\n                         zoom_range=0.2,         # 확대/축소 범위\n                         shear_range=0.2,        # 비스듬히 늘림\n                         horizontal_flip=True,   # 가로 전환\n                        #  vertical_flip=True,     # 세로 전환\n                         fill_mode='nearest')    # 마지막 옵션 주의하자. 이미지 회전, 이동, 축소할 때 발생하는 공간을 채우는 방식\n\n\nimageGen = aug.flow(image, # 이미지 어레이를 받아서.\n                    batch_size=1,\n                    save_to_dir='output',\n                    save_prefix='image',\n                    save_format='jpg' )\n\n\n!mkdir output\n\nmkdir: cannot create directory ‘output’: File exists\n\n\n\n!ls output\n\n\ntotal = 0\n\nfor image in imageGen:\n    # 루프가 돌면서 이미지가 한장씩 생성된다.\n    total += 1\n    # 20장 채우면 멈추자\n    if total == 20:\n        break\n\n\n!ls output\n\nimage_0_1125.jpg  image_0_3787.jpg  image_0_6552.jpg  image_0_8717.jpg\nimage_0_2228.jpg  image_0_3902.jpg  image_0_6647.jpg  image_0_874.jpg\nimage_0_2764.jpg  image_0_3948.jpg  image_0_7317.jpg  image_0_8943.jpg\nimage_0_3212.jpg  image_0_5149.jpg  image_0_8481.jpg  image_0_9553.jpg\nimage_0_3598.jpg  image_0_6426.jpg  image_0_8573.jpg  image_0_9653.jpg\n\n\n\nimport os\n\n\nplt.figure(figsize=(12,8))\n# plt.imshow(image)   # 차원 추가하여서 실행 X\nplt.imshow(image_org)\nplt.show()\n\n\n\n\n\nrows, cols = 5, 4\nfig, axes = plt.subplots(rows, cols, figsize=(10, 20))\noutput_files = os.listdir('output')\n\nfor idx, ax in enumerate(axes.flat):  # flatten한 axes에 대해 인덱스와 함께 순회\n    img = plt.imread( './output/'+output_files[idx] )\n    ax.imshow( img )\n    ax.axis('off')\n\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "posts/image/2021-01-29-01. CNNwithCIFAR10.html",
    "href": "posts/image/2021-01-29-01. CNNwithCIFAR10.html",
    "title": "00. CIFAR10",
    "section": "",
    "text": "Convolutional Neural Network with CIFAR-10\n\n# Import libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nimport random as rd\nfrom sklearn.metrics import accuracy_score\n\nimport tensorflow as tf\nfrom tensorflow import keras\n\n\nData Load\n\n(train_x, train_y), (test_x, test_y) = keras.datasets.cifar10.load_data()\n\nDownloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n170498071/170498071 [==============================] - 36s 0us/step\n\n\n\nprint(train_x.shape, train_y.shape, test_x.shape, test_y.shape)\n\n(50000, 32, 32, 3) (50000, 1) (10000, 32, 32, 3) (10000, 1)\n\n\n\nlabels = {0 : 'Airplane',\n          1 : 'Automobile',\n          2 : 'Bird',\n          3 : 'Cat',\n          4 : 'Deer',\n          5 : 'Dog',\n          6 : 'Frog',\n          7 : 'Horse',\n          8 : 'Ship',\n          9 : 'Truck' }\n\nprint(labels)\n\n{0: 'Airplane', 1: 'Automobile', 2: 'Bird', 3: 'Cat', 4: 'Deer', 5: 'Dog', 6: 'Frog', 7: 'Horse', 8: 'Ship', 9: 'Truck'}\n\n\n\nid = rd.randrange(0,10000)\n\nprint(f'id = {id}')\nprint(f'Image Name: {labels[test_y[id][0]]}')\nplt.imshow(test_x[id])\nplt.show()\n\nid = 1925\nImage Name: Automobile\n\n\n\n\n\n\n\nX변수: Scaling (Standardization)\n\n모든 채널에 Standardization 적용\n\n\nmean_n, std_n = train_x.mean(), train_x.std()\nmean_n, std_n\n\n(120.70756512369792, 64.1500758911213)\n\n\n\ntrain_x = (train_x - mean_n) / std_n\ntest_x = (test_x - mean_n) / std_n\n\n\ntrain_x.mean(), train_x.std()\n\n(-2.5247951877342226e-17, 1.0000000000000022)\n\n\n\n개별 채널에 Standardization 적용\n\n\ntr_r_mean, tr_r_std = train_x[:,:,:,0].mean(), train_x[:,:,:,0].std()\ntr_g_mean, tr_g_std = train_x[:,:,:,1].mean(), train_x[:,:,:,1].std()\ntr_b_mean, tr_b_std = train_x[:,:,:,2].mean(), train_x[:,:,:,2].std()\n\n\ntrain_x_r = (train_x[:,:,:,0] - tr_r_mean) / tr_r_std\ntrain_x_g = (train_x[:,:,:,1] - tr_g_mean) / tr_g_std\ntrain_x_b = (train_x[:,:,:,2] - tr_b_mean) / tr_b_std\n\n\ntrain_x_r.shape, train_x_g.shape, train_x_b.shape\n\n((50000, 32, 32), (50000, 32, 32), (50000, 32, 32))\n\n\n\ntrain_x = np.stack( (train_x_r, train_x_g, train_x_b), axis=3 )\n\n\ntest_x_r = (test_x[:,:,:,0] - tr_r_mean) / tr_r_std\ntest_x_g = (test_x[:,:,:,1] - tr_g_mean) / tr_g_std\ntest_x_b = (test_x[:,:,:,2] - tr_b_mean) / tr_b_std\n\n\ntest_x = np.stack( (test_x_r, test_x_g, test_x_b), axis=3 )\n\n\ntrain_x.shape, test_x.shape\n\n((50000, 32, 32, 3), (10000, 32, 32, 3))\n\n\n\n\nY변수: One-Hot Encoding\n\ntrain_y.shape\n\n(50000, 1)\n\n\n\ntrain_y = np.ravel(train_y)\ntest_y = np.ravel(test_y)\n\n\ntrain_y.shape\n\n(50000,)\n\n\n\nclass_n = len(np.unique(train_y))\n\n\nfrom tensorflow.keras.utils import to_categorical\n\n\ntrain_y = to_categorical(train_y, class_n)\ntest_y = to_categorical(test_y, class_n)\n\n\ntrain_x.shape, train_y.shape\n\n((50000, 32, 32, 3), (50000, 10))\n\n\n\n\nModeling\n\nEarlyStopping 의 옵션 조절\n.fit( )\n.predict( )\n모델 구조\n\nFunctional, Sequential 중 택일\n인풋레이어\nConvolution : 필터수 32개, 사이즈(3, 3), same padding\nConvolution : 필터수 32개, 사이즈(3, 3), same padding\nBatchNormalization\nMaxPooling : 사이즈(2,2) 스트라이드(2,2)\nDropOut : 25% 비활성화\nConvolution : 필터수 64개, 사이즈(3, 3), same padding\nConvolution : 필터수 64개, 사이즈(3, 3), same padding\nBatchNormalization\nMaxPooling : 사이즈(2,2) 스트라이드(2,2)\nDropOut : 25% 비활성화\nFlatten( )\nFully Connected Layer : 노드 1024개\nBatchNormalization\nDropOut : 35% 비활성화\n아웃풋레이어\n\n\n\nimport tensorflow as tf\nfrom tensorflow import keras\n\n\n## Sequential API\n# 1. 세션 클리어 : 메모리에 남아있는 모델 구조를 지워줘!\nkeras.backend.clear_session()\n\n# 2. 모델 발판 생성 : 레이어 블록을 조립할 발판!\nmodel1 = keras.models.Sequential()\n\n# 3. 레이어 블록 조립 : .add( )\n# 인풋레이어\nmodel1.add( keras.layers.Input(shape=(32,32,3)) )\n\n# Convolution : 필터수 32개, 사이즈(3, 3), same padding\nmodel1.add( keras.layers.Conv2D(filters=32,          # 새롭게 제작하려는 feature map의 수! or 서로 다른 filters 수!\n                                kernel_size=(3,3),   # Conv2D 필터의 가로세로 사이즈 # depth는 자동 보정!\n                                strides=(1,1),       # Conv2D 필터의 이동 보폭!\n                                padding='same',      # 1. 이전 feature map 사이즈 유지 | 2. 외곽 정보를 더 반영!\n                                activation='relu',   # 주의!\n                                ) )\n# Convolution : 필터수 32개, 사이즈(3, 3), same padding\nmodel1.add( keras.layers.Conv2D(filters=32,          # 새롭게 제작하려는 feature map의 수! or 서로 다른 filters 수!\n                                kernel_size=(3,3),   # Conv2D 필터의 가로세로 사이즈 # depth는 자동 보정!\n                                strides=(1,1),       # Conv2D 필터의 이동 보폭!\n                                padding='same',      # 1. 이전 feature map 사이즈 유지 | 2. 외곽 정보를 더 반영!\n                                activation='relu',   # 주의!\n                                ) )\n# BatchNormalization\nmodel1.add( keras.layers.BatchNormalization() )\n# MaxPooling : 사이즈(2,2) 스트라이드(2,2)\nmodel1.add( keras.layers.MaxPool2D(pool_size=(2,2),  # Maxpool2D 필터의 가로세로 사이즈\n                                   strides=(2,2)     # Maxpool2D 필터의 이동 보폭! # default는 필터 사이즈를 따름!\n                                   ) )\n# DropOut : 25% 비활성화\nmodel1.add( keras.layers.Dropout(0.25) )\n\n# Convolution : 필터수 64개, 사이즈(3, 3), same padding\nmodel1.add( keras.layers.Conv2D(filters=64,          # 새롭게 제작하려는 feature map의 수! or 서로 다른 filters 수!\n                                kernel_size=(3,3),   # Conv2D 필터의 가로세로 사이즈 # depth는 자동 보정!\n                                strides=(1,1),       # Conv2D 필터의 이동 보폭!\n                                padding='same',      # 1. 이전 feature map 사이즈 유지 | 2. 외곽 정보를 더 반영!\n                                activation='relu',   # 주의!\n                                ) )\n# Convolution : 필터수 64개, 사이즈(3, 3), same padding\nmodel1.add( keras.layers.Conv2D(filters=64,          # 새롭게 제작하려는 feature map의 수! or 서로 다른 filters 수!\n                                kernel_size=(3,3),   # Conv2D 필터의 가로세로 사이즈 # depth는 자동 보정!\n                                strides=(1,1),       # Conv2D 필터의 이동 보폭!\n                                padding='same',      # 1. 이전 feature map 사이즈 유지 | 2. 외곽 정보를 더 반영!\n                                activation='relu',   # 주의!\n                                ) )\n# BatchNormalization\nmodel1.add( keras.layers.BatchNormalization() )\n# MaxPooling : 사이즈(2,2) 스트라이드(2,2)\nmodel1.add( keras.layers.MaxPool2D(pool_size=(2,2),  # Maxpool2D 필터의 가로세로 사이즈\n                                   strides=(2,2)     # Maxpool2D 필터의 이동 보폭! # default는 필터 사이즈를 따름!\n                                   ) )\n# DropOut : 25% 비활성화\nmodel1.add( keras.layers.Dropout(0.25) )\n\n# Flatten( )\nmodel1.add( keras.layers.Flatten() )\n# Fully Connected Layer : 노드 1024개\nmodel1.add( keras.layers.Dense(1024, activation='relu') )\n# BatchNormalization\nmodel1.add( keras.layers.BatchNormalization() )\n# DropOut : 35% 비활성화\nmodel1.add( keras.layers.Dropout(0.35) )\n# 아웃풋레이어\nmodel1.add( keras.layers.Dense(10, activation='softmax') )\n\n# 4. 컴파일\nmodel1.compile(optimizer='adam',\n               loss=keras.losses.categorical_crossentropy,\n               metrics=['accuracy']\n               )\n\n\nmodel1.summary()\n\nModel: \"sequential\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n conv2d (Conv2D)             (None, 32, 32, 32)        896       \n                                                                 \n conv2d_1 (Conv2D)           (None, 32, 32, 32)        9248      \n                                                                 \n batch_normalization (Batch  (None, 32, 32, 32)        128       \n Normalization)                                                  \n                                                                 \n max_pooling2d (MaxPooling2  (None, 16, 16, 32)        0         \n D)                                                              \n                                                                 \n dropout (Dropout)           (None, 16, 16, 32)        0         \n                                                                 \n conv2d_2 (Conv2D)           (None, 16, 16, 64)        18496     \n                                                                 \n conv2d_3 (Conv2D)           (None, 16, 16, 64)        36928     \n                                                                 \n batch_normalization_1 (Bat  (None, 16, 16, 64)        256       \n chNormalization)                                                \n                                                                 \n max_pooling2d_1 (MaxPoolin  (None, 8, 8, 64)          0         \n g2D)                                                            \n                                                                 \n dropout_1 (Dropout)         (None, 8, 8, 64)          0         \n                                                                 \n flatten (Flatten)           (None, 4096)              0         \n                                                                 \n dense (Dense)               (None, 1024)              4195328   \n                                                                 \n batch_normalization_2 (Bat  (None, 1024)              4096      \n chNormalization)                                                \n                                                                 \n dropout_2 (Dropout)         (None, 1024)              0         \n                                                                 \n dense_1 (Dense)             (None, 10)                10250     \n                                                                 \n=================================================================\nTotal params: 4275626 (16.31 MB)\nTrainable params: 4273386 (16.30 MB)\nNon-trainable params: 2240 (8.75 KB)\n_________________________________________________________________\n\n\n\nfrom tensorflow.keras.backend import clear_session\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input, Dense, Flatten, BatchNormalization, Dropout\nfrom tensorflow.keras.layers import Conv2D, MaxPool2D\nfrom tensorflow.keras.losses import categorical_crossentropy\n\n\n## Functional API\n# 1. 세션 클리어 : 청소\nclear_session()\n\n# 2. 레이어 사슬처럼 엮기\n# 인풋레이어\nil = Input(shape=(32,32,3))\n# Convolution : 필터수 32개, 사이즈(3, 3), same padding\nhl = Conv2D(filters=32,         # 새롭게 제작하려는 feature map의 수! 혹은 서로 다른 필터 32개 사용!\n            kernel_size=(3,3),  # Conv2D 필터의 가로세로 사이즈!\n            strides=(1,1),      # Conv2D 필터의 이동 보폭!\n            padding='same',     # 1.이전 feature map 사이즈 보존! 2. 외곽 정보 더 반영!\n            activation='relu'\n            )(il)               # 주의!!!\n# Convolution : 필터수 32개, 사이즈(3, 3), same padding\nhl = Conv2D(filters=32,         # 새롭게 제작하려는 feature map의 수! 혹은 서로 다른 필터 32개 사용!\n            kernel_size=(3,3),  # Conv2D 필터의 가로세로 사이즈!\n            strides=(1,1),      # Conv2D 필터의 이동 보폭!\n            padding='same',     # 1.이전 feature map 사이즈 보존! 2. 외곽 정보 더 반영!\n            activation='relu'\n            )(hl)               # 주의!!!\n# BatchNormalization\nhl = BatchNormalization()(hl)\n# MaxPooling : 사이즈(2,2) 스트라이드(2,2)\nhl = MaxPool2D(pool_size=(2,2), # Maxpool2D 필터의 가로세로 사이즈!\n               strides=(2,2)    # Maxpool2D 필터의 이동 보폭! 기본적으로 필터 사이즈를 따름!\n               )(hl)\n# DropOut : 25% 비활성화\nhl = Dropout(0.25)(hl)\n\n# Convolution : 필터수 64개, 사이즈(3, 3), same padding\nhl = Conv2D(filters=64,         # 새롭게 제작하려는 feature map의 수! 혹은 서로 다른 필터 32개 사용!\n            kernel_size=(3,3),  # Conv2D 필터의 가로세로 사이즈!\n            strides=(1,1),      # Conv2D 필터의 이동 보폭!\n            padding='same',     # 1.이전 feature map 사이즈 보존! 2. 외곽 정보 더 반영!\n            activation='relu'\n            )(hl)               # 주의!!!\n# Convolution : 필터수 64개, 사이즈(3, 3), same padding\nhl = Conv2D(filters=64,         # 새롭게 제작하려는 feature map의 수! 혹은 서로 다른 필터 32개 사용!\n            kernel_size=(3,3),  # Conv2D 필터의 가로세로 사이즈!\n            strides=(1,1),      # Conv2D 필터의 이동 보폭!\n            padding='same',     # 1.이전 feature map 사이즈 보존! 2. 외곽 정보 더 반영!\n            activation='relu'\n            )(hl)               # 주의!!!\n# BatchNormalization\nhl = BatchNormalization()(hl)\n# MaxPooling : 사이즈(2,2) 스트라이드(2,2)\nhl = MaxPool2D(pool_size=(2,2), # Maxpool2D 필터의 가로세로 사이즈!\n               strides=(2,2)    # Maxpool2D 필터의 이동 보폭! 기본적으로 필터 사이즈를 따름!\n               )(hl)\n# DropOut : 25% 비활성화\nhl = Dropout(0.25)(hl)\n\n# Flatten( )\nhl = Flatten()(hl)\n# Fully Connected Layer : 노드 1024개\nhl = Dense(1024, activation='relu')(hl)\n# BatchNormalization\nhl = BatchNormalization()(hl)\n# DropOut : 35% 비활성화\nhl = Dropout(0.35)(hl)\n# 아웃풋레이어\nol = Dense(10, activation='softmax')(hl)\n\n# 3. 모델의 시작과 끝 지정\nmodel2 = Model(il, ol)\n\n# 4. 컴파일\nmodel2.compile(optimizer='adam',\n               loss=categorical_crossentropy,\n               metrics=['accuracy']\n               )\n\n\nmodel2.summary()\n\nModel: \"model\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n input_1 (InputLayer)        [(None, 32, 32, 3)]       0         \n                                                                 \n conv2d (Conv2D)             (None, 32, 32, 32)        896       \n                                                                 \n conv2d_1 (Conv2D)           (None, 32, 32, 32)        9248      \n                                                                 \n batch_normalization (Batch  (None, 32, 32, 32)        128       \n Normalization)                                                  \n                                                                 \n max_pooling2d (MaxPooling2  (None, 16, 16, 32)        0         \n D)                                                              \n                                                                 \n dropout (Dropout)           (None, 16, 16, 32)        0         \n                                                                 \n conv2d_2 (Conv2D)           (None, 16, 16, 64)        18496     \n                                                                 \n conv2d_3 (Conv2D)           (None, 16, 16, 64)        36928     \n                                                                 \n batch_normalization_1 (Bat  (None, 16, 16, 64)        256       \n chNormalization)                                                \n                                                                 \n max_pooling2d_1 (MaxPoolin  (None, 8, 8, 64)          0         \n g2D)                                                            \n                                                                 \n dropout_1 (Dropout)         (None, 8, 8, 64)          0         \n                                                                 \n flatten (Flatten)           (None, 4096)              0         \n                                                                 \n dense (Dense)               (None, 1024)              4195328   \n                                                                 \n batch_normalization_2 (Bat  (None, 1024)              4096      \n chNormalization)                                                \n                                                                 \n dropout_2 (Dropout)         (None, 1024)              0         \n                                                                 \n dense_1 (Dense)             (None, 10)                10250     \n                                                                 \n=================================================================\nTotal params: 4275626 (16.31 MB)\nTrainable params: 4273386 (16.30 MB)\nNon-trainable params: 2240 (8.75 KB)\n_________________________________________________________________\n\n\n\nfrom tensorflow.keras.callbacks import EarlyStopping\n\n\nes = EarlyStopping(monitor='val_loss',     # 얼리스토핑을 적용할 대상!\n                   min_delta=0,            # Threshold. 이보다 크게 변화해야 성능 개선 간주!\n                   patience=3,             # 성능 개선이 발생하지 않을 때, 몇 epochs 더 볼 것인지!\n                   verbose=1,              # 어느 epoch가 최적인지 알려줌!\n                   restore_best_weights=True # 얼리스토핑으로 학습이 멈췄을 때, 최적의 가중치를 가진 시점으로 돌려줌!\n                   )\n\n\nmodel2.fit(train_x, train_y, epochs=10000, verbose=1,\n           validation_split=0.2,   # 매 epoch마다 training set에서 20%를 validation으로 지정!\n           callbacks=[es]          # 얼리스토핑 적용!\n           )\n\nEpoch 1/10000\n1250/1250 [==============================] - 23s 8ms/step - loss: 1.5644 - accuracy: 0.4883 - val_loss: 1.1193 - val_accuracy: 0.6283\nEpoch 2/10000\n1250/1250 [==============================] - 9s 7ms/step - loss: 1.0641 - accuracy: 0.6286 - val_loss: 0.8881 - val_accuracy: 0.6901\nEpoch 3/10000\n1250/1250 [==============================] - 9s 7ms/step - loss: 0.9226 - accuracy: 0.6790 - val_loss: 0.9034 - val_accuracy: 0.6921\nEpoch 4/10000\n1250/1250 [==============================] - 10s 8ms/step - loss: 0.8170 - accuracy: 0.7150 - val_loss: 0.8299 - val_accuracy: 0.7211\nEpoch 5/10000\n1250/1250 [==============================] - 10s 8ms/step - loss: 0.7404 - accuracy: 0.7428 - val_loss: 0.7956 - val_accuracy: 0.7306\nEpoch 6/10000\n1250/1250 [==============================] - 9s 7ms/step - loss: 0.6906 - accuracy: 0.7589 - val_loss: 0.7729 - val_accuracy: 0.7436\nEpoch 7/10000\n1250/1250 [==============================] - 10s 8ms/step - loss: 0.6233 - accuracy: 0.7829 - val_loss: 0.6676 - val_accuracy: 0.7739\nEpoch 8/10000\n1250/1250 [==============================] - 9s 8ms/step - loss: 0.5692 - accuracy: 0.8009 - val_loss: 0.6594 - val_accuracy: 0.7831\nEpoch 9/10000\n1250/1250 [==============================] - 9s 7ms/step - loss: 0.5153 - accuracy: 0.8210 - val_loss: 0.6843 - val_accuracy: 0.7760\nEpoch 10/10000\n1250/1250 [==============================] - 9s 7ms/step - loss: 0.4761 - accuracy: 0.8338 - val_loss: 0.6373 - val_accuracy: 0.7886\nEpoch 11/10000\n1250/1250 [==============================] - 10s 8ms/step - loss: 0.4448 - accuracy: 0.8424 - val_loss: 0.8425 - val_accuracy: 0.7519\nEpoch 12/10000\n1250/1250 [==============================] - 9s 7ms/step - loss: 0.3841 - accuracy: 0.8635 - val_loss: 0.6361 - val_accuracy: 0.7977\nEpoch 13/10000\n1250/1250 [==============================] - 10s 8ms/step - loss: 0.3479 - accuracy: 0.8777 - val_loss: 0.7693 - val_accuracy: 0.7677\nEpoch 14/10000\n1250/1250 [==============================] - 9s 8ms/step - loss: 0.3538 - accuracy: 0.8752 - val_loss: 0.6934 - val_accuracy: 0.7936\nEpoch 15/10000\n1248/1250 [============================&gt;.] - ETA: 0s - loss: 0.3086 - accuracy: 0.8913Restoring model weights from the end of the best epoch: 12.\n1250/1250 [==============================] - 10s 8ms/step - loss: 0.3088 - accuracy: 0.8912 - val_loss: 0.6732 - val_accuracy: 0.7962\nEpoch 15: early stopping\n\n\n&lt;keras.src.callbacks.History at 0x797b3cb59630&gt;\n\n\n\n\nVisualization\n\n# 원핫 인코딩 해제 : 카테고리 중 가장 높은 값\ntrain_y = train_y.argmax(axis=1)\ntest_y = test_y.argmax(axis=1)\n\n\npred_train = model2.predict(train_x)\npred_test = model2.predict(test_x)\n\nsingle_pred_train = pred_train.argmax(axis=1)\nsingle_pred_test = pred_test.argmax(axis=1)\n\nlogi_train_accuracy = accuracy_score(train_y, single_pred_train)\nlogi_test_accuracy = accuracy_score(test_y, single_pred_test)\n\nprint('CNN')\nprint(f'트레이닝 정확도 : {logi_train_accuracy*100:.2f}%')\nprint(f'테스트 정확도 : {logi_test_accuracy*100:.2f}%')\n\n1563/1563 [==============================] - 3s 2ms/step\n313/313 [==============================] - 1s 3ms/step\nCNN\n트레이닝 정확도 : 92.97%\n테스트 정확도 : 79.27%\n\n\n\nid = rd.randrange(0,10000)\n\nprint(f'id = {id}')\nprint(f'다음 그림은 {labels[test_y[id]]} 입니다.')\nprint(f'모델의 예측 : {labels[single_pred_test[id]]}')\n\nprob = np.floor(pred_test[id]*100).tolist()\nprob_dict = {}\n\nfor idx, prob in enumerate(prob) :\n    prob_dict[ labels[idx] ] = prob\n\nprint('모델의 카테고리별 확률 : ')\nprint(prob_dict)\n\nif test_y[id] == single_pred_test[id] :\n    print('정답입니다')\nelse :\n    print('틀렸어요')\n\nplt.imshow(test_x[id].reshape([32,32,-1]))\nplt.show()\n\nWARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n\n\nid = 9649\n다음 그림은 Dog 입니다.\n모델의 예측 : Dog\n모델의 카테고리별 확률 : \n{'Airplane': 0.0, 'Automobile': 0.0, 'Bird': 0.0, 'Cat': 24.0, 'Deer': 0.0, 'Dog': 74.0, 'Frog': 0.0, 'Horse': 0.0, 'Ship': 0.0, 'Truck': 0.0}\n정답입니다\n\n\n\n\n\n\n'''\n틀린 것만 관찰해보기\n\n'''\n\ntrue_false = (test_y == single_pred_test)\nf_id = np.where(true_false == False)[0]\nf_n = len(f_id)\n\nid = f_id[rd.randrange(0,f_n)]\n\n\nprint(f'id = {id}')\nprint(f'다음 그림은 {labels[test_y[id]]} 입니다.')\nprint(f'모델의 예측 : {labels[single_pred_test[id]]}')\n\nprob = np.floor(pred_test[id]*100).tolist()\nprob_dict = {}\n\nfor idx, prob in enumerate(prob) :\n    prob_dict[ labels[idx] ] = prob\n\nprint('모델의 카테고리별 확률 : ')\nprint(prob_dict)\n\nif test_y[id] == single_pred_test[id] :\n    print('정답입니다')\nelse :\n    print('틀렸어요')\n\nplt.imshow(test_x[id].reshape([32,32,-1]))\nplt.show()\n\nWARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n\n\nid = 685\n다음 그림은 Frog 입니다.\n모델의 예측 : Bird\n모델의 카테고리별 확률 : \n{'Airplane': 0.0, 'Automobile': 0.0, 'Bird': 75.0, 'Cat': 7.0, 'Deer': 15.0, 'Dog': 0.0, 'Frog': 0.0, 'Horse': 0.0, 'Ship': 0.0, 'Truck': 0.0}\n틀렸어요"
  },
  {
    "objectID": "posts/basic/2023-11-01-02. iris.html",
    "href": "posts/basic/2023-11-01-02. iris.html",
    "title": "02. iris",
    "section": "",
    "text": "import seaborn as sns\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nplt.rcParams['font.family'] = \"Malgun Gothic\"\nplt.rcParams['axes.unicode_minus'] = False\n\n\niris = sns.load_dataset(\"iris\")\n\n\niris.head()\n\n\n\n\n\n\n\n\nsepal_length\nsepal_width\npetal_length\npetal_width\nspecies\n\n\n\n\n0\n5.1\n3.5\n1.4\n0.2\nsetosa\n\n\n1\n4.9\n3.0\n1.4\n0.2\nsetosa\n\n\n2\n4.7\n3.2\n1.3\n0.2\nsetosa\n\n\n3\n4.6\n3.1\n1.5\n0.2\nsetosa\n\n\n4\n5.0\n3.6\n1.4\n0.2\nsetosa"
  },
  {
    "objectID": "posts/basic/2023-11-01-02. iris.html#species-분포-확인",
    "href": "posts/basic/2023-11-01-02. iris.html#species-분포-확인",
    "title": "02. iris",
    "section": "(1) species 분포 확인",
    "text": "(1) species 분포 확인\n- barplot\n\nplt.figure(figsize = (4,4))\nsns.countplot(x = \"species\", data = iris )\nplt.show()\n\n\n\n\n- scatterplot\n\nsns.scatterplot(x = \"sepal_length\", y = \"petal_length\", hue = \"species\", data = iris)\n\n&lt;Axes: xlabel='sepal_length', ylabel='petal_length'&gt;"
  },
  {
    "objectID": "posts/basic/2023-11-01-02. iris.html#species-라벨-인코딩",
    "href": "posts/basic/2023-11-01-02. iris.html#species-라벨-인코딩",
    "title": "02. iris",
    "section": "(1) species 라벨 인코딩",
    "text": "(1) species 라벨 인코딩\n\nfrom sklearn.preprocessing import LabelEncoder\n\n\nle = LabelEncoder()\ny = le.fit_transform(y)\nprint(le.classes_)\n\n['setosa' 'versicolor' 'virginica']"
  },
  {
    "objectID": "posts/basic/2023-11-01-02. iris.html#tree",
    "href": "posts/basic/2023-11-01-02. iris.html#tree",
    "title": "02. iris",
    "section": "(1) tree",
    "text": "(1) tree\n\nfrom sklearn.tree import DecisionTreeClassifier\n\ntree = DecisionTreeClassifier(max_depth=5)\n\ntree.fit(X, y)\n\ntree_pred = tree.predict(X)\n\nfrom sklearn.metrics import *\n\naccuracy_score(y, tree_pred)\n\n1.0"
  },
  {
    "objectID": "posts/basic/2023-11-01-02. iris.html#rf",
    "href": "posts/basic/2023-11-01-02. iris.html#rf",
    "title": "02. iris",
    "section": "(2) RF",
    "text": "(2) RF\n\nfrom sklearn.ensemble import RandomForestClassifier\n\nrf = RandomForestClassifier(max_depth = 5, n_estimators = 10)\n\nrf.fit(X, y)\n\nrf_pred = rf.predict(X)\n\naccuracy_score(y, rf_pred)\n\n0.98\n\n\n\npredict 후 라벨 추출\n\nle.classes_\n\narray(['setosa', 'versicolor', 'virginica'], dtype=object)\n\n\n\nle.classes_[rf.predict([X[50]])[0]]\n\n'versicolor'"
  },
  {
    "objectID": "posts/basic/2023-10-30-00. Churn.html",
    "href": "posts/basic/2023-10-30-00. Churn.html",
    "title": "00. Churn",
    "section": "",
    "text": "import pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport plotly.express as px\nimport plotly.io as pio\npio.renderers.default = \"plotly_mimetype+notebook_connected\"\nimport scipy.stats as spst\nimport seaborn as sns"
  },
  {
    "objectID": "posts/basic/2023-10-30-00. Churn.html#드라이브-마운트",
    "href": "posts/basic/2023-10-30-00. Churn.html#드라이브-마운트",
    "title": "00. Churn",
    "section": "드라이브 마운트",
    "text": "드라이브 마운트\n\nfrom google.colab import drive\ndrive.mount('/content/drive')\n\nDrive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n\n\n\ncd /content/drive/MyDrive/Colab Notebooks/DX/AICE\n\n/content/drive/MyDrive/Colab Notebooks/DX/AICE"
  },
  {
    "objectID": "posts/basic/2023-10-30-00. Churn.html#데이터-로드",
    "href": "posts/basic/2023-10-30-00. Churn.html#데이터-로드",
    "title": "00. Churn",
    "section": "데이터 로드",
    "text": "데이터 로드\n\ndf = pd.read_csv(\"data_v1.csv\")\ndf.head()\n\n\n  \n    \n\n\n\n\n\n\ncustomerID\ngender\nSeniorCitizen\nPartner\nDependents\ntenure\nPhoneService\nMultipleLines\nInternetService\nOnlineSecurity\n...\nDeviceProtection\nTechSupport\nStreamingTV\nStreamingMovies\nContract\nPaperlessBilling\nPaymentMethod\nMonthlyCharges\nTotalCharges\nChurn\n\n\n\n\n0\n7590-VHVEG\nNaN\n0.0\nYes\nNo\n1\nNo\nNo phone service\nDSL\nNo\n...\nNo\nNo\nNo\nNo\nNaN\nYes\nElectronic check\n29.85\n29.85\nNo\n\n\n1\n5575-GNVDE\nMale\n0.0\nNo\nNo\n34\nYes\nNo\nDSL\nYes\n...\nYes\nNo\nNo\nNo\nOne year\nNo\nMailed check\n56.95\n1889.5\nNo\n\n\n2\n3668-QPYBK\nMale\n0.0\nNo\nNo\n2\nYes\nNo\nDSL\nYes\n...\nNaN\nNo\nNo\nNo\nMonth-to-month\nYes\nMailed check\n53.85\n108.15\nYes\n\n\n3\n7795-CFOCW\nMale\n0.0\nNo\nNo\n45\nNo\nNo phone service\nDSL\nYes\n...\nNaN\nYes\nNo\nNo\nOne year\nNo\nBank transfer (automatic)\n42.30\n1840.75\nNo\n\n\n4\n9237-HQITU\nFemale\n0.0\nNo\nNo\n2\nYes\nNo\nFiber optic\nNo\n...\nNaN\nNo\nNo\nNo\nMonth-to-month\nYes\nElectronic check\n70.70\n151.65\nYes\n\n\n\n\n\n5 rows × 21 columns\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n\n  \n\n\n    \n        \n    \n\n  \n\n\n\n  \n\n    \n  \n\n\n\ndf.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 7043 entries, 0 to 7042\nData columns (total 21 columns):\n #   Column            Non-Null Count  Dtype  \n---  ------            --------------  -----  \n 0   customerID        7043 non-null   object \n 1   gender            7034 non-null   object \n 2   SeniorCitizen     7042 non-null   float64\n 3   Partner           7043 non-null   object \n 4   Dependents        7041 non-null   object \n 5   tenure            7043 non-null   int64  \n 6   PhoneService      7040 non-null   object \n 7   MultipleLines     7043 non-null   object \n 8   InternetService   7043 non-null   object \n 9   OnlineSecurity    7043 non-null   object \n 10  OnlineBackup      7043 non-null   object \n 11  DeviceProtection  3580 non-null   object \n 12  TechSupport       7043 non-null   object \n 13  StreamingTV       7043 non-null   object \n 14  StreamingMovies   7043 non-null   object \n 15  Contract          7042 non-null   object \n 16  PaperlessBilling  7043 non-null   object \n 17  PaymentMethod     7042 non-null   object \n 18  MonthlyCharges    7042 non-null   float64\n 19  TotalCharges      7043 non-null   object \n 20  Churn             7043 non-null   object \ndtypes: float64(2), int64(1), object(18)\nmemory usage: 1.1+ MB"
  },
  {
    "objectID": "posts/basic/2023-10-30-00. Churn.html#eda-exploratory-data-analysis",
    "href": "posts/basic/2023-10-30-00. Churn.html#eda-exploratory-data-analysis",
    "title": "00. Churn",
    "section": "EDA (Exploratory Data Analysis)",
    "text": "EDA (Exploratory Data Analysis)\n\n결측치 확인\n\ndf.isnull().sum()\n\ncustomerID             0\ngender                 9\nSeniorCitizen          1\nPartner                0\nDependents             2\ntenure                 0\nPhoneService           3\nMultipleLines          0\nInternetService        0\nOnlineSecurity         0\nOnlineBackup           0\nDeviceProtection    3463\nTechSupport            0\nStreamingTV            0\nStreamingMovies        0\nContract               1\nPaperlessBilling       0\nPaymentMethod          1\nMonthlyCharges         1\nTotalCharges           0\nChurn                  0\ndtype: int64\n\n\n\n\n통계 정보 확인\n\ndf.describe().T\n\n\n  \n    \n\n\n\n\n\n\ncount\nmean\nstd\nmin\n25%\n50%\n75%\nmax\n\n\n\n\nSeniorCitizen\n7042.0\n0.162170\n0.368633\n0.00\n0.0\n0.00\n0.00\n1.00\n\n\ntenure\n7043.0\n32.371149\n24.559481\n0.00\n9.0\n29.00\n55.00\n72.00\n\n\nMonthlyCharges\n7042.0\n64.763256\n30.091898\n18.25\n35.5\n70.35\n89.85\n118.75\n\n\n\n\n\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n\n  \n\n\n    \n        \n    \n\n  \n\n\n\n  \n\n    \n  \n\n\n\n\n전처리 수행\n\ncustomerID 컬럼을 삭제\n\n\ndf.drop(\"customerID\", axis = 1, inplace = True)\n\n\n확인\n\n\n\"customreID\" in df.columns\n\nFalse\n\n\n\nTotalCharges 컬럼의 타입을 object에서 float으로 변환\n\n\n[float(i)   for i in  df.TotalCharges][:5] ##\n\nValueError: ignored\n\n\n\n공백이 있어 error가 뜬다.\n\n\ndf.TotalCharges =  df.TotalCharges.replace(\" \", 0).replace(\"\",0)\n\n\ndf.TotalCharges = [float(i)   for i in  df.TotalCharges]\n\n\ndf.TotalCharges ## 실수형으로 바뀐 것을 확인\n\n0         29.85\n1       1889.50\n2        108.15\n3       1840.75\n4        151.65\n         ...   \n7038    1990.50\n7039    7362.90\n7040     346.45\n7041     306.60\n7042    6844.50\nName: TotalCharges, Length: 7043, dtype: float64\n\n\n- Churn 컬럼의 문자열 값을 숫자로 변경\n\ndf.Churn = df.Churn.replace([\"Yes\",\"No\"],[1,0])\ndf.Churn.dtypes\n\ndtype('int64')\n\n\n- 컬럼별로 null값이 얼마나 있는지 확인\n\ndf.isnull().sum()[df.isnull().sum() !=0]\n\ngender                 9\nSeniorCitizen          1\nDependents             2\nPhoneService           3\nDeviceProtection    3463\nContract               1\nPaymentMethod          1\nMonthlyCharges         1\ndtype: int64\n\n\n- 결측치가 많은 DeviceProtection 열을 제거\n\ndf.drop(\"DeviceProtection\", axis = 1, inplace = True)\ndf.isnull().sum()[df.isnull().sum() !=0]\n\ngender            9\nSeniorCitizen     1\nDependents        2\nPhoneService      3\nContract          1\nPaymentMethod     1\nMonthlyCharges    1\ndtype: int64\n\n\n\n\n시각화\n\nObject 컬럼을 하나씩 가져와서 Bar chart 그리기\n\n\no_col = df.select_dtypes(\"O\").columns.values\nlen(o_col)\n\n14\n\n\n\nfig, axes = plt.subplots(7, 2, figsize = (14, 20))\no_col = o_col.reshape(7,-1)\n\nfor i in range(7) :\n  for j in range(2) :\n      sns.countplot(x = o_col[i][j], data = df, ax = axes[i][j])\n      axes[i][j].set_title(o_col[i][j])\nfig.tight_layout()\n\n\n\n\n\n\n불균형이 심한 열(PhoneService)삭제\n\ndf.drop(\"PhoneService\", axis = 1, inplace = True)\n\"PhoneService\"  in  df.columns\n\nFalse\n\n\n\n\ntarget 변수 분포 파악\n\nsns.countplot(x = \"Churn\", data = df)\nplt.title(\"Churn\")\n\nText(0.5, 1.0, 'Churn')\n\n\n\n\n\n- target 변수의 분포 확인 결과 불균형을 보인다.\n\n\nSeniorCitizen 열 분포 확인\n\nsns.countplot(x = \"SeniorCitizen\", data = df)\nplt.title(\"SeniorCitizen\")\nplt.show()\n\n\n\n\n- 불균형이 심하므로 삭제\n\ndf.drop(\"SeniorCitizen\", axis = 1, inplace = True)\n\"SeniorCitizen\"  in  df.columns\n\nFalse\n\n\n\n\ntenure 열의 분포 확인\n\nfig, axes = plt.subplots(1, 2, figsize = (12, 4))\nax1, ax2 = axes\n\nsns.histplot(x= \"tenure\", data = df, hue = \"Churn\", ax = ax1)\nsns.kdeplot(x= \"tenure\", data = df, hue = \"Churn\", ax = ax2)\n\nfig.tight_layout()\nfig.show()\n\n\n\n\n\n\nTotalCharges 열의 분포 확인\n\nfig, axes = plt.subplots(1, 2, figsize = (12, 4))\nax1, ax2 = axes\n\nsns.histplot(x= \"TotalCharges\", data = df, hue = \"Churn\", ax = ax1)\nsns.kdeplot(x= \"TotalCharges\", data = df, hue = \"Churn\", ax = ax2)\n\nfig.tight_layout()\nfig.show()\n\n\n\n\n### MultipleLines 분포 확인\n\nsns.countplot(x = \"MultipleLines\", data = df, hue = \"Churn\")\nplt.show()\n\n\n\n\n\n\n상관관계 분석\n\ntenure, MonthlyCharges, TotalCharges 컬럼간의 상관관계를 heatmap으로 그려보시오.\n\n\nc_col = ['tenure', 'MonthlyCharges', 'TotalCharges']\n\n\nsns.heatmap(df[c_col].corr(),\n                        annot = True,\n                        fmt = \".2f\")\nfig.show()\n\n\n\n\n\ndf[c_col].corr()\n\n\n  \n    \n\n\n\n\n\n\ntenure\nMonthlyCharges\nTotalCharges\n\n\n\n\ntenure\n1.000000\n0.247871\n0.826178\n\n\nMonthlyCharges\n0.247871\n1.000000\n0.651167\n\n\nTotalCharges\n0.826178\n0.651167\n1.000000\n\n\n\n\n\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n\n  \n\n\n    \n        \n    \n\n  \n\n\n\n  \n\n    \n  \n\n\n\n\nTotalCharges boxplot\n\nsns.boxplot(x = \"Churn\", y= \"TotalCharges\", data = df)\nplt.show()\n\n\n\n\n\n\n결과저장\n\ndf.to_csv(\"data_v1_save.csv\", index = False)\n\n\n\n다시 불러와서 확인\n\npd.read_csv(\"data_v1_save.csv\").shape\n\n(7043, 17)"
  },
  {
    "objectID": "posts/basic/2023-10-30-00. Churn.html#더미변수-변환",
    "href": "posts/basic/2023-10-30-00. Churn.html#더미변수-변환",
    "title": "00. Churn",
    "section": "더미변수 변환",
    "text": "더미변수 변환\n\ndf = pd.read_csv(\"data_v1_save.csv\")\n\n\ndf = df.dropna()\n\n\nd_col = df.select_dtypes(\"O\").columns.values\nd_col\n\narray(['gender', 'Partner', 'Dependents', 'MultipleLines',\n       'InternetService', 'OnlineSecurity', 'OnlineBackup', 'TechSupport',\n       'StreamingTV', 'StreamingMovies', 'Contract', 'PaperlessBilling',\n       'PaymentMethod'], dtype=object)\n\n\n\ndf1 = pd.get_dummies(data = df, columns = d_col, drop_first = True)\ndf1.select_dtypes(\"O\").columns.values\n\narray([], dtype=object)\n\n\n\ndf1.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nInt64Index: 7030 entries, 1 to 7041\nData columns (total 27 columns):\n #   Column                                 Non-Null Count  Dtype  \n---  ------                                 --------------  -----  \n 0   tenure                                 7030 non-null   int64  \n 1   MonthlyCharges                         7030 non-null   float64\n 2   TotalCharges                           7030 non-null   float64\n 3   Churn                                  7030 non-null   int64  \n 4   gender_Male                            7030 non-null   uint8  \n 5   Partner_Yes                            7030 non-null   uint8  \n 6   Dependents_Yes                         7030 non-null   uint8  \n 7   MultipleLines_No phone service         7030 non-null   uint8  \n 8   MultipleLines_Yes                      7030 non-null   uint8  \n 9   InternetService_Fiber optic            7030 non-null   uint8  \n 10  InternetService_No                     7030 non-null   uint8  \n 11  OnlineSecurity_No internet service     7030 non-null   uint8  \n 12  OnlineSecurity_Yes                     7030 non-null   uint8  \n 13  OnlineBackup_No internet service       7030 non-null   uint8  \n 14  OnlineBackup_Yes                       7030 non-null   uint8  \n 15  TechSupport_No internet service        7030 non-null   uint8  \n 16  TechSupport_Yes                        7030 non-null   uint8  \n 17  StreamingTV_No internet service        7030 non-null   uint8  \n 18  StreamingTV_Yes                        7030 non-null   uint8  \n 19  StreamingMovies_No internet service    7030 non-null   uint8  \n 20  StreamingMovies_Yes                    7030 non-null   uint8  \n 21  Contract_One year                      7030 non-null   uint8  \n 22  Contract_Two year                      7030 non-null   uint8  \n 23  PaperlessBilling_Yes                   7030 non-null   uint8  \n 24  PaymentMethod_Credit card (automatic)  7030 non-null   uint8  \n 25  PaymentMethod_Electronic check         7030 non-null   uint8  \n 26  PaymentMethod_Mailed check             7030 non-null   uint8  \ndtypes: float64(2), int64(2), uint8(23)\nmemory usage: 432.5 KB\n\n\n\ndf1.to_csv(\"전처리완료.csv\",index= False)"
  },
  {
    "objectID": "posts/basic/2023-10-30-00. Churn.html#훈련-평가-데이터-분리",
    "href": "posts/basic/2023-10-30-00. Churn.html#훈련-평가-데이터-분리",
    "title": "00. Churn",
    "section": "훈련, 평가 데이터 분리",
    "text": "훈련, 평가 데이터 분리\n\ntarget = \"Churn\"\n\nX = df1.drop(target, axis = 1)\ny = df1[target]\n\n\n# 입력 : X, y\n# Train : Test 비율 = 7:3\n# y Class 비율을 유지하면서 나누기 : stratify=y\n# 여러 번 수행해도 같은 결과 나오게 고정 : random_state=42\n# 결과 : X_train, X_test, y_train, y_test\n\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size =0.3, stratify = y, random_state = 42 )\n\n\nX_train.shape\n\n(4921, 26)\n\n\n\ny_train.shape\n\n(4921,)"
  },
  {
    "objectID": "posts/basic/2023-10-30-00. Churn.html#정규화스케일링",
    "href": "posts/basic/2023-10-30-00. Churn.html#정규화스케일링",
    "title": "00. Churn",
    "section": "정규화/스케일링",
    "text": "정규화/스케일링\n\nfrom sklearn.preprocessing import MinMaxScaler\n\n\nscaler = MinMaxScaler()\n\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)"
  },
  {
    "objectID": "posts/basic/2023-10-30-00. Churn.html#모델별-bar차트-그려주고-성능-시각화-시험-x",
    "href": "posts/basic/2023-10-30-00. Churn.html#모델별-bar차트-그려주고-성능-시각화-시험-x",
    "title": "00. Churn",
    "section": "모델별 bar차트 그려주고 성능 시각화 (시험 X)",
    "text": "모델별 bar차트 그려주고 성능 시각화 (시험 X)\n\n\nCode\n# 모델별로 Recall 점수 저장\n# 모델 Recall 점수 순서대로 바차트를 그려 모델별로 성능 확인 가능\n\nfrom sklearn.metrics import accuracy_score\n\nmy_predictions = {}\n\ncolors = ['r', 'c', 'm', 'y', 'k', 'khaki', 'teal', 'orchid', 'sandybrown',\n          'greenyellow', 'dodgerblue', 'deepskyblue', 'rosybrown', 'firebrick',\n          'deeppink', 'crimson', 'salmon', 'darkred', 'olivedrab', 'olive',\n          'forestgreen', 'royalblue', 'indigo', 'navy', 'mediumpurple', 'chocolate',\n          'gold', 'darkorange', 'seagreen', 'turquoise', 'steelblue', 'slategray',\n          'peru', 'midnightblue', 'slateblue', 'dimgray', 'cadetblue', 'tomato'\n         ]\n\n# 모델명, 예측값, 실제값을 주면 위의 plot_predictions 함수 호출하여 Scatter 그래프 그리며\n# 모델별 MSE값을 Bar chart로 그려줌\n\ndef recall_eval(name_, pred, actual):\n    global predictions\n    global colors\n\n    plt.figure(figsize=(12, 9))\n\n    #acc = accuracy_score(actual, pred)\n    acc = recall_score(actual, pred)\n    my_predictions[name_] = acc * 100\n\n    y_value = sorted(my_predictions.items(), key=lambda x: x[1], reverse=True)\n\n    df = pd.DataFrame(y_value, columns=['model', 'recall'])\n    print(df)\n\n    length = len(df)\n\n    plt.figure(figsize=(10, length))\n    ax = plt.subplot()\n    ax.set_yticks(np.arange(len(df)))\n    ax.set_yticklabels(df['model'], fontsize=15)\n    bars = ax.barh(np.arange(len(df)), df['recall'])\n\n    for i, v in enumerate(df['recall']):\n        idx = np.random.choice(len(colors))\n        bars[i].set_color(colors[idx])\n        ax.text(v + 2, i, str(round(v, 3)), color='k', fontsize=15, fontweight='bold')\n\n    plt.title('recall', fontsize=18)\n    plt.xlim(0, 100)\n\n    plt.show()"
  },
  {
    "objectID": "posts/basic/2023-10-30-00. Churn.html#모델-성능-평가",
    "href": "posts/basic/2023-10-30-00. Churn.html#모델-성능-평가",
    "title": "00. Churn",
    "section": "모델 성능 평가",
    "text": "모델 성능 평가\n\n1. 로지스틱\n\nfrom sklearn.linear_model import LogisticRegression\n\nmodel = LogisticRegression()\n\nmodel.fit(X_train, y_train)\n\nLogisticRegression()In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.LogisticRegressionLogisticRegression()\n\n\n\nl_pred = model.predict(X_test)\n\n- 결과 확인\n\nfrom sklearn.metrics import *\n\n\nprint(confusion_matrix(y_test, l_pred))\nprint(classification_report(y_test, l_pred))\n\n[[1385  164]\n [ 246  314]]\n              precision    recall  f1-score   support\n\n           0       0.85      0.89      0.87      1549\n           1       0.66      0.56      0.61       560\n\n    accuracy                           0.81      2109\n   macro avg       0.75      0.73      0.74      2109\nweighted avg       0.80      0.81      0.80      2109\n\n\n\n\nrecall_eval(\"Logistic Regression\", l_pred, y_test)\n\n                 model     recall\n0  Logistic Regression  56.071429\n\n\n&lt;Figure size 1200x900 with 0 Axes&gt;\n\n\n\n\n\n\n\n2. KNN\n\nfrom sklearn.neighbors import KNeighborsClassifier\n\nmodel  = KNeighborsClassifier(n_neighbors = 5)\n\nmodel.fit(X_train, y_train)\n\nk_pred = model.predict(X_test)\n\nprint(confusion_matrix(y_test, k_pred))\nprint(classification_report(y_test, k_pred))\n\n[[1310  239]\n [ 273  287]]\n              precision    recall  f1-score   support\n\n           0       0.83      0.85      0.84      1549\n           1       0.55      0.51      0.53       560\n\n    accuracy                           0.76      2109\n   macro avg       0.69      0.68      0.68      2109\nweighted avg       0.75      0.76      0.75      2109\n\n\n\n\nrecall_eval(\"KNN\", k_pred, y_test)\n\n                 model     recall\n0  Logistic Regression  56.071429\n1                  KNN  51.250000\n\n\n&lt;Figure size 1200x900 with 0 Axes&gt;\n\n\n\n\n\n\n\n3. Decision Tree\n\nfrom sklearn.tree import DecisionTreeClassifier\n\nmodel = DecisionTreeClassifier()\n\nmodel.fit(X_train, y_train)\n\ntree_pred = model.predict(X_test)\n\nprint(confusion_matrix(y_test, tree_pred))\nprint(classification_report(y_test, tree_pred))\n\n[[1289  260]\n [ 265  295]]\n              precision    recall  f1-score   support\n\n           0       0.83      0.83      0.83      1549\n           1       0.53      0.53      0.53       560\n\n    accuracy                           0.75      2109\n   macro avg       0.68      0.68      0.68      2109\nweighted avg       0.75      0.75      0.75      2109\n\n\n\n\nrecall_eval(\"Decision Tree\", tree_pred, y_test)\n\n                 model     recall\n0  Logistic Regression  56.071429\n1        Decision Tree  52.678571\n2                  KNN  51.250000\n\n\n&lt;Figure size 1200x900 with 0 Axes&gt;\n\n\n\n\n\n주요 Hyperparameter ##### 파라미터들을 조절하면서 모델의 성능을 높이거나 과대적합/과소적합 문제를 해결합니다.\n\nrandom_state: 랜덤 시드 고정 값. 고정해두고 튜닝하세요!\nn_jobs: CPU 사용 갯수 (여러 코어를 사용하면 모델 학습이 빨라짐)\nmax_depth: 깊어질 수 있는 최대 깊이. 너무 깊은 트리는 과대적합 발생할 수 있음\nn_estimators: 앙상블하는 트리의 갯수\nmax_features: 최대로 사용할 feature의 갯수. 값이 작을수록 과대적합 방지함\nmin_samples_split: 트리가 분할할 때 필요한 최소 샘플 수. 이 값을 증가시키면 각 분할에 샘플이 많이 필요해서 과대적합 방지함\n\n\n\n4. RandomForest\n\nfrom sklearn.ensemble import RandomForestClassifier\n\nmodel = RandomForestClassifier(n_estimators = 3, random_state = 42)\n\nmodel.fit(X_train, y_train)\n\nrf_pred = model.predict(X_test)\n\nprint(confusion_matrix(y_test, rf_pred))\nprint(classification_report(y_test, rf_pred))\n\n[[1332  217]\n [ 300  260]]\n              precision    recall  f1-score   support\n\n           0       0.82      0.86      0.84      1549\n           1       0.55      0.46      0.50       560\n\n    accuracy                           0.75      2109\n   macro avg       0.68      0.66      0.67      2109\nweighted avg       0.74      0.75      0.75      2109\n\n\n\n\nrecall_eval(\"Random Forest\", rf_pred, y_test)\n\n                 model     recall\n0  Logistic Regression  56.071429\n1        Decision Tree  52.678571\n2                  KNN  51.250000\n3        Random Forest  46.428571\n\n\n&lt;Figure size 1200x900 with 0 Axes&gt;\n\n\n\n\n\n주요 Hyperparameter - random_state: 랜덤 시드 고정 값. 고정해두고 튜닝하세요! - n_jobs: CPU 사용 갯수 (여러 코어를 사용하면 모델 학습이 빨라짐) - learning_rate: 학습율. 너무 큰 학습율은 성능이 떨어질 수 있고 너무 낮으면 학습이 느려져서 적절한 값을 찾아야 함, default=0.1 - n_estimators: 부스팅 스테이지 수. (랜덤포레스트 트리의 갯수 설정과 비슷한 개념). default=100 - max_depth: 트리의 깊이. 너무 높으면 과적합, 너무 낮으면 성능이 떨어짐. default=3. - subsample: 샘플 사용 비율(0~1 사이의 값), 과대적합 방지용. - max_features: 최대로 사용할 feature의 비율. 과대적합 방지용. default=1.0\n\n\n5. XGboost\n\n#!pip install xgboost\n\n\nfrom xgboost import XGBClassifier\n\nmodel = XGBClassifier()\n\n\nmodel.fit(X_train, y_train)\n\nx_pred = model.predict(X_test)\n\nprint(confusion_matrix(y_test, x_pred))\nprint(classification_report(y_test, x_pred))\n\n[[1359  190]\n [ 278  282]]\n              precision    recall  f1-score   support\n\n           0       0.83      0.88      0.85      1549\n           1       0.60      0.50      0.55       560\n\n    accuracy                           0.78      2109\n   macro avg       0.71      0.69      0.70      2109\nweighted avg       0.77      0.78      0.77      2109\n\n\n\n\nrecall_eval(\"XGboost\", x_pred, y_test)\n\n                 model     recall\n0  Logistic Regression  56.071429\n1        Decision Tree  52.678571\n2                  KNN  51.250000\n3              XGboost  50.357143\n4        Random Forest  46.428571\n\n\n&lt;Figure size 1200x900 with 0 Axes&gt;\n\n\n\n\n\n주요 Hyperparameter - random_state: 랜덤 시드 고정 값. 고정해두고 튜닝하세요! - n_jobs: CPU 사용 갯수 (여러 코어를 사용하면 모델 학습이 빨라짐) - learning_rate: 학습율. 이 값이 너무 높으면 과적합할 수 있고 낮으면 학습이 느려질 수 있음. 적절한 값을 찾아야함. default=0.1 - n_estimators: 부스팅 스테이지 수.(랜덤포레스트 트리의 갯수와 비슷한 개념). 높을수록 복잡성 증가함. default=100 - max_depth: 트리의 깊이. 값이 크면 과적합 위험이 있음. default=3. - colsample_bytree: 샘플 사용 비율 (max_features와 비슷한 개념). 과대적합 방지용. default=1.0\n\n\n6. LGBM\n\n#!pip install lightgbm\n\n\nfrom lightgbm import LGBMClassifier\n\nmodel = LGBMClassifier(n_estimator = 3, random_state = 42)\n\nmodel.fit(X_train, y_train)\n\nlg_pred = model.predict(X_test)\n\nprint(confusion_matrix(y_test, lg_pred))\nprint(classification_report(y_test, lg_pred))\n\n[LightGBM] [Warning] Unknown parameter: n_estimator\n[LightGBM] [Warning] Unknown parameter: n_estimator\n[LightGBM] [Info] Number of positive: 1308, number of negative: 3613\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000441 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 629\n[LightGBM] [Info] Number of data points in the train set: 4921, number of used features: 26\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.265800 -&gt; initscore=-1.016039\n[LightGBM] [Info] Start training from score -1.016039\n[LightGBM] [Warning] Unknown parameter: n_estimator\n[[1377  172]\n [ 273  287]]\n              precision    recall  f1-score   support\n\n           0       0.83      0.89      0.86      1549\n           1       0.63      0.51      0.56       560\n\n    accuracy                           0.79      2109\n   macro avg       0.73      0.70      0.71      2109\nweighted avg       0.78      0.79      0.78      2109\n\n\n\n\nrecall_eval('LGBM', lg_pred, y_test)\n\n                 model     recall\n0  Logistic Regression  56.071429\n1        Decision Tree  52.678571\n2                  KNN  51.250000\n3                 LGBM  51.250000\n4              XGboost  50.357143\n5        Random Forest  46.428571\n\n\n&lt;Figure size 1200x900 with 0 Axes&gt;"
  },
  {
    "objectID": "posts/basic/2023-10-30-00. Churn.html#데이터-셋-분리",
    "href": "posts/basic/2023-10-30-00. Churn.html#데이터-셋-분리",
    "title": "00. Churn",
    "section": "데이터 셋 분리",
    "text": "데이터 셋 분리\n\ntarget = \"Churn\"\n\nX = df.drop(target, axis = 1)\ny = df[target]\n\n\nfrom sklearn.model_selection import train_test_split\n\n\n# 입력 : X, y\n# Train : Test 비율 = 7:3\n# y Class 비율을 유지하면서 나누기 : stratify=y\n# 여러 번 수행해도 같은 결과 나오게 고정 : random_state=42\n# 결과 : X_train, X_test, y_train, y_test\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, stratify = y, random_state = 42)\n\n\n스케일링\n\nfrom sklearn.preprocessing import MinMaxScaler\n\nscaler = MinMaxScaler()\n\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)"
  },
  {
    "objectID": "posts/basic/2023-10-30-00. Churn.html#dnn-구현-1",
    "href": "posts/basic/2023-10-30-00. Churn.html#dnn-구현-1",
    "title": "00. Churn",
    "section": "DNN 구현 1",
    "text": "DNN 구현 1\n\nimport tensorflow as tf\n\n- 하이퍼 파라미터 설정\n\nbatch_size = 16\nepochs = 20\n\n- 아래의 요구대로 Sequential 모델 만들기\n\n# Sequential() 모델 정의 하고 model로 저장\n# input layer는 input_shape=() 옵션을 사용한다.\n# 39개 input layer\n# unit 4개 hidden layer\n# unit 3개 hidden layer\n# 1개 output layser : 이진분류\n\n\nX_train.shape\n\n(4921, 26)\n\n\n\nnf = X_train.shape[1]\n\n\nmodel = tf.keras.models.Sequential()\nmodel.add(tf.keras.layers.Dense(4, activation = \"relu\", input_shape = (nf,)))\nmodel.add(tf.keras.layers.Dense(3, activation = \"relu\"))\nmodel.add(tf.keras.layers.Dense(1, activation = \"sigmoid\"))\n\n\nmodel.summary()\n\nModel: \"sequential_5\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n dense_12 (Dense)            (None, 4)                 108       \n                                                                 \n dense_13 (Dense)            (None, 3)                 15        \n                                                                 \n dense_14 (Dense)            (None, 1)                 4         \n                                                                 \n=================================================================\nTotal params: 127 (508.00 Byte)\nTrainable params: 127 (508.00 Byte)\nNon-trainable params: 0 (0.00 Byte)\n_________________________________________________________________\n\n\n- dropout 추가\n\nmodel = tf.keras.models.Sequential()\nmodel.add(tf.keras.layers.Dense(4, activation = \"relu\", input_shape = (nf,)))\nmodel.add(tf.keras.layers.Dropout(0.3))\nmodel.add(tf.keras.layers.Dense(3, activation = \"relu\"))\nmodel.add(tf.keras.layers.Dropout(0.3))\nmodel.add(tf.keras.layers.Dense(1, activation = \"sigmoid\"))\n\n\nmodel.summary()\n\nModel: \"sequential_6\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n dense_15 (Dense)            (None, 4)                 108       \n                                                                 \n dropout (Dropout)           (None, 4)                 0         \n                                                                 \n dense_16 (Dense)            (None, 3)                 15        \n                                                                 \n dropout_1 (Dropout)         (None, 3)                 0         \n                                                                 \n dense_17 (Dense)            (None, 1)                 4         \n                                                                 \n=================================================================\nTotal params: 127 (508.00 Byte)\nTrainable params: 127 (508.00 Byte)\nNon-trainable params: 0 (0.00 Byte)\n_________________________________________________________________\n\n\n- 아래의 요구사항대로 모델을 컴파일\n\n# - 옵티마이저 : 'adam'\n# - 손실 함수 : 'binary_crossentropy'\n# - 평가 지표 : 'accuracy'\n\nmodel.compile(loss = tf.keras.losses.binary_crossentropy,\n                            optimizer = tf.keras.optimizers.Adam(0.001),\n                              metrics = [\"accuracy\"])\n\n\n아래 요구사항대로 모델 학습 시키기\n\n모델 이름 : model\nSequential 모델의 fit() 함수 사용\nX, y : X_train, y_train\nvalidation_data=(X_test, y_test)\nepochs : 10번\nbatch_size : 10번\n\n\nmodel.fit(X_train, y_train,\n                validation_data=(X_test, y_test),\n                epochs = 10,\n                batch_size = 10)\n\nEpoch 1/10\n493/493 [==============================] - 11s 5ms/step - loss: 0.6046 - accuracy: 0.7106 - val_loss: 0.5062 - val_accuracy: 0.7345\nEpoch 2/10\n493/493 [==============================] - 2s 5ms/step - loss: 0.5344 - accuracy: 0.7342 - val_loss: 0.4865 - val_accuracy: 0.7345\nEpoch 3/10\n493/493 [==============================] - 2s 5ms/step - loss: 0.5257 - accuracy: 0.7342 - val_loss: 0.4782 - val_accuracy: 0.7345\nEpoch 4/10\n493/493 [==============================] - 3s 5ms/step - loss: 0.5206 - accuracy: 0.7342 - val_loss: 0.4726 - val_accuracy: 0.7345\nEpoch 5/10\n493/493 [==============================] - 3s 7ms/step - loss: 0.5192 - accuracy: 0.7368 - val_loss: 0.4628 - val_accuracy: 0.7387\nEpoch 6/10\n493/493 [==============================] - 3s 5ms/step - loss: 0.5051 - accuracy: 0.7559 - val_loss: 0.4498 - val_accuracy: 0.7615\nEpoch 7/10\n493/493 [==============================] - 3s 5ms/step - loss: 0.4985 - accuracy: 0.7586 - val_loss: 0.4547 - val_accuracy: 0.7520\nEpoch 8/10\n493/493 [==============================] - 2s 5ms/step - loss: 0.4960 - accuracy: 0.7663 - val_loss: 0.4525 - val_accuracy: 0.7596\nEpoch 9/10\n493/493 [==============================] - 3s 5ms/step - loss: 0.4952 - accuracy: 0.7551 - val_loss: 0.4512 - val_accuracy: 0.7525\nEpoch 10/10\n493/493 [==============================] - 5s 11ms/step - loss: 0.4868 - accuracy: 0.7663 - val_loss: 0.4487 - val_accuracy: 0.7577\n\n\n&lt;keras.src.callbacks.History at 0x780ac638ace0&gt;"
  },
  {
    "objectID": "posts/basic/2023-10-30-00. Churn.html#dnn-구현-2",
    "href": "posts/basic/2023-10-30-00. Churn.html#dnn-구현-2",
    "title": "00. Churn",
    "section": "DNN 구현 2",
    "text": "DNN 구현 2\n- 아래의 요구사항대로 모델을 설계\n\n# 39개 input layer\n# unit 5개 hidden layer\n# dropout\n# unit 4개 hidden layer\n# dropout\n# 2개 output layser : 다중분류\n# epochs : 20번\n# batch_size : 16번\n\nmodel = tf.keras.models.Sequential()\n\nmodel.add(tf.keras.layers.Dense(5, activation = \"relu\", input_shape = (nf,)))\nmodel.add(tf.keras.layers.Dropout(0.3))\nmodel.add(tf.keras.layers.Dense(4, activation  = \"relu\"))\nmodel.add(tf.keras.layers.Dropout(0.3))\nmodel.add(tf.keras.layers.Dense(2, activation = \"softmax\"))\n\n\nmodel.summary()\n\nModel: \"sequential_7\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n dense_18 (Dense)            (None, 5)                 135       \n                                                                 \n dropout_2 (Dropout)         (None, 5)                 0         \n                                                                 \n dense_19 (Dense)            (None, 4)                 24        \n                                                                 \n dropout_3 (Dropout)         (None, 4)                 0         \n                                                                 \n dense_20 (Dense)            (None, 2)                 10        \n                                                                 \n=================================================================\nTotal params: 169 (676.00 Byte)\nTrainable params: 169 (676.00 Byte)\nNon-trainable params: 0 (0.00 Byte)\n_________________________________________________________________\n\n\n\n아래 요구사항대로 모델 학습 시키기\n\nmodel.compile(loss = tf.keras.losses.sparse_categorical_crossentropy,\n                            optimizer = tf.keras.optimizers.Adam(0.001), metrics = [\"accuracy\"])\n\n\n# 학습데이터 : X_train, y_train\n# 검증데이터 : X_test, y_test\n# epochs : 20, batch_size : 16\n# 'history' 변수에 저장\n\nhistory = model.fit(X_train, y_train,\n                                validation_data = [X_test, y_test],\n                                    epochs = 20, batch_size = 16).history\n\nEpoch 1/20\n308/308 [==============================] - 3s 5ms/step - loss: 0.5928 - accuracy: 0.7055 - val_loss: 0.5120 - val_accuracy: 0.7345\nEpoch 2/20\n308/308 [==============================] - 3s 11ms/step - loss: 0.5300 - accuracy: 0.7476 - val_loss: 0.4789 - val_accuracy: 0.7373\nEpoch 3/20\n308/308 [==============================] - 2s 6ms/step - loss: 0.5085 - accuracy: 0.7535 - val_loss: 0.4659 - val_accuracy: 0.7482\nEpoch 4/20\n308/308 [==============================] - 1s 4ms/step - loss: 0.4919 - accuracy: 0.7606 - val_loss: 0.4555 - val_accuracy: 0.7553\nEpoch 5/20\n308/308 [==============================] - 1s 4ms/step - loss: 0.4909 - accuracy: 0.7588 - val_loss: 0.4540 - val_accuracy: 0.7530\nEpoch 6/20\n308/308 [==============================] - 1s 5ms/step - loss: 0.4769 - accuracy: 0.7635 - val_loss: 0.4469 - val_accuracy: 0.7596\nEpoch 7/20\n308/308 [==============================] - 1s 4ms/step - loss: 0.4734 - accuracy: 0.7702 - val_loss: 0.4440 - val_accuracy: 0.7743\nEpoch 8/20\n308/308 [==============================] - 1s 4ms/step - loss: 0.4767 - accuracy: 0.7669 - val_loss: 0.4434 - val_accuracy: 0.7776\nEpoch 9/20\n308/308 [==============================] - 1s 4ms/step - loss: 0.4803 - accuracy: 0.7610 - val_loss: 0.4478 - val_accuracy: 0.7672\nEpoch 10/20\n308/308 [==============================] - 1s 4ms/step - loss: 0.4787 - accuracy: 0.7629 - val_loss: 0.4457 - val_accuracy: 0.7672\nEpoch 11/20\n308/308 [==============================] - 2s 7ms/step - loss: 0.4748 - accuracy: 0.7641 - val_loss: 0.4414 - val_accuracy: 0.7710\nEpoch 12/20\n308/308 [==============================] - 2s 7ms/step - loss: 0.4741 - accuracy: 0.7692 - val_loss: 0.4396 - val_accuracy: 0.7776\nEpoch 13/20\n308/308 [==============================] - 1s 5ms/step - loss: 0.4752 - accuracy: 0.7653 - val_loss: 0.4382 - val_accuracy: 0.7800\nEpoch 14/20\n308/308 [==============================] - 1s 4ms/step - loss: 0.4637 - accuracy: 0.7647 - val_loss: 0.4379 - val_accuracy: 0.7805\nEpoch 15/20\n308/308 [==============================] - 1s 4ms/step - loss: 0.4571 - accuracy: 0.7704 - val_loss: 0.4369 - val_accuracy: 0.7824\nEpoch 16/20\n308/308 [==============================] - 1s 4ms/step - loss: 0.4623 - accuracy: 0.7667 - val_loss: 0.4388 - val_accuracy: 0.7790\nEpoch 17/20\n308/308 [==============================] - 1s 4ms/step - loss: 0.4656 - accuracy: 0.7655 - val_loss: 0.4400 - val_accuracy: 0.7814\nEpoch 18/20\n308/308 [==============================] - 1s 5ms/step - loss: 0.4638 - accuracy: 0.7635 - val_loss: 0.4393 - val_accuracy: 0.7786\nEpoch 19/20\n308/308 [==============================] - 1s 5ms/step - loss: 0.4618 - accuracy: 0.7659 - val_loss: 0.4384 - val_accuracy: 0.7809\nEpoch 20/20\n308/308 [==============================] - 2s 6ms/step - loss: 0.4616 - accuracy: 0.7673 - val_loss: 0.4386 - val_accuracy: 0.7824\n\n\n\n\n조기종료 설정\n\n# val_loss(검증손실) 모니터링해서 손실이 최소화되는 방향으로 모니터링\n# 성능이 5번 지나도록 좋아지지 않으면 조기 종료\n\nearly_stop = tf.keras.callbacks.EarlyStopping(monitor = \"val_loss\",mode= \"min\",\n                                                                                  verbose = 1, patience = 5)\n\n\n# 최적의 모델을 'best_model.h5' 파일로 저장, 검증 손실이 최소일 때만 저장\n# val_loss 가장 낮은 값을 가질 때마다 모델 저장\n\ncheck_point = tf.keras.callbacks.ModelCheckpoint(\"best_model.h5\", verbose = 1,\n                                                                monitors = \"val_loss\",mode = \"min\", save_best_only = True)\n\n\n\n학습\n\n# early_stop과 check_point Callback 사용하여 모델에 적용시키세요.\n# epochs=50, batch_size=20\n# 검증 데이터로 X_test, y_test 사용\n# verbose 옵션을 1로 설정\n# 'history' 변수에 저장\n\n\nhistory = model.fit(X_train, y_train,\n                                validation_data = (X_test, y_test),\n                                epochs = 50, batch_size = 20,\n                                callbacks = [early_stop, check_point], verbose = 1 ).history\n\nEpoch 1/50\n246/247 [============================&gt;.] - ETA: 0s - loss: 0.4575 - accuracy: 0.7770\nEpoch 1: val_loss improved from inf to 0.43708, saving model to best_model.h5\n247/247 [==============================] - 2s 10ms/step - loss: 0.4579 - accuracy: 0.7769 - val_loss: 0.4371 - val_accuracy: 0.7819\nEpoch 2/50\n 18/247 [=&gt;............................] - ETA: 1s - loss: 0.4827 - accuracy: 0.7278242/247 [============================&gt;.] - ETA: 0s - loss: 0.4659 - accuracy: 0.7616\nEpoch 2: val_loss improved from 0.43708 to 0.43677, saving model to best_model.h5\n247/247 [==============================] - 2s 9ms/step - loss: 0.4652 - accuracy: 0.7620 - val_loss: 0.4368 - val_accuracy: 0.7814\nEpoch 3/50\n240/247 [============================&gt;.] - ETA: 0s - loss: 0.4550 - accuracy: 0.7690\nEpoch 3: val_loss did not improve from 0.43677\n247/247 [==============================] - 2s 10ms/step - loss: 0.4568 - accuracy: 0.7673 - val_loss: 0.4374 - val_accuracy: 0.7881\nEpoch 4/50\n244/247 [============================&gt;.] - ETA: 0s - loss: 0.4572 - accuracy: 0.7736\nEpoch 4: val_loss improved from 0.43677 to 0.43675, saving model to best_model.h5\n247/247 [==============================] - 1s 6ms/step - loss: 0.4576 - accuracy: 0.7726 - val_loss: 0.4367 - val_accuracy: 0.7833\nEpoch 5/50\n243/247 [============================&gt;.] - ETA: 0s - loss: 0.4547 - accuracy: 0.7671\nEpoch 5: val_loss improved from 0.43675 to 0.43665, saving model to best_model.h5\n247/247 [==============================] - 1s 5ms/step - loss: 0.4559 - accuracy: 0.7659 - val_loss: 0.4366 - val_accuracy: 0.7805\nEpoch 6/50\n235/247 [===========================&gt;..] - ETA: 0s - loss: 0.4576 - accuracy: 0.7668\nEpoch 6: val_loss did not improve from 0.43665\n247/247 [==============================] - 1s 5ms/step - loss: 0.4577 - accuracy: 0.7669 - val_loss: 0.4382 - val_accuracy: 0.7795\nEpoch 7/50\n235/247 [===========================&gt;..] - ETA: 0s - loss: 0.4550 - accuracy: 0.7687\nEpoch 7: val_loss did not improve from 0.43665\n247/247 [==============================] - 1s 4ms/step - loss: 0.4531 - accuracy: 0.7700 - val_loss: 0.4376 - val_accuracy: 0.7847\nEpoch 8/50\n237/247 [===========================&gt;..] - ETA: 0s - loss: 0.4614 - accuracy: 0.7696\nEpoch 8: val_loss did not improve from 0.43665\n247/247 [==============================] - 1s 5ms/step - loss: 0.4627 - accuracy: 0.7683 - val_loss: 0.4390 - val_accuracy: 0.7819\nEpoch 9/50\n235/247 [===========================&gt;..] - ETA: 0s - loss: 0.4622 - accuracy: 0.7689\nEpoch 9: val_loss did not improve from 0.43665\n247/247 [==============================] - 1s 4ms/step - loss: 0.4599 - accuracy: 0.7708 - val_loss: 0.4379 - val_accuracy: 0.7881\nEpoch 10/50\n245/247 [============================&gt;.] - ETA: 0s - loss: 0.4555 - accuracy: 0.7684\nEpoch 10: val_loss did not improve from 0.43665\n247/247 [==============================] - 1s 5ms/step - loss: 0.4552 - accuracy: 0.7683 - val_loss: 0.4371 - val_accuracy: 0.7824\nEpoch 10: early stopping\n\n\n/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning:\n\nYou are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n\n\n\n\n\nloss 확인\n\nlosses = pd.DataFrame(history)\n\n\nlosses\n\n\n  \n    \n\n\n\n\n\n\nloss\naccuracy\nval_loss\nval_accuracy\n\n\n\n\n0\n0.457895\n0.776875\n0.437084\n0.781887\n\n\n1\n0.465190\n0.762040\n0.436769\n0.781413\n\n\n2\n0.456798\n0.767324\n0.437379\n0.788051\n\n\n3\n0.457556\n0.772607\n0.436749\n0.783310\n\n\n4\n0.455916\n0.765901\n0.436647\n0.780465\n\n\n5\n0.457705\n0.766917\n0.438182\n0.779516\n\n\n6\n0.453103\n0.769965\n0.437608\n0.784732\n\n\n7\n0.462745\n0.768340\n0.439002\n0.781887\n\n\n8\n0.459855\n0.770778\n0.437930\n0.788051\n\n\n9\n0.455196\n0.768340\n0.437104\n0.782361\n\n\n\n\n\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n\n  \n\n\n    \n        \n    \n\n  \n\n\n\n  \n\n    \n  \n\n\n\n\n성능 시각화\n\nlosses.plot()\n\n&lt;Axes: &gt;\n\n\n\n\n\n\n\n아래 조건에 따라 정확도를 시각화하는 코드작성\n\n‘history’ 객체를 사용\n그래프 제목 : ‘Accuracy’\nx축 레이블 : ‘Epochs’\ny축 레이블 : ‘Acc’\n범례 : ‘acc’, ‘val_acc’\n\n\nplt.plot(losses[\"accuracy\"], label = \"acc\")\nplt.plot(losses[\"val_accuracy\"], label = \"val_acc\")\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Acc\")\nplt.title(\"Accuracy\")\nplt.legend()\n\n&lt;matplotlib.legend.Legend at 0x780ab6edc970&gt;\n\n\n\n\n\n\n\n성능 평가\n\npred = model.predict(X_test).argmax(axis = 1)\n\n66/66 [==============================] - 0s 3ms/step\n\n\n\nprint(confusion_matrix(y_test, pred))\nprint(classification_report(y_test,pred))\n\n[[1447  102]\n [ 357  203]]\n              precision    recall  f1-score   support\n\n           0       0.80      0.93      0.86      1549\n           1       0.67      0.36      0.47       560\n\n    accuracy                           0.78      2109\n   macro avg       0.73      0.65      0.67      2109\nweighted avg       0.77      0.78      0.76      2109\n\n\n\n\n\n(참고) 재현율 성능이 좋지 않다면 어떻게 성능향상 할 수 있나?\n\n성능향상을 할 수 있는 방법은 여러 가지가 있습니다. (시험범위는 아닙니다)\nDNN 하이퍼파라미터를 수정하면서 성능향상이 되는지 확인해 볼 수 있습니다.\n데이터를 줄이거나(UnderSampling) 늘리거나(OverSampling), Feature(컬럼)을 늘리거나 줄이거나 하는 식으로 데이터를 균형하게 조정할 수도 있습니다.c"
  },
  {
    "objectID": "posts/advanced/2023-01-24-04. 네이버 영화 리뷰 분류 (1).html",
    "href": "posts/advanced/2023-01-24-04. 네이버 영화 리뷰 분류 (1).html",
    "title": "04. 네이버 영화 리뷰 분류",
    "section": "",
    "text": "import pickle\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport re\nimport urllib.request\nfrom tqdm import tqdm\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\n\n\nurllib.request.urlretrieve(\"https://raw.githubusercontent.com/e9t/nsmc/master/ratings_train.txt\", filename=\"ratings_train.txt\")\nurllib.request.urlretrieve(\"https://raw.githubusercontent.com/e9t/nsmc/master/ratings_test.txt\", filename=\"ratings_test.txt\")\n\n('ratings_test.txt', &lt;http.client.HTTPMessage at 0x7a5a106631c0&gt;)\n\n\n\ntrain_data = pd.read_table('ratings_train.txt')\ntest_data = pd.read_table('ratings_test.txt')\n\n\ntrain_data.head()\n\n\n  \n    \n\n\n\n\n\n\nid\ndocument\nlabel\n\n\n\n\n0\n9976970\n아 더빙.. 진짜 짜증나네요 목소리\n0\n\n\n1\n3819312\n흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나\n1\n\n\n2\n10265843\n너무재밓었다그래서보는것을추천한다\n0\n\n\n3\n9045019\n교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정\n0\n\n\n4\n6483659\n사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...\n1"
  },
  {
    "objectID": "posts/advanced/2023-01-24-04. 네이버 영화 리뷰 분류 (1).html#결측치-제거",
    "href": "posts/advanced/2023-01-24-04. 네이버 영화 리뷰 분류 (1).html#결측치-제거",
    "title": "04. 네이버 영화 리뷰 분류",
    "section": "0, 결측치 제거",
    "text": "0, 결측치 제거\n\ntrain_data = train_data.dropna().reset_index(drop=True)"
  },
  {
    "objectID": "posts/advanced/2023-01-24-04. 네이버 영화 리뷰 분류 (1).html#특수문자-제거",
    "href": "posts/advanced/2023-01-24-04. 네이버 영화 리뷰 분류 (1).html#특수문자-제거",
    "title": "04. 네이버 영화 리뷰 분류",
    "section": "1. 특수문자 제거",
    "text": "1. 특수문자 제거\n\nremoval_list =  \"‘, ’, ◇, ‘, ”,  ’, ', ·, \\“, ·, △, ●,  , ■, (, ), \\\", &gt;&gt;, `, /, #, ∼, =,ㆍ&lt;,&gt;, .,?, !,【,】, …, ◆,%, ₩\"\ndef remove_special(sentence: str = None):\n\n    sentence = re.sub(\"[.,\\'\\\"’‘”“!?]\", \"\", sentence)\n    sentence = re.sub(\"[^ㄱ-ㅎ가-힣a-zA-Z\\\\s]\", \" \", sentence)\n    sentence = re.sub(\"\\s+\", \" \", sentence)\n    sentence = sentence.translate(str.maketrans(removal_list, ' '*len(removal_list)))\n    sentence = sentence.strip()\n    sentence = sentence.replace('\\n', ' ')\n\n    return sentence\n\n\ntrain_data[\"특수문자제거\"] = [remove_special(i) for i in train_data[\"document\"]]"
  },
  {
    "objectID": "posts/advanced/2023-01-24-04. 네이버 영화 리뷰 분류 (1).html#단어-분리",
    "href": "posts/advanced/2023-01-24-04. 네이버 영화 리뷰 분류 (1).html#단어-분리",
    "title": "04. 네이버 영화 리뷰 분류",
    "section": "2. 단어 분리",
    "text": "2. 단어 분리\n\ntrain_data[\"단어분리\"]= [i.split() for i in train_data[\"특수문자제거\"]]\nprint(train_data[\"단어분리\"][:2])\n\n0            [아, 더빙, 진짜, 짜증나네요, 목소리]\n1    [흠포스터보고, 초딩영화줄오버연기조차, 가볍지, 않구나]\nName: 단어분리, dtype: object"
  },
  {
    "objectID": "posts/advanced/2023-01-24-04. 네이버 영화 리뷰 분류 (1).html#불용어제거",
    "href": "posts/advanced/2023-01-24-04. 네이버 영화 리뷰 분류 (1).html#불용어제거",
    "title": "04. 네이버 영화 리뷰 분류",
    "section": "3. 불용어제거",
    "text": "3. 불용어제거\n\ndef remove_stopword(sent):\n    stopwords = ['의','가','이','은','들','는','좀','잘','걍','과','도','를','을','으로','자','에','와','한','이', '로', '에서', '하는', '하면', '하고', '요', '혹시', '합니다', '감사합니다', '안녕하세요']\n    removed = [word for word in sent if not word in stopwords] # 불용어 제거\n    return removed\n\n\ntrain_data[\"불용어제거\"] = [remove_stopword(i) for i in train_data[\"단어분리\"]]\ntrain_data[\"불용어제거\"].head()\n\n0                              [아, 더빙, 진짜, 짜증나네요, 목소리]\n1                      [흠포스터보고, 초딩영화줄오버연기조차, 가볍지, 않구나]\n2                                  [너무재밓었다그래서보는것을추천한다]\n3                     [교도소, 이야기구먼, 솔직히, 재미는, 없다평점, 조정]\n4    [사이몬페그의, 익살스런, 연기가, 돋보였던, 영화스파이더맨에서, 늙어보이기만, 했...\nName: 불용어제거, dtype: object"
  },
  {
    "objectID": "posts/advanced/2023-01-24-04. 네이버 영화 리뷰 분류 (1).html#한글자-단어-제거",
    "href": "posts/advanced/2023-01-24-04. 네이버 영화 리뷰 분류 (1).html#한글자-단어-제거",
    "title": "04. 네이버 영화 리뷰 분류",
    "section": "4. 한글자 단어 제거",
    "text": "4. 한글자 단어 제거\n\ntrain_data[\"한글자제거\"] = [[j for j in i if len(j) &gt;=2 ] for i in train_data[\"불용어제거\"]]\ntrain_data[\"한글자제거\"][:5]\n\n0                                 [더빙, 진짜, 짜증나네요, 목소리]\n1                      [흠포스터보고, 초딩영화줄오버연기조차, 가볍지, 않구나]\n2                                  [너무재밓었다그래서보는것을추천한다]\n3                     [교도소, 이야기구먼, 솔직히, 재미는, 없다평점, 조정]\n4    [사이몬페그의, 익살스런, 연기가, 돋보였던, 영화스파이더맨에서, 늙어보이기만, 했...\nName: 한글자제거, dtype: object"
  },
  {
    "objectID": "posts/advanced/2023-01-24-04. 네이버 영화 리뷰 분류 (1).html#문장-단어-개수-측정",
    "href": "posts/advanced/2023-01-24-04. 네이버 영화 리뷰 분류 (1).html#문장-단어-개수-측정",
    "title": "04. 네이버 영화 리뷰 분류",
    "section": "5. 문장 단어 개수 측정",
    "text": "5. 문장 단어 개수 측정\n\ncleansing_length =[len(i) for i in train_data[\"한글자제거\"]]\ntrain_data[\"cleansing_length\"] = cleansing_length\n\n\ntrain_data.cleansing_length.describe()\n\ncount    149995.000000\nmean          6.995107\nstd           6.025118\nmin           0.000000\n25%           3.000000\n50%           5.000000\n75%           9.000000\nmax          47.000000\nName: cleansing_length, dtype: float64\n\n\n- 패딩을 위해 상한선 설정\n\nmax_length = train_data.cleansing_length.quantile(.9)\nmax_length\n\n15.0"
  },
  {
    "objectID": "posts/advanced/2023-01-24-04. 네이버 영화 리뷰 분류 (1).html#단어-모으기",
    "href": "posts/advanced/2023-01-24-04. 네이버 영화 리뷰 분류 (1).html#단어-모으기",
    "title": "04. 네이버 영화 리뷰 분류",
    "section": "단어 모으기",
    "text": "단어 모으기\n\nword_list  = [j for i in train_data[\"한글자제거\"] for j in i]\nword_list[:5]\n\n['더빙', '진짜', '짜증나네요', '목소리', '흠포스터보고']"
  },
  {
    "objectID": "posts/advanced/2023-01-24-04. 네이버 영화 리뷰 분류 (1).html#전체-단어-빈도-수",
    "href": "posts/advanced/2023-01-24-04. 네이버 영화 리뷰 분류 (1).html#전체-단어-빈도-수",
    "title": "04. 네이버 영화 리뷰 분류",
    "section": "전체 단어 빈도 수",
    "text": "전체 단어 빈도 수\n\nimport collections\n\nword_count = collections.Counter(word_list)\n# word_count.most_common()"
  },
  {
    "objectID": "posts/advanced/2023-01-24-04. 네이버 영화 리뷰 분류 (1).html#전체-단어-빈도수-및-합계-확인하기",
    "href": "posts/advanced/2023-01-24-04. 네이버 영화 리뷰 분류 (1).html#전체-단어-빈도수-및-합계-확인하기",
    "title": "04. 네이버 영화 리뷰 분류",
    "section": "전체 단어 빈도수 및 합계 확인하기",
    "text": "전체 단어 빈도수 및 합계 확인하기\n\nword_frequency = word_count.values()\ntotal_word = len(set(word_list))\ntotal_frequency_sum = sum(word_count.values())\n\ntotal_word, total_frequency_sum\n\n(298569, 1049231)"
  },
  {
    "objectID": "posts/advanced/2023-01-24-04. 네이버 영화 리뷰 분류 (1).html#회귀-단어-빈도수-및-합계-확인하기",
    "href": "posts/advanced/2023-01-24-04. 네이버 영화 리뷰 분류 (1).html#회귀-단어-빈도수-및-합계-확인하기",
    "title": "04. 네이버 영화 리뷰 분류",
    "section": "회귀 단어 빈도수 및 합계 확인하기",
    "text": "회귀 단어 빈도수 및 합계 확인하기\n\nrare_frequency = { i : j  for i,j in word_count.items() if j ==1}\nrare_count = len(rare_frequency)\nrare_frequency_sum = sum(rare_frequency.values())\n\nrare_count, rare_frequency_sum\n\n(230637, 230637)\n\n\n\nrare_count_percent = rare_count/total_word\nrare_frequency_percent = rare_frequency_sum/total_frequency_sum\n\n\nprint(\"클렌징 데이터의 전체 단어 수: \", total_word)\nprint(\"데이터 내 전체 희귀 단어수: \",  rare_count)\nprint(\"\\n\")\nprint(\"데이터의 전체 단어의 빈도 수 합: \",  total_frequency_sum )\nprint(\"데이터 내 전체 희귀 단어의 빈도 수 합: \",   rare_frequency_sum)\nprint(\"전체 단어에서 희귀 단어가 차지하는 비율: \",  rare_frequency_percent)\n\n클렌징 데이터의 전체 단어 수:  298569\n데이터 내 전체 희귀 단어수:  230637\n\n\n데이터의 전체 단어의 빈도 수 합:  1049231\n데이터 내 전체 희귀 단어의 빈도 수 합:  230637\n전체 단어에서 희귀 단어가 차지하는 비율:  0.2198152742341772"
  },
  {
    "objectID": "posts/advanced/2023-01-24-04. 네이버 영화 리뷰 분류 (1).html#단어사전-크기-정하기",
    "href": "posts/advanced/2023-01-24-04. 네이버 영화 리뷰 분류 (1).html#단어사전-크기-정하기",
    "title": "04. 네이버 영화 리뷰 분류",
    "section": "단어사전 크기 정하기",
    "text": "단어사전 크기 정하기\n\nvocab_size = total_word-rare_count\nvocab_size\n\n67932"
  },
  {
    "objectID": "posts/advanced/2023-01-24-04. 네이버 영화 리뷰 분류 (1).html#단어사전-인덱스-생성토큰화",
    "href": "posts/advanced/2023-01-24-04. 네이버 영화 리뷰 분류 (1).html#단어사전-인덱스-생성토큰화",
    "title": "04. 네이버 영화 리뷰 분류",
    "section": "단어사전 인덱스 생성(토큰화)",
    "text": "단어사전 인덱스 생성(토큰화)\n\ntokenizer = Tokenizer(num_words = vocab_size)\ntokenizer.fit_on_texts(train_data[\"한글자제거\"])\n\ntrain_data[\"토큰화\"] = tokenizer.texts_to_sequences(train_data[\"한글자제거\"])\ntrain_data.head()\n\n\n  \n    \n\n\n\n\n\n\nid\ndocument\nlabel\n특수문자제거\n단어분리\n불용어제거\n한글자제거\ncleansing_length\n토큰화\n\n\n\n\n0\n9976970\n아 더빙.. 진짜 짜증나네요 목소리\n0\n아 더빙 진짜 짜증나네요 목소리\n[아, 더빙, 진짜, 짜증나네요, 목소리]\n[아, 더빙, 진짜, 짜증나네요, 목소리]\n[더빙, 진짜, 짜증나네요, 목소리]\n4\n[816, 4, 6472, 983]\n\n\n1\n3819312\n흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나\n1\n흠포스터보고 초딩영화줄오버연기조차 가볍지 않구나\n[흠포스터보고, 초딩영화줄오버연기조차, 가볍지, 않구나]\n[흠포스터보고, 초딩영화줄오버연기조차, 가볍지, 않구나]\n[흠포스터보고, 초딩영화줄오버연기조차, 가볍지, 않구나]\n4\n[67876, 67877, 6473, 40413]\n\n\n2\n10265843\n너무재밓었다그래서보는것을추천한다\n0\n너무재밓었다그래서보는것을추천한다\n[너무재밓었다그래서보는것을추천한다]\n[너무재밓었다그래서보는것을추천한다]\n[너무재밓었다그래서보는것을추천한다]\n1\n[67878]\n\n\n3\n9045019\n교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정\n0\n교도소 이야기구먼 솔직히 재미는 없다평점 조정\n[교도소, 이야기구먼, 솔직히, 재미는, 없다평점, 조정]\n[교도소, 이야기구먼, 솔직히, 재미는, 없다평점, 조정]\n[교도소, 이야기구먼, 솔직히, 재미는, 없다평점, 조정]\n6\n[23198, 67879, 48, 304, 67880, 9568]\n\n\n4\n6483659\n사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...\n1\n사이몬페그의 익살스런 연기가 돋보였던 영화스파이더맨에서 늙어보이기만 했던 커스틴 던...\n[사이몬페그의, 익살스런, 연기가, 돋보였던, 영화스파이더맨에서, 늙어보이기만, 했...\n[사이몬페그의, 익살스런, 연기가, 돋보였던, 영화스파이더맨에서, 늙어보이기만, 했...\n[사이몬페그의, 익살스런, 연기가, 돋보였던, 영화스파이더맨에서, 늙어보이기만, 했...\n11\n[67881, 40414, 75, 4839, 67882, 67883, 735, 23..."
  },
  {
    "objectID": "posts/advanced/2023-01-24-04. 네이버 영화 리뷰 분류 (1).html#input-데이터-준비",
    "href": "posts/advanced/2023-01-24-04. 네이버 영화 리뷰 분류 (1).html#input-데이터-준비",
    "title": "04. 네이버 영화 리뷰 분류",
    "section": "input 데이터 준비",
    "text": "input 데이터 준비\n\nimport tensorflow as tf\n\n\ny = train_data[\"label\"]\nx =  tf.keras.utils.pad_sequences(train_data[\"토큰화\"], maxlen = int(max_length))\nx\n\narray([[    0,     0,     0, ...,     4,  6472,   983],\n       [    0,     0,     0, ..., 67877,  6473, 40413],\n       [    0,     0,     0, ...,     0,     0, 67878],\n       ...,\n       [    0,     0,     0, ..., 21725, 38791, 23154],\n       [    0,     0,     0, ..., 30887, 66417, 13093],\n       [    0,     0,     0, ...,   104,  1877,     1]], dtype=int32)\n\n\n\nfrom sklearn.model_selection import train_test_split\n\nx_train, x_val, y_train, y_val = train_test_split(x, y, test_size = 0.3, random_state = 2023)"
  },
  {
    "objectID": "posts/advanced/2023-01-24-04. 네이버 영화 리뷰 분류 (1).html#모델-설계-1.-transformer",
    "href": "posts/advanced/2023-01-24-04. 네이버 영화 리뷰 분류 (1).html#모델-설계-1.-transformer",
    "title": "04. 네이버 영화 리뷰 분류",
    "section": "모델 설계 1. transformer",
    "text": "모델 설계 1. transformer\n\nembedding_dim = 100\nhidden_unit = 128\n\n\nimport tensorflow as tf\n\nX = tf.keras.Input(shape=[int(max_length)])\n\nH = tf.keras.layers.Embedding(vocab_size, embedding_dim)(X)\nH = tf.keras.layers.SimpleRNN(hidden_unit, return_sequences=True)(H)\n\n# Transformer::self-attentions\nH1 = tf.keras.layers.MultiHeadAttention(2, 16)(H, H)\nH = tf.keras.layers.BatchNormalization()(H + H1)\n\n# Transformer::feed-forward\nH1 = tf.keras.layers.Dense(hidden_unit, activation='swish')(H)\nH = tf.keras.layers.BatchNormalization()(H + H1)\n\nH = tf.keras.layers.GlobalAveragePooling1D()(H)\nY = tf.keras.layers.Dense(1, activation=\"sigmoid\")(H)\n\nmodel = tf.keras.Model(X, Y)\nmodel.compile(loss=\"binary_crossentropy\", metrics=\"accuracy\", optimizer = \"adam\")\n\n#model.summary()\n\n\nh1 = model.fit(x_train, y_train, epochs=10, batch_size=128, validation_split=0.2).history\n\nEpoch 1/10\n657/657 [==============================] - 50s 70ms/step - loss: 0.4705 - accuracy: 0.7573 - val_loss: 0.4366 - val_accuracy: 0.7862\nEpoch 2/10\n657/657 [==============================] - 19s 29ms/step - loss: 0.2612 - accuracy: 0.8791 - val_loss: 0.4595 - val_accuracy: 0.7916\nEpoch 3/10\n657/657 [==============================] - 17s 26ms/step - loss: 0.1624 - accuracy: 0.9220 - val_loss: 0.6055 - val_accuracy: 0.7840\nEpoch 4/10\n657/657 [==============================] - 19s 28ms/step - loss: 0.1345 - accuracy: 0.9330 - val_loss: 0.6309 - val_accuracy: 0.7764\nEpoch 5/10\n657/657 [==============================] - 17s 26ms/step - loss: 0.1213 - accuracy: 0.9384 - val_loss: 0.7449 - val_accuracy: 0.7844\nEpoch 6/10\n657/657 [==============================] - 17s 25ms/step - loss: 0.1098 - accuracy: 0.9418 - val_loss: 0.7740 - val_accuracy: 0.7759\nEpoch 7/10\n657/657 [==============================] - 19s 28ms/step - loss: 0.1039 - accuracy: 0.9445 - val_loss: 0.9025 - val_accuracy: 0.7746\nEpoch 8/10\n657/657 [==============================] - 16s 25ms/step - loss: 0.1011 - accuracy: 0.9445 - val_loss: 0.8709 - val_accuracy: 0.7785\nEpoch 9/10\n657/657 [==============================] - 17s 26ms/step - loss: 0.0994 - accuracy: 0.9458 - val_loss: 0.8742 - val_accuracy: 0.7712\nEpoch 10/10\n657/657 [==============================] - 18s 27ms/step - loss: 0.0965 - accuracy: 0.9458 - val_loss: 1.0221 - val_accuracy: 0.7752\n\n\n\npred1 = model.predict(x_val)\n\n1407/1407 [==============================] - 7s 5ms/step\n\n\n\npred1 = np.where(pred1&gt;0.5, 1, 0)\n\n\nfrom sklearn.metrics import *\n\nprint(classification_report(y_val,pred1))\n\n              precision    recall  f1-score   support\n\n           0       0.80      0.74      0.77     22538\n           1       0.75      0.81      0.78     22461\n\n    accuracy                           0.77     44999\n   macro avg       0.78      0.78      0.77     44999\nweighted avg       0.78      0.77      0.77     44999"
  },
  {
    "objectID": "posts/advanced/2023-01-24-04. 네이버 영화 리뷰 분류 (1).html#모델-설계2.-lstm",
    "href": "posts/advanced/2023-01-24-04. 네이버 영화 리뷰 분류 (1).html#모델-설계2.-lstm",
    "title": "04. 네이버 영화 리뷰 분류",
    "section": "모델 설계2. lstm",
    "text": "모델 설계2. lstm\n\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras.models import *\nfrom tensorflow.keras.callbacks import *\n\nembedding_dim = 100\nhidden_units = 128\n\nmodel = Sequential()\nmodel.add(Embedding(vocab_size, embedding_dim))\nmodel.add(LSTM(hidden_unit))\nmodel.add(Dense(1, activation='sigmoid'))\nmodel.compile(loss=\"binary_crossentropy\", metrics=\"accuracy\", optimizer = \"adam\")\n\n\nh2 = model.fit(x_train, y_train, epochs=10, batch_size=128, validation_split=0.2).history\n\nEpoch 1/10\n657/657 [==============================] - 29s 37ms/step - loss: 0.4713 - accuracy: 0.7557 - val_loss: 0.4074 - val_accuracy: 0.8027\nEpoch 2/10\n657/657 [==============================] - 8s 12ms/step - loss: 0.2892 - accuracy: 0.8663 - val_loss: 0.4457 - val_accuracy: 0.7920\nEpoch 3/10\n657/657 [==============================] - 6s 8ms/step - loss: 0.2053 - accuracy: 0.9036 - val_loss: 0.5187 - val_accuracy: 0.7888\nEpoch 4/10\n657/657 [==============================] - 6s 9ms/step - loss: 0.1610 - accuracy: 0.9217 - val_loss: 0.6151 - val_accuracy: 0.7874\nEpoch 5/10\n657/657 [==============================] - 5s 8ms/step - loss: 0.1340 - accuracy: 0.9317 - val_loss: 0.7061 - val_accuracy: 0.7851\nEpoch 6/10\n657/657 [==============================] - 5s 8ms/step - loss: 0.1159 - accuracy: 0.9387 - val_loss: 0.7840 - val_accuracy: 0.7837\nEpoch 7/10\n657/657 [==============================] - 6s 8ms/step - loss: 0.1026 - accuracy: 0.9436 - val_loss: 0.8887 - val_accuracy: 0.7798\nEpoch 8/10\n657/657 [==============================] - 5s 7ms/step - loss: 0.0951 - accuracy: 0.9469 - val_loss: 1.0325 - val_accuracy: 0.7756\nEpoch 9/10\n657/657 [==============================] - 6s 9ms/step - loss: 0.0907 - accuracy: 0.9481 - val_loss: 1.0723 - val_accuracy: 0.7795\nEpoch 10/10\n657/657 [==============================] - 5s 8ms/step - loss: 0.0862 - accuracy: 0.9500 - val_loss: 1.1715 - val_accuracy: 0.7783\n\n\n\npred2 = np.where(model.predict(x_val)&gt;0.5,1,0)\n\n1407/1407 [==============================] - 5s 3ms/step\n\n\n\nprint(classification_report(y_val,pred2))\n\n              precision    recall  f1-score   support\n\n           0       0.79      0.75      0.77     22538\n           1       0.76      0.80      0.78     22461\n\n    accuracy                           0.77     44999\n   macro avg       0.77      0.77      0.77     44999\nweighted avg       0.77      0.77      0.77     44999"
  },
  {
    "objectID": "posts/advanced/2023-01-24-04. 네이버 영화 리뷰 분류 (1).html#summary",
    "href": "posts/advanced/2023-01-24-04. 네이버 영화 리뷰 분류 (1).html#summary",
    "title": "04. 네이버 영화 리뷰 분류",
    "section": "summary",
    "text": "summary\n두 모델의 성능차이가 그렇게 크지않음.. 그때그때 선택해서 하면 되겠당"
  },
  {
    "objectID": "posts/advanced/2023-01-22-02. 이미지_분류.html",
    "href": "posts/advanced/2023-01-22-02. 이미지_분류.html",
    "title": "02. 이미지 분류",
    "section": "",
    "text": "Fashion_mnist 자료를 불러온 뒤 아래의 네트워크를 이용하여 적합하라.\n1 평가지표로 accuracy를 이용할 것\n2 epoch는 10으로 설정할 것\n3 optimizer는 adam을 이용할 것\n\n\n\nimport tensorflow as tf\n\nfrom keras.backend import *\nfrom keras.models import *\nfrom keras.layers import *\nfrom keras.callbacks import *\nfrom keras.datasets import *\nfrom keras.losses import *\nfrom keras.optimizers import *\n\n\n(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n\nDownloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n29515/29515 [==============================] - 0s 0us/step\nDownloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n26421880/26421880 [==============================] - 0s 0us/step\nDownloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n5148/5148 [==============================] - 0s 0us/step\nDownloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n4422102/4422102 [==============================] - 0s 0us/step\n\n\n\nx_train.shape, y_train.shape\n\n((60000, 28, 28), (60000,))\n\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nplt.imshow(x_test[1], cmap = \"Greys\")\n\n&lt;matplotlib.image.AxesImage at 0x7ca011e8f970&gt;\n\n\n\n\n\n\n\n\n- MinMax scaler 금지 \\(\\to\\) 태블러 데이터에 최적화되어있기 때문\n\n전처리 규칙은 train set을 따라야한다!\n\n\nM, m = x_train.max(), x_train.min()\n\ntrain_x  = ((x_train-m)/(M-m)).reshape(-1, 28, 28, 1)\ntest_x  = ((x_test-m)/(M-m)).reshape(-1, 28, 28, 1)\n\n\n\n\n\nimport graphviz\ndef gv(s): return graphviz.Source('digraph G{ rankdir=\"LR\"'+ s + ';}')\n\n#collapse\ngv('''\nsplines=line\nsubgraph cluster_1{\n    style=filled;\n    color=lightgrey;\n    \"x1\"\n    \"x2\"\n    \"..\"\n    \"x784\"\n    label = \"Layer 0\"\n}\nsubgraph cluster_2{\n    style=filled;\n    color=lightgrey;\n    \"x1\" -&gt; \"node1\"\n    \"x2\" -&gt; \"node1\"\n    \"..\" -&gt; \"node1\"\n    \"x784\" -&gt; \"node1\"\n\n    \"x1\" -&gt; \"node2\"\n    \"x2\" -&gt; \"node2\"\n    \"..\" -&gt; \"node2\"\n    \"x784\" -&gt; \"node2\"\n\n    \"x1\" -&gt; \"...\"\n    \"x2\" -&gt; \"...\"\n    \"..\" -&gt; \"...\"\n    \"x784\" -&gt; \"...\"\n\n    \"x1\" -&gt; \"node20\"\n    \"x2\" -&gt; \"node20\"\n    \"..\" -&gt; \"node20\"\n    \"x784\" -&gt; \"node20\"\n\n\n    label = \"Layer 1: relu\"\n}\nsubgraph cluster_3{\n    style=filled;\n    color=lightgrey;\n    \"node1\" -&gt; \"node1 \"\n    \"node2\" -&gt; \"node1 \"\n    \"...\" -&gt; \"node1 \"\n    \"node20\" -&gt; \"node1 \"\n\n    \"node1\" -&gt; \"node2 \"\n    \"node2\" -&gt; \"node2 \"\n    \"...\" -&gt; \"node2 \"\n    \"node20\" -&gt; \"node2 \"\n\n    \"node1\" -&gt; \"... \"\n    \"node2\" -&gt; \"... \"\n    \"...\" -&gt; \"... \"\n    \"node20\" -&gt; \"... \"\n\n    \"node1\" -&gt; \"node30 \"\n    \"node2\" -&gt; \"node30 \"\n    \"...\" -&gt; \"node30 \"\n    \"node20\" -&gt; \"node30 \"\n\n\n    label = \"Layer 2: relu\"\n}\nsubgraph cluster_4{\n    style=filled;\n    color=lightgrey;\n\n    \"node1 \" -&gt; \"y10\"\n    \"node2 \" -&gt; \"y10\"\n    \"... \" -&gt; \"y10\"\n    \"node30 \" -&gt; \"y10\"\n\n    \"node1 \" -&gt; \"y1\"\n    \"node2 \" -&gt; \"y1\"\n    \"... \" -&gt; \"y1\"\n    \"node30 \" -&gt; \"y1\"\n\n    \"node1 \" -&gt; \".\"\n    \"node2 \" -&gt; \".\"\n    \"... \" -&gt; \".\"\n    \"node30 \" -&gt; \".\"\n\n    label = \"Layer 3: softmax\"\n}\n''')\n\n\n\n\n\n28*28\n\n784\n\n\n\nnp.unique(y_train)\n\narray([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=uint8)\n\n\n\nmodel.compile?\n\nObject `model.compile` not found.\n\n\n\nmodel = Sequential()\n\nmodel.add(Flatten())\nmodel.add(Dense(20, activation = \"relu\"))\nmodel.add(Dense(30, activation = \"relu\"))\nmodel.add(Dense(10, activation = \"softmax\"))\n\nmodel.compile(optimizer = Adam(0.001), metrics = [\"acc\"], loss =  \"sparse_categorical_crossentropy\")\n\n\nes  = EarlyStopping(monitor = \"val_loss\", mode = \"min\", patience = 5, verbose = 1)\n\nmc = ModelCheckpoint(monitor = \"val_loss\", filepath = \"mnist_dnn.ckpt\",\n                                    save_best_only = True,  mode = \"min\", verbose = 1 )\n\n\n\n\n\nhistory = model.fit(train_x, y_train, epochs = 10, validation_split = 0.2,\n                                  callbacks = [es, mc]).history\n\nEpoch 1/10\n1485/1500 [============================&gt;.] - ETA: 0s - loss: 0.3112 - acc: 0.8847\nEpoch 1: val_loss did not improve from 0.35468\n1500/1500 [==============================] - 6s 4ms/step - loss: 0.3110 - acc: 0.8849 - val_loss: 0.3716 - val_acc: 0.8689\nEpoch 2/10\n1489/1500 [============================&gt;.] - ETA: 0s - loss: 0.3018 - acc: 0.8887\nEpoch 2: val_loss did not improve from 0.35468\n1500/1500 [==============================] - 5s 3ms/step - loss: 0.3020 - acc: 0.8888 - val_loss: 0.3825 - val_acc: 0.8664\nEpoch 3/10\n1483/1500 [============================&gt;.] - ETA: 0s - loss: 0.2999 - acc: 0.8894\nEpoch 3: val_loss did not improve from 0.35468\n1500/1500 [==============================] - 5s 3ms/step - loss: 0.2999 - acc: 0.8895 - val_loss: 0.3568 - val_acc: 0.8772\nEpoch 4/10\n1499/1500 [============================&gt;.] - ETA: 0s - loss: 0.2959 - acc: 0.8922\nEpoch 4: val_loss did not improve from 0.35468\n1500/1500 [==============================] - 5s 4ms/step - loss: 0.2958 - acc: 0.8923 - val_loss: 0.3665 - val_acc: 0.8738\nEpoch 5/10\n1490/1500 [============================&gt;.] - ETA: 0s - loss: 0.2912 - acc: 0.8904\nEpoch 5: val_loss did not improve from 0.35468\n1500/1500 [==============================] - 5s 4ms/step - loss: 0.2911 - acc: 0.8905 - val_loss: 0.3589 - val_acc: 0.8723\nEpoch 6/10\n1499/1500 [============================&gt;.] - ETA: 0s - loss: 0.2865 - acc: 0.8951\nEpoch 6: val_loss improved from 0.35468 to 0.35428, saving model to mnist_dnn.ckpt\n1500/1500 [==============================] - 8s 5ms/step - loss: 0.2865 - acc: 0.8951 - val_loss: 0.3543 - val_acc: 0.8740\nEpoch 7/10\n1498/1500 [============================&gt;.] - ETA: 0s - loss: 0.2824 - acc: 0.8946\nEpoch 7: val_loss did not improve from 0.35428\n1500/1500 [==============================] - 5s 3ms/step - loss: 0.2823 - acc: 0.8946 - val_loss: 0.3610 - val_acc: 0.8751\nEpoch 8/10\n1482/1500 [============================&gt;.] - ETA: 0s - loss: 0.2809 - acc: 0.8966\nEpoch 8: val_loss improved from 0.35428 to 0.35115, saving model to mnist_dnn.ckpt\n1500/1500 [==============================] - 6s 4ms/step - loss: 0.2807 - acc: 0.8966 - val_loss: 0.3511 - val_acc: 0.8751\nEpoch 9/10\n1485/1500 [============================&gt;.] - ETA: 0s - loss: 0.2759 - acc: 0.8977\nEpoch 9: val_loss did not improve from 0.35115\n1500/1500 [==============================] - 5s 3ms/step - loss: 0.2760 - acc: 0.8977 - val_loss: 0.3617 - val_acc: 0.8750\nEpoch 10/10\n1495/1500 [============================&gt;.] - ETA: 0s - loss: 0.2708 - acc: 0.9002\nEpoch 10: val_loss did not improve from 0.35115\n1500/1500 [==============================] - 5s 3ms/step - loss: 0.2712 - acc: 0.9001 - val_loss: 0.3593 - val_acc: 0.8748\n\n\n\n\n\n\nresult1 = model.predict(test_x)\n\n313/313 [==============================] - 1s 2ms/step\n\n\n\nresult1 = np.argmax(result1, axis = 1)\n\n\nfrom sklearn.metrics import *\n\naccuracy_score(y_test, result1)\n\n0.8652\n\n\n\n\n\n1 train_loss, val_loss 확인\n\nimport matplotlib.pyplot as plt\n\nplt.figure(figsize = (8,4))\nplt.plot(history[\"loss\"], label = \"train_loss\")\nplt.plot(history[\"val_loss\"], label = \"val_loss\")\nplt.legend()\nplt.show()\n\n\n\n\n2 실젝값, 예측값 비교\n\nfrom sklearn.metrics import *\nimport seaborn as sns\n\nsns.heatmap(confusion_matrix(y_test, result1),\n                        annot = True, fmt = \"3d\")\n\nprint(classification_report(y_test, result1))\nplt.show()\n\n              precision    recall  f1-score   support\n\n           0       0.80      0.83      0.81      1000\n           1       0.96      0.97      0.97      1000\n           2       0.81      0.73      0.76      1000\n           3       0.87      0.86      0.87      1000\n           4       0.75      0.82      0.78      1000\n           5       0.95      0.96      0.96      1000\n           6       0.69      0.62      0.65      1000\n           7       0.93      0.95      0.94      1000\n           8       0.91      0.97      0.94      1000\n           9       0.97      0.94      0.95      1000\n\n    accuracy                           0.87     10000\n   macro avg       0.86      0.87      0.86     10000\nweighted avg       0.86      0.87      0.86     10000"
  },
  {
    "objectID": "posts/advanced/2023-01-22-02. 이미지_분류.html#적합된-네트워크를-이용하여-test-data의-accuracy를-구하라",
    "href": "posts/advanced/2023-01-22-02. 이미지_분류.html#적합된-네트워크를-이용하여-test-data의-accuracy를-구하라",
    "title": "02. 이미지 분류",
    "section": "",
    "text": "result1 = model.predict(test_x)\n\n313/313 [==============================] - 1s 2ms/step\n\n\n\nresult1 = np.argmax(result1, axis = 1)\n\n\nfrom sklearn.metrics import *\n\naccuracy_score(y_test, result1)\n\n0.8652"
  },
  {
    "objectID": "posts/advanced/2023-01-22-02. 이미지_분류.html#과적합인지-확인",
    "href": "posts/advanced/2023-01-22-02. 이미지_분류.html#과적합인지-확인",
    "title": "02. 이미지 분류",
    "section": "",
    "text": "1 train_loss, val_loss 확인\n\nimport matplotlib.pyplot as plt\n\nplt.figure(figsize = (8,4))\nplt.plot(history[\"loss\"], label = \"train_loss\")\nplt.plot(history[\"val_loss\"], label = \"val_loss\")\nplt.legend()\nplt.show()\n\n\n\n\n2 실젝값, 예측값 비교\n\nfrom sklearn.metrics import *\nimport seaborn as sns\n\nsns.heatmap(confusion_matrix(y_test, result1),\n                        annot = True, fmt = \"3d\")\n\nprint(classification_report(y_test, result1))\nplt.show()\n\n              precision    recall  f1-score   support\n\n           0       0.80      0.83      0.81      1000\n           1       0.96      0.97      0.97      1000\n           2       0.81      0.73      0.76      1000\n           3       0.87      0.86      0.87      1000\n           4       0.75      0.82      0.78      1000\n           5       0.95      0.96      0.96      1000\n           6       0.69      0.62      0.65      1000\n           7       0.93      0.95      0.94      1000\n           8       0.91      0.97      0.94      1000\n           9       0.97      0.94      0.95      1000\n\n    accuracy                           0.87     10000\n   macro avg       0.86      0.87      0.86     10000\nweighted avg       0.86      0.87      0.86     10000"
  },
  {
    "objectID": "posts/advanced/2023-01-22-02. 이미지_분류.html#데이터-로드-및-전처리",
    "href": "posts/advanced/2023-01-22-02. 이미지_분류.html#데이터-로드-및-전처리",
    "title": "02. 이미지 분류",
    "section": "데이터 로드 및 전처리",
    "text": "데이터 로드 및 전처리\n\n(x_train, y_train), (x_test, y_test)  = fashion_mnist.load_data()\n\n\nM, m = x_train.max(), x_train.min()\n\ntrain_x = ((x_train-m)/(M-m)).reshape(-1, 28, 28, 1)\ntest_x = ((x_test-m)/(M-m)).reshape(-1, 28, 28, 1)"
  },
  {
    "objectID": "posts/advanced/2023-01-22-02. 이미지_분류.html#모델-설계-1",
    "href": "posts/advanced/2023-01-22-02. 이미지_분류.html#모델-설계-1",
    "title": "02. 이미지 분류",
    "section": "모델 설계 1",
    "text": "모델 설계 1\n이때 n1=6, n2=16, n3=120 으로 설정한다, 드랍아웃비율은 20%로 설정한다.\n\nmodel  = Sequential()\n\nmodel.add(Conv2D(filters = 6, kernel_size = (5 ,5), input_shape = (28, 28, 1), padding = \"valid\")) ## 패딩은 \"valid\"가 기본값\nmodel.add(MaxPool2D(pool_size = (2,2),  padding = \"valid\")) ## 패딩과 pool_size는 입력한 값이 디폴트임\nmodel.add(Conv2D(16, (5, 5)))\nmodel.add(MaxPool2D())\nmodel.add(Flatten())\nmodel.add(Dense(120, activation = \"relu\"))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(10, activation = \"softmax\"))\n\nmodel.compile(optimizer = Adam(0.001), loss = \"sparse_categorical_crossentropy\", metrics = [\"acc\"])\n\n\nmodel.summary()\n\nModel: \"sequential_9\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n conv2d_8 (Conv2D)           (None, 24, 24, 6)         156       \n                                                                 \n max_pooling2d_7 (MaxPoolin  (None, 12, 12, 6)         0         \n g2D)                                                            \n                                                                 \n conv2d_9 (Conv2D)           (None, 8, 8, 16)          2416      \n                                                                 \n max_pooling2d_8 (MaxPoolin  (None, 4, 4, 16)          0         \n g2D)                                                            \n                                                                 \n flatten_6 (Flatten)         (None, 256)               0         \n                                                                 \n dense_15 (Dense)            (None, 120)               30840     \n                                                                 \n dropout_3 (Dropout)         (None, 120)               0         \n                                                                 \n dense_16 (Dense)            (None, 10)                1210      \n                                                                 \n=================================================================\nTotal params: 34622 (135.24 KB)\nTrainable params: 34622 (135.24 KB)\nNon-trainable params: 0 (0.00 Byte)\n_________________________________________________________________"
  },
  {
    "objectID": "posts/advanced/2023-01-22-02. 이미지_분류.html#모델-설계-2",
    "href": "posts/advanced/2023-01-22-02. 이미지_분류.html#모델-설계-2",
    "title": "02. 이미지 분류",
    "section": "모델 설계 2",
    "text": "모델 설계 2\nn1=(6,64,128), n2=(16,256)에 대하여 test set의 loss가 최소화되는 조합을 찾아라.\n\nepoc = 3, validation = 0.2로 설정\n\n\nn1 = [6, 64, 128]\nn2 = [16, 256]\n\nfor i in n1 :\n  for j in n2 :\n      model  = Sequential()\n      model.add(Conv2D(filters = i, kernel_size = (5 ,5), input_shape = (28, 28, 1), padding = \"valid\")) ## 패딩은 \"valid\"가 기본값\n      model.add(MaxPool2D(pool_size = (2,2),  padding = \"valid\")) ## 패딩과 pool_size는 입력한 값이 디폴트임\n      model.add(Conv2D(j, (5, 5)))\n      model.add(MaxPool2D())\n      model.add(Flatten())\n      model.add(Dense(120, activation = \"relu\"))\n      model.add(Dropout(0.2))\n      model.add(Dense(10, activation = \"softmax\"))\n\n      model.compile(optimizer = Adam(0.001), loss = \"sparse_categorical_crossentropy\", metrics = [\"acc\"])\n      model.fit(train_x, y_train, validation_split = 0.2, epochs = 3, verbose = 0)\n\n      result = model.evaluate(test_x, y_test)\n      print(f\"n1 : {i}, n2 : {j} -&gt; loss : {result[0]}, acc  :  {result[1]}\")\n\n313/313 [==============================] - 1s 2ms/step - loss: 0.3501 - acc: 0.8754\nn1 : 6, n2 : 16 -&gt; loss : 0.3500571548938751, acc  :  0.8754000067710876\n313/313 [==============================] - 1s 2ms/step - loss: 0.3233 - acc: 0.8802\nn1 : 6, n2 : 256 -&gt; loss : 0.32328951358795166, acc  :  0.8802000284194946\n313/313 [==============================] - 1s 3ms/step - loss: 0.3424 - acc: 0.8788\nn1 : 64, n2 : 16 -&gt; loss : 0.34240153431892395, acc  :  0.8787999749183655\n313/313 [==============================] - 1s 3ms/step - loss: 0.3065 - acc: 0.8891\nn1 : 64, n2 : 256 -&gt; loss : 0.30652520060539246, acc  :  0.8891000151634216\n313/313 [==============================] - 1s 3ms/step - loss: 0.3387 - acc: 0.8804\nn1 : 128, n2 : 16 -&gt; loss : 0.3387366831302643, acc  :  0.8804000020027161\n313/313 [==============================] - 1s 4ms/step - loss: 0.3110 - acc: 0.8912\nn1 : 128, n2 : 256 -&gt; loss : 0.31100359559059143, acc  :  0.8912000060081482\n\n\n- 64, 256 일 때 test_loss가 가장 작음"
  },
  {
    "objectID": "posts/advanced/2023-01-22-02. 이미지_분류.html#데이터-로드-및-전처리-1",
    "href": "posts/advanced/2023-01-22-02. 이미지_분류.html#데이터-로드-및-전처리-1",
    "title": "02. 이미지 분류",
    "section": "데이터 로드 및 전처리",
    "text": "데이터 로드 및 전처리\n\n(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n\n\nx_train.shape, y_train.shape, x_test. shape,y_test.shape\n\n((50000, 32, 32, 3), (50000, 1), (10000, 32, 32, 3), (10000, 1))\n\n\n\ntrain_x = x_train/255.0\ntest_x = x_test/255.0\n\ny_train = y_train.reshape(-1,)\ny_test = y_test.reshape(-1,)\n\n\ny_test.shape\n\n(10000,)"
  },
  {
    "objectID": "posts/advanced/2023-01-22-02. 이미지_분류.html#모델-설계-3",
    "href": "posts/advanced/2023-01-22-02. 이미지_분류.html#모델-설계-3",
    "title": "02. 이미지 분류",
    "section": "모델 설계",
    "text": "모델 설계\n\nmodel  = Sequential()\n\nmodel.add(Conv2D(32, (3,3), input_shape = (32,32, 3)))\nmodel.add(Conv2D(32, (3,3)))\nmodel.add(BatchNormalization())\nmodel.add(MaxPool2D((2, 2), strides = (2,2)))\nmodel.add(Dropout(0.25))\n\n\nmodel.add(Conv2D(64, (3,3)))\nmodel.add(Conv2D(64, (3, 3)))\nmodel.add(MaxPool2D((2, 2), strides = (2,2)))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.25))\n\nmodel.add(Flatten())\nmodel.add(Dense(1024, activation = \"relu\"))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.2))\nmodel.add(Dense(10, activation = \"softmax\"))\n\nmodel.compile(optimizer = Adam(0.001), loss = \"sparse_categorical_crossentropy\", metrics = [\"acc\"])\n\n\nes = EarlyStopping(monitor = \"val_loss\", mode = \"min\", verbose = 1, patience = 5)\nch = ModelCheckpoint(filepath = \"CIFAR.h5\", monitor = \"val_loss\", verbose = 1,  save_best_only= True )\n\n\nmodel.fit(train_x, y_train, epochs = 30, validation_split = 0.2, callbacks = [es, ch])\n\nEpoch 1/30\n1243/1250 [============================&gt;.] - ETA: 0s - loss: 1.6670 - acc: 0.4495\nEpoch 1: val_loss improved from inf to 2.01761, saving model to CIFAR.h5\n1250/1250 [==============================] - 13s 7ms/step - loss: 1.6649 - acc: 0.4503 - val_loss: 2.0176 - val_acc: 0.3802\nEpoch 2/30\n  10/1250 [..............................] - ETA: 7s - loss: 1.4683 - acc: 0.4750 1250/1250 [==============================] - ETA: 0s - loss: 1.2204 - acc: 0.5806\nEpoch 2: val_loss improved from 2.01761 to 1.30872, saving model to CIFAR.h5\n1250/1250 [==============================] - 8s 6ms/step - loss: 1.2204 - acc: 0.5806 - val_loss: 1.3087 - val_acc: 0.5842\nEpoch 3/30\n1243/1250 [============================&gt;.] - ETA: 0s - loss: 1.0502 - acc: 0.6359\nEpoch 3: val_loss improved from 1.30872 to 1.11962, saving model to CIFAR.h5\n1250/1250 [==============================] - 8s 7ms/step - loss: 1.0508 - acc: 0.6355 - val_loss: 1.1196 - val_acc: 0.6230\nEpoch 4/30\n1245/1250 [============================&gt;.] - ETA: 0s - loss: 0.9571 - acc: 0.6714\nEpoch 4: val_loss improved from 1.11962 to 0.93383, saving model to CIFAR.h5\n1250/1250 [==============================] - 8s 7ms/step - loss: 0.9571 - acc: 0.6715 - val_loss: 0.9338 - val_acc: 0.6749\nEpoch 5/30\n1250/1250 [==============================] - ETA: 0s - loss: 0.8859 - acc: 0.6924\nEpoch 5: val_loss improved from 0.93383 to 0.86031, saving model to CIFAR.h5\n1250/1250 [==============================] - 8s 6ms/step - loss: 0.8859 - acc: 0.6924 - val_loss: 0.8603 - val_acc: 0.7047\nEpoch 6/30\n1243/1250 [============================&gt;.] - ETA: 0s - loss: 0.8145 - acc: 0.7167\nEpoch 6: val_loss did not improve from 0.86031\n1250/1250 [==============================] - 9s 7ms/step - loss: 0.8142 - acc: 0.7168 - val_loss: 0.9080 - val_acc: 0.6976\nEpoch 7/30\n1249/1250 [============================&gt;.] - ETA: 0s - loss: 0.7646 - acc: 0.7375\nEpoch 7: val_loss improved from 0.86031 to 0.84302, saving model to CIFAR.h5\n1250/1250 [==============================] - 8s 6ms/step - loss: 0.7648 - acc: 0.7375 - val_loss: 0.8430 - val_acc: 0.7168\nEpoch 8/30\n1243/1250 [============================&gt;.] - ETA: 0s - loss: 0.7157 - acc: 0.7530\nEpoch 8: val_loss did not improve from 0.84302\n1250/1250 [==============================] - 8s 6ms/step - loss: 0.7159 - acc: 0.7528 - val_loss: 0.8542 - val_acc: 0.7174\nEpoch 9/30\n1243/1250 [============================&gt;.] - ETA: 0s - loss: 0.6680 - acc: 0.7698\nEpoch 9: val_loss did not improve from 0.84302\n1250/1250 [==============================] - 10s 8ms/step - loss: 0.6687 - acc: 0.7694 - val_loss: 0.8723 - val_acc: 0.7212\nEpoch 10/30\n1245/1250 [============================&gt;.] - ETA: 0s - loss: 0.6272 - acc: 0.7805\nEpoch 10: val_loss improved from 0.84302 to 0.78872, saving model to CIFAR.h5\n1250/1250 [==============================] - 9s 7ms/step - loss: 0.6279 - acc: 0.7804 - val_loss: 0.7887 - val_acc: 0.7422\nEpoch 11/30\n1248/1250 [============================&gt;.] - ETA: 0s - loss: 0.5885 - acc: 0.7975\nEpoch 11: val_loss did not improve from 0.78872\n1250/1250 [==============================] - 8s 6ms/step - loss: 0.5884 - acc: 0.7974 - val_loss: 0.8317 - val_acc: 0.7329\nEpoch 12/30\n1242/1250 [============================&gt;.] - ETA: 0s - loss: 0.5561 - acc: 0.8071\nEpoch 12: val_loss did not improve from 0.78872\n1250/1250 [==============================] - 9s 7ms/step - loss: 0.5563 - acc: 0.8072 - val_loss: 0.8331 - val_acc: 0.7350\nEpoch 13/30\n1245/1250 [============================&gt;.] - ETA: 0s - loss: 0.5360 - acc: 0.8161\nEpoch 13: val_loss did not improve from 0.78872\n1250/1250 [==============================] - 8s 7ms/step - loss: 0.5360 - acc: 0.8161 - val_loss: 0.8569 - val_acc: 0.7379\nEpoch 14/30\n1246/1250 [============================&gt;.] - ETA: 0s - loss: 0.5022 - acc: 0.8245\nEpoch 14: val_loss did not improve from 0.78872\n1250/1250 [==============================] - 8s 6ms/step - loss: 0.5022 - acc: 0.8244 - val_loss: 0.8388 - val_acc: 0.7460\nEpoch 15/30\n1244/1250 [============================&gt;.] - ETA: 0s - loss: 0.4688 - acc: 0.8346\nEpoch 15: val_loss did not improve from 0.78872\n1250/1250 [==============================] - 9s 7ms/step - loss: 0.4691 - acc: 0.8344 - val_loss: 0.8866 - val_acc: 0.7282\nEpoch 15: early stopping\n\n\n/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n  saving_api.save_model(\n\n\n&lt;keras.src.callbacks.History at 0x79059019eb00&gt;"
  },
  {
    "objectID": "posts/advanced/2023-01-22-02. 이미지_분류.html#예측",
    "href": "posts/advanced/2023-01-22-02. 이미지_분류.html#예측",
    "title": "02. 이미지 분류",
    "section": "예측",
    "text": "예측\n\nmodel.evaluate(test_x, y_test)\n\n313/313 [==============================] - 2s 5ms/step - loss: 0.9003 - acc: 0.7314\n\n\n[0.9002749919891357, 0.7314000129699707]"
  },
  {
    "objectID": "posts/advanced/2023-01-22-02. 이미지_분류.html#모델-로드-후-예측-결과-시각화",
    "href": "posts/advanced/2023-01-22-02. 이미지_분류.html#모델-로드-후-예측-결과-시각화",
    "title": "02. 이미지 분류",
    "section": "모델 로드 후 예측 결과 시각화",
    "text": "모델 로드 후 예측 결과 시각화\n\nload_model = load_model(\"CIFAR.h5\")\n\n\nimport numpy as np\npred = np.argmax(load_model.predict(test_x), axis = 1)\n\n313/313 [==============================] - 2s 5ms/step\n\n\n\nimport seaborn as sns\nfrom sklearn.metrics import *\n\nsns.heatmap(confusion_matrix(y_test, pred),\n                                                      annot = True, fmt = \"3d\")\n\n&lt;Axes: &gt;"
  },
  {
    "objectID": "posts/advanced/2023-01-21-Extra 01. summary (1).html",
    "href": "posts/advanced/2023-01-21-Extra 01. summary (1).html",
    "title": "Extra 01. summary (1)",
    "section": "",
    "text": "- knn의 경우 필요하다면 스케일링 단계가 필요\n- 이산형 변수, 즉 범주형 변수를 모델의 예측변수로 사용할 경우 더미변수로 변환해주어야한다.\npd.get_dummies(data, columns = 더미화할컬럼리스트, dtype = (int or float))\n- 결측치 처리 : 히스토그램, boxplot, 시계열 데이터인 경우 등등을 고려하여 각 case에 맞게 적절히 결측치를 처리해준다.\n\nmisforest, EM 알고리즘을 통한 결측치 처리를 한다지만, 개인적인 생각으로는 좀 과한 결측치 처리가 아닌지 싶음\n이유는 즉슨, 결측치를 처리하기위해 결측치 처리 단계에서 모델링을 한번 더 수행하는데 이 때 시간이 생각보다 오래 걸림\n\n\n\n\n- 아래와 같이 여러개의 모델을 생성한다음 cross-validation 통해 최적의 모델을 선택하였다.\n\nexample\n\n\n# 1. knn\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import cross_val_score\nknn = KNeighborsClassifier(n_neighbors=5)\n\nknn.cv = cross_val_score(knn, x_train_s, y_train, cv = 5)\n\nknn.cv_m = knn.cv.mean()\n\n# 2. tree\nfrom sklearn.tree import DecisionTreeClassifier\ntree = DecisionTreeClassifier(max_depth = 5, random_state = 1)\n\ntree.cv = cross_val_score(tree, x_train, y_train, cv = 5)\n\ntree.cv_m = tree.cv.mean()\n\n# 3. logistic\nfrom sklearn.linear_model import LogisticRegression\nlogit = LogisticRegression()\nlogit.cv = cross_val_score(logit, x_train, y_train, cv = 5)\n\nlogit.cv_m = logit.cv.mean()\n\n# 4. RF\nfrom sklearn.ensemble import RandomForestClassifier\n\nrf = RandomForestClassifier(max_depth = 5,  random_state = 1)\n\nrf.cv = cross_val_score(rf, x_train,y_train)\n\nrf.cv_m = rf.cv.mean()\n\n# 5. XGBoost\nfrom xgboost import XGBClassifier\nxgb =  XGBClassifier(max_depth = 5, random_state = 1)\n\nxgb.cv = cross_val_score(xgb, x_train, y_train, cv = 5)\n\nxgb.cv_m  = xgb.cv.mean()\n\nfrom lightgbm import LGBMClassifier\n\nlgbm = LGBMClassifier(max_depth = 5, random_state = 1,verbose = -100) \n\nlgbm.cv = cross_val_score(lgbm, x_train, y_train, cv = 5)\n\nlgbm.cv_m = lgbm.cv.mean()\n\n\n\n- 그 후 선택한 최종 모델을 튜닝해 최종 모델을 select\nfrom sklearn.model_selection import GridSearchCV\nmodel = XGBClassifier(max_depth= 5, random_state = 1)\n\nparams=  {\"max_depth\" : range(1,21)}\n\nmodel = GridSearchCV(model,\n                     params,\n                     cv=5,\n                     scoring='r2')\n\n\n\n\n\n\n\n- 아래 링크를 참조해서 까먹을때 마다 보자~~\n- ISLP2023-00.Linear Regression\n\n\n\n- 이것두 아래 링크를 참조하자.\n- ISLP2023-01. Classification\n\n\n\n- 학습을 안함, 그냥 그 근처 K개의 녀석들을 보고 값을 할당\n\\[P(y= j | X = x_0) = \\frac {1}{K}  \\sum_{i\\in N_0} I(y_i = j)\\]\n\\[N_0  : x_0\\text {와 가장 가까운  K개의 자료의 집합}\\]\n- \\(k\\)가 작을수록 모델은 복잡해지고, 클수록 단순해짐\n\n솔직히 와닿지 않지만, 내 방식대로 이해해보자.\n이전에 선형회귀분석에서 모델 복잡도를 생각해보자, 모델을 일직선으로 예측한 경우 단순선형회귀분석이다.\n즉, 모델 하나하나의 포인트를 고려하지 않고 전체 평균적인 선형회귀식을 하나 구한 것이다.\n이를 다시 KNN예제로 생각해 \\(K\\)가 클경우 생각해보변, 주변 녀석들의 하나하나 개인적은 특성을 고려하기보단 전체적인 특성에 기반하여 주어진\\(x_0\\)에 대한 \\(y\\)를 예측하는 것이다.\n따라서, \\(k\\)가 작을수록 주변 녀석들의 특징을 하나하나 잘 고려해서 모델이 복잡한 것이고, \\(k\\)가 크면 전체적인 평균을 고려한 것이기 때문에 모델이 단순해진다… \\(\\to\\) 사실 이것도 그렇게 와닿지 않음 나중에 더 찾아보자…\n\n\n\n\n\n나무모형은 간단하고 해석상에 장점이 있으나 다른 방법들에 비해 좋은 성능을 보이지 못하는 경우가 있음\n\n\n\n1 설명변수들의 가능한 조합을 이용하여 예측공간을 \\(J\\)개의 겹치지 않는(non-overlaping)구역으로 분할\n2 각 관측값은 \\(R_j\\) 구역에 포함되며, \\(R_j\\) 구역에 포함된 training data의 반응변수 (\\(y\\))의 평균 (분류문제에선 voting방식)을 이용하여 예측\n\\[\\hat {y}_{R_j} = \\frac {1}{n_j} \\sum_{k\\in R_J} y_k \\]\n3 목표 : 다음의 RSS를 최소화 하는 구역 \\(R_1,R_2, R_J\\)를 찾는 것\n\\[RSS = \\sum_{j=1}^{J} \\sum_{i \\in R_j} (y_i - \\hat {y}_{R_{j}})^2\\]\n4 모든 조합을 확인하는 것은 불가능…(사실 가능하다. tree를 무한정 쪼개면)\n\n근데 tree를 무한정 쪼갤경우 과적합문제가 무조건 발생\n\n5 정지규칙 (stopping rule)\n\n모든 자료가 한 범주에 속할 때\n노드에 속하는 자료가 일정 수 이하일 떄\nMSE의 감소량이 아주 작을 떄\n뿌리마디로부터의 깊이가 일정 수 이상일 떄 등 (max_depth)\n\n6 가지치기 : 과적합을 막기위한 방법\n\n사실 정지규칙도 이에 포함됨, 따라서 위에거 + 빠진 내용을 적겠음\nmin_samples_leaf(default = 1) : leaf노드가 되기 위한 최소한의 샘플 수\nmin_samples_split(default = 20 : 노드를 분할하기 위한 최소한의 샘플 수 (값을 적게 설정할수록 계순 분할되어, 과적합 발생 위험 증가)\nmax_feature : 최선의 분할을 위해 고려할 변수(feature) 개수\n\nsqrt : 전체 변수 개수의 루트\nauto : sqrt와 같은 의미\nlog : \\(\\log_{2}\\) (전체 변수의 수)\n\nmax_leaf_node : 리프 노드의 최대 개수 \\(\\to\\) \\(\\text{Cost complexity Pruning}\\)\n\n\\(|T|\\)는 터미널도드로 리프노드의 개수를 뜻한다.\n\\(R_{\\alpha}(T)\\)는 변하지 않는 비용함수로 \\(R(T)\\)는 우리가 알고 있는 \\(RSS\\)와 같다.\n아래식이 뜻하는 바는 리프노드의 개수가 클수록 \\(R(T)\\) 훈련 데이터 셋에대한 \\(RSS\\)가 작아져 과적합 문제가 발생할 수 있기 때문에 적절한 리프노드의 개수를 설정해야한다는 의미이다.\n\\(\\alpha\\)는 \\(\\text {tuning parameter}\\)로 복잡도를 조절한다. 만약 \\(\\alpha\\)가 0이라면 기존의 비용함수와 같고 1에 가까워질수록 \\(R(T)\\)값이 작아진다.\n따라서 우리는 적절한 \\(\\alpha\\)값과 \\(|T|\\)값을 교차검증 기법을 통해 찾아내어 가지치기를 수행하여야한다.\n\n\n\\[\\begin {align}R_{\\alpha}(T) &= \\sum R(T) + \\alpha |T|  \\\\ \\\\\n                                                          &= \\sum_{m=1}^{|T|} \\sum_{x_i \\in R_m} (y_i - \\hat {y}_{R_m})^2 +  \\alpha |T|  \\end {align}\\]\n7 비용함수\n\n지니 지수 (Gini Index)\n\n\\[Gini (D) = 1- \\sum_{k=1}^{K}p_{k}^2 = \\sum_{k=1}^{K} p_k(1-p_k)\\]\n\\[p_k : \\text{Node D에서 k번째 범주에 속하는 관측 비율}\\]\n\n\n\n\n순수하게 분류되면 값은 0이다.\n만약 분리규칙 \\(A\\)에 의해서 Node D가 \\(D_1, D_2\\)로 분리된다면, 분리규칙 \\(A\\)에서 Ginin지수는 다음과 같다.\n\n\\[Gini_A(D) =\\frac {|D_1|}{|D|}Gini(D_1) +\\frac {|D_2|}{|D|}Gini(D_2) \\]\n\n위에 근거하여 분리규칙 A에서 발생한 불순도 감소량은 다음과 같이 정의할 수 있다.\n\n\\[\\Delta Gini(A) = Gini(D) - Gini_{A}(D)\\]\n\n따라서, \\(Gini_{A}(D)\\)를 가장 작게 하거나 \\(\\Delta Gini(A)\\)를 가장 크게 하는 분리 규칙을 선택!\n\n\n\n엔트로피(Entropy)\n\n\\[\\text {Entropy}  = -\\sum_{i=1}^m p_i\\log_{2} p_i\\]\n\n순수하게 분류되면 0\n\n\n정보 이득\n\n\n엔트로피와 지니지수는 단지 속성의 불순도를 표현한다.\n우리가 알고 싶은 것은 “어떠한 속성이 얼마나 많은 정보를 제공하는가!” 이다.\n\n\\[\\text {Gain}(T,X)= \\text{Entropy}(T)-\\text{Entropy}(T,X)\\]\n\n위 식을 살펴보니 지니지수에서 했던 불순도 감소량과 비슷하지 않은가?\n\n\\[\\Delta Gini(A) = Gini(D) - Gini_{A}(D)\\]\n\n\n\n\n\n앞서 언급한 tree는 과대적합의 위험이 큰 모형임 \\(\\to\\) max_depth를 무작정 깊게 하면 과대적합이 발생하므로\n앙상블의 아이디어 : 이러한 test데이터 셋에 예측력이 약한 모델을 결합해서 성능이 좋은 모델을 만들자!\n\n\n\n- 여러 모델들의 예측결과를 투표를 통해 최종 예측결과를 결정\n\n하드 보팅 : 다수 모델이 예측한 값이 최종 결과값\n소프트 보팅 : 모든 모델이 예측한 레이블 값의 결정 확률 평균을 구한 뒤 가장 확률이 높은 값을 최종 선택\n\n\n\n\n- Boostrap Aggregating\n- 아이디어 : 모형의 분산을 줄여 과적합을 방지하자.\n\n만약, 모집단으로부터 여러개의 훈련자료를 얻을 수 있고 이로부터 여러개의 모형 \\(\\hat{f}_1(x)\\dots \\hat{f}_b(x)\\)를 얻을 수 있다면, 다음과 같이 분산을 줄일 수 있다.\n\n\\[\\hat{f}_{avg}(x) = \\frac {1}{B} \\sum_{i=1}^{B} \\hat{f}_b(x)\\]\n\n보통은 한 set의 자료만이 주어지게 되므로 위 방식은 직접 적용이 불가능\n그래서 우리는 복원추출을 기반으로 같은 size의 표본을 추출해 각각의 모델링을 수행한다. (Bootstrap sample)\n\n\\[X_1^{*}\\dots X_B^{*}\\]\n\\[\\hat{f}_{\\text{bag}}(x) = \\frac {1}{B} \\sum_{i=1}^{B} \\hat{f}^{*}_b(x)\\]\n\n보팅과 다른점은 보팅은 여러개의 예측모델, 배깅은 동일한 예측모델 여러개를 앙상블하는 것임!\n대표적인 모델 : Randoms Forest\n\n\n\n- 여러 tree모델이 전체 데이터에서 배깅 방식으로 각자의 데이터를 샘플링\n\n모델들이 개별적으로 학습을 수행한 뒤 모든 결과를 집계하여 최종 결과를 결정\n\n# 불러오기\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import *\n\n# 선언하기\nmodel = RandomForestClassifier(max_depth=5, random_state=1)\n\n# 학습하기\nmodel.fit(x_train, y_train)\n\n# 예측하기\ny_pred = model.predict(x_test)\n- Out-of-Bag은 생략 (ISLP 교재참고)\n- RF 모델의 변수 선택\n\n하나의 트리를 형성하는 과정에서, 각 노드에서 전체 \\(p\\)개의 설명변수 중 \\(m\\)개만을 임의로 추출하여 분리 규칙을 생성한다.\n\n일반적으로 \\(m \\approx \\sqrt {p}\\)\n\n\nRandomForestClassifier( max_features='sqrt') ## default\n- 변수 중요도 (Variable Importance measur)\n\n사실 여러 형태의 나무를 결합하여 산출된 모델은…. 해석이 거의 불가능해진다.\n대안적으로, 나무들을 생성할 떄 어떠한 변수들이 RSS 혹은 Gini index 등에 큰 감소를 가져왔는지를 요약한 값으로 변수의 중요도를 파악할 수 있음.\n\\(B\\)개의 모형에 대한 평균적인 기여 정도로 변수의 중요도를 평가하게 된다!\nscikit-learn 참고링크\n\n\n\n\n\n\n\n\n\n\n같은 유형의 약한 예측 모형을 결합하여 매우 정확한 예측 모형을 만드는 방법\n예측 모형을 순차적으로(Sequentially) 학습하여 먼저 학습된 모형의 결과가 다음 모형의 학습 시 정보를 제공\n즉, 이전 모형의 약점(잔차)를 학습하여 보완한다.\n\n\n\n\n\n배깅에 비해 성능이 좋지만, 속도가 느리고 과적합 발생 가능성이 있음.\n대표적인 부스팅 알고리즘 : XGBoost, LightGBM\n\n- Boosting의 원리 (ISLP 기준)\n\n초기값 셋팅 \\(\\hat{f}(x) = 0, r_1 = y_1\\)\nFor \\(b = 1, 2\\dots B , repaet\\) :\n\n\\[\\hat {f}(x)_{i+1} = \\hat {f}(x)_{i} + \\lambda \\hat {f}^{b}(x)\\]\n\nupdate the residual,\n\n\\[r_{i+1} = r_{i}- \\lambda \\hat{f}^{b} (x) \\]\n\n초기 셋팅된 \\(\\hat {f}_1 = 0\\) 이므로\n\n\\[\\hat {f}(x)_{\\text{final}} = \\sum_{i=1}^{B} \\lambda \\hat {f}^{b}(x)\\]\n- 위 같은 방식의 문제점 \\(\\to\\) 과적합발생… 당연하다. 예측 모형을 순차적으로 학습한다는 것은 모형간 자기 상관성이 존재하고 모형의 분산이 증가하기 때문에 과적합이 발생할 수 밖에 없다…\n- 이를 막기위해 나온 모델이 XGBoost!\n\n\n- Extreme Gradient Boost\n\nreview : 방금 정리했던 Boosting기법과 같이 기본 학습기를 의사결정나무로 하며, 잔차를 이용해 이전 모형의 약점을 보완하는 방식으로 학습한다.\n+\\(\\alpha\\) : 기존의 Graident Tree Boosting에 과적합 방지를 위한 파라미터\\((\\lambda, \\gamma)\\)가 추가된 알고리즘이다.\n\n\n\n0 parameter\n\n\\(L\\) : 손실함수\n\\(M\\) : 개별 모형의 최대 개수\n\\(l\\) : 학습률\n\\(\\gamma, \\lambda\\) : 과적합 방지를 위한 파라미터\n\n1. 초기 모형은 상수로 설정하며 다음과 같이 손실함수를 최소화 하는 모형으로 설정한다.\n\n초기 모형(상수값)을 아무렇게나 설정해도 된다고 하지만… 최적화 관점에서 아래처럼 잡아주는게 적절한 듯 하다.\n\n\\[F_{0}(x) = \\underset {c}{\\text{arg min}}  \\sum_{i=1}^{n} L(y_i,c)  \\]\n2 \\(m = 1,\\dots M\\)에 대하여 다음을 반복\n\n\nGradient \\(g_i\\)와 Hessian \\(h_i\\)를 계산\n\n\n\\[g_i = \\left[ \\frac {\\partial L(y_i, F(x_i))}{\\partial  F(x_i)}\\right],\\quad F(x_i) = \\hat {F}_{m-1}(x)\\]\n\\[h_i = \\left[ \\frac {\\partial^2 L(y_i, F(x_i))}{\\partial  F(x_i)^2}\\right],\\quad F(x_i) = \\hat {F}_{m-1}(x)\\]\n\n\n회귀나무 \\(\\phi_m\\)을 다음과 같이 적합\n\n\n\\[l = \\sum_{i=1}^{n} \\frac {1}{2}h_i \\left [ - \\frac {g_i}{h_i} - \\phi(x_i) \\right ]  + \\gamma T + \\frac {1}{2} \\lambda ||\\phi||^2\\]\n\\[\\phi_m = \\underset {\\phi} {\\text{arg min}} \\sum_{i=1}^{n} \\frac {1}{2}h_i \\left [ - \\frac {g_i}{h_i} - \\phi(x_i) \\right ]  + \\gamma T + \\frac {1}{2} \\lambda ||\\phi||^2\\]\n\n여기서 \\(T\\)는 \\(\\phi\\)의 끝마디 개수, \\(||\\phi||^2 = \\sum_{j=1}^{T} w_j^2\\) 이며 \\(w_j\\)는 \\(j\\)번째 끝마디에서의 출력값이다.\n\n잘 살펴보면 릿지회귀분석에 L2 penalty와 비슷한데, L1 penalty 방식도 지원하는 것 같다.\n\n\n다음과 같이 업데이트 한다.\n\n\n\\[ F_{m}(x) = F_{m-1}(x) + l\\cdot \\phi_m(x)\\]\n3 최종모형은?\n\\[F_M(x) =  \\sum_{m=0}^{M} F_m(x)\\]\n4 summary\n\nXGBoost는 기존 Gradient Boosting기법에 문제인 과적합문제를 해결하기 위해 \\(\\gamma, \\lambda\\) 파라미터를 사용한다.(규제)\n손실함수를 살펴보면 터미널 노드(끝마디 노드)의 수와 끝마디에서의 출력값에 대한 패널티 파라미터가 들어가있다,\n의사결정나무에 가지치기 과정에서 터미널 노드의 개수에 따라 panelty를 부여하는 방식을 생각해보면 비슷한 방식이다.\n또한, 내장된 교차 검증? (이거는 이론적으로 구현되어있다기보단 사이킷런에서 내부적으로 동작하게 만든것 같음)\n\n여튼 여기서 조기 중단을 가능하게끔 지원해준다.\n\n결측치 자체 처리 : 알아서 결측치를 고려해서 학습을 한다.(결측치 여부를 노드 분기를 위한 질문에 포함시킴)\n\n이것도 사이킷런에서 내부적으로 구현한듯\n그래도 명시적으로 결측치에 대한 처리를 진행하기를 권고…\n\n\n5 실습 코드\n# 불러오기\nfrom xgboost import XGBRegressor\nfrom sklearn.metrics import mean_absolute_error, r2_score\n\n# 선언하기\nmodel = XGBRegressor(max_depth=5, n_estimators=100, random_state=1)\n\n# 학습하기\nmodel.fit(x_train, y_train)\n\n# 예측하기\ny_pred = model.predict(x_test)\n\n# 평가하기\nprint(mean_absolute_error(y_test, y_pred))\nprint(r2_score(y_test, y_pred))\n6 주요 파라미터\n\nlearning_rate : 학습률(default = 0.1)\nn_estimators : 나무의 개수 (default = 100)\nmid_child_weight : 트리에서 추가적으로 분할할 지를 결정하기 위해 필요한 데이터들의 weight(\\(w_i\\))들의 총함 (default = 1)\ngamma : 트리에서 추가적으로 분할할지를 결정하기 위한 값 \\(\\gamma T\\) (default = 0)\nmax_depth : 나무의 깊이 (default = 6)\nsub_sample : weak learner가 학습에 사용되는 데이터 샘플링 비율\n\n과적합이 염려되는 경우 1보다 작은 값으로 설정, (default = 1)\n\ncolsample_bytree : 트리 생성에 필요한 변수 선택 비율\n\n변수가 많은 경우 과적합을 조절하기 위해서 사용, 기본값 = 1\n\nreg_lambda : L2규제 적용값 (\\(\\lambda \\sum_{j=1}^{T} w_j^2\\), 기본값 \\(\\lambda = 1\\))\nreg_alpha : L1규제 적용값 (\\(\\alpha \\sum_{j=1}^{T} |w|\\), 기본값 \\(\\alpha = 0\\))\nearly_stopping_rounds : n_estimators만큼 학습을 반복하지 않더라도 조기 종료 가능(default = 10, 10번 동안 성능 향상이 없으면 학습 중단.)\n\n\n\n\n\n\n\n- 기본 아이디어 : 두 클래스 사이에 가장 넓은 도로를 내는 것\n- 용어 정리\n\n결정 경계 (Decision Boundary) or 초평면\n\n클래스를 구분하는 경계선\n결정 경계가 바로 모델 (Hyper plane)이라고 부름\n\n벡터 : 모든 데이터 포인트\n서포트 벡터 : 결정경계와 가끼운 데이터 포인트\n\n마진의 크기와 결정경계에 영향을 미침\n\n마진(margin) : 서포트 벡터와 결정경계 사이의 거리\n\n폭이 가장 넓은 도로를 찾는 것이 SVM의 목표\n마진이 클수록 새로운 데이터에 대해 안정적인 분류가 가능해지는 것임\n\n잘 생각해보면 마진의 크기가 좁을수록 정확한 분류가 일어나나 과적합 문제가 발생하므로\n마진의 크기와 오류에 대한 허용 정도는 Trade-off 관계에 있는 것을 알 수 있다.\n이것을 조절하는 파라미터 \\(\\to\\) 비용(C)\n\n- 이를 이해하기 위해서!\n\nSupport vector classifier의 decision boundary는 다음과 같은 최적화 문제의 해로 정의된다.\n\n\n만약, label = {1,-1}이라 하면 초평면은 다음과 같은 성질을 가진다.\n\n\\[\\text {Hyper plane}=  \\beta_0+ \\beta_1x_{i1}+\\dots \\beta_1x_{ip} = 0\\]\n\\[\\beta_0+ \\beta_1x_{i1}+\\dots \\beta_1x_{ip} &gt; 0, \\quad \\text{if }  y_i=1\\]\n\\[\\beta_0+ \\beta_1x_{i1}+\\dots \\beta_1x_{ip} &lt; 0, \\quad \\text{if }  y_i=-1\\]\n\n이는 다음과 같이 간단히 표현할 수 있다.\n\n\\[y_i(\\beta_0+ \\beta_1x_{i1}+\\dots \\beta_1x_{ip}) &gt; 0\\]\n\n아래의 두 식은 관측치가 초평면을 중심으로 두 class를 정확히 구분되고, 관측치와 초평면사이의 직교거리가 최소 \\(M\\)이상이 되도록 보장해 주는 조건이다.\n\n\\[\\underset{\\beta_0,\\beta_1 \\dots \\beta_p, M}{\\text {maximize} M} \\]\n\\[ \\sum_{i=1}^{p} \\beta_j^2 =  1\\]\n\\[y_i(\\beta_0+ \\beta_1x_{i1}+\\dots \\beta_1x_{ip}) &gt; M\\]\n\n그러나 실제로 관측치는 두 개의 class로 정확히 구분되지 않은 경우가 더 많으며 한 두개의 관측치에 큰 영향을 받을 수 있다,(Not robust)\n\n\n관측치에 영향을 받아 초평면이 영향을 받은 예시\n\n\n\n\n\n이를 해결하기 위해 \\(C&gt;0\\), tuning parameter와 \\(\\epsilon_i\\)(slack bariable)를 사용\n\n\\[\\underset{\\beta_0,\\beta_1 \\dots \\beta_p, M}{\\text {maximize} M}, \\sum_{i=1}^{p} \\beta_j^2 =  1 \\]\n\\[y_i(\\beta_0+ \\beta_1x_{i1}+\\dots \\beta_1x_{ip}) &gt; M(1-\\epsilon_i) \\quad  (\\epsilon_i &gt; 0,  \\sum_{i=1}^n \\epsilon_i \\leq C)\\]\n\n\\(C\\)가 커질수록 margin이 넓어짐\n\\(C\\)를 작게하면 현 데이터의 정확한 분류에 더 집중하게 되므로 자료 적합성이 좋아짐, 즉 bias는 감소하고 variance는 증가\nmargin 위 혹은 안쪽에 위치한 관측치들을 일컬어 support vector라고 한다.\n\n\nC값에 따른 margin 변화\n\n\n\n\n\n여기에서 \\(C\\)값이 가장 큰 것은 왼쪽 맨위 그림이다. \\(\\to\\) 직관적으로 \\(C\\)는 허용한계이므로 \\(M\\)즉, 마진의 넓이를 넓힌다고 생각하자.\n잠깐 생각해야될 문제\n\n\n\n\n\n우리는 여태껏 직선의 경우인 Support vector classifier를 생각했다. 근데 위에 처럼 생긴다면….\n\n- 그래서 고안된 방법이 본격적인 SVM(support vector machine)이다.\n\n고차원의 decision boundary를 고려함. \\(\\to\\) 예를 들어, 2차항까지 고려한 최적화 문제의 해로써 decision boundary를 정의할 수 있음…\n\n\\[\\underset{\\beta_0,\\beta_{11},\\dots,\\beta_{p1},\\beta_{12},\\dots,\\beta_{p2},\\varepsilon_1,\\dots ,\\varepsilon_n,M} {\\text {maximize}}M\\]\n\\[\\sum_{i=1}^{p}\\sum_{k=1}^2 \\beta_{jk}^2 = 1\\]\n\\[y_i \\left( \\beta_0 + \\sum_{j=1}^{p} \\beta_{j1}x_{ij} + \\sum_{j=1}^{p}\\beta_{i2}x_{ij}^2\\right) &gt; M(1-\\varepsilon_i)\\]\n\\[\\epsilon_i &gt; 0,  \\sum_{i=1}^n \\epsilon_i \\leq C\\]\n- 단순히 확장한 것에 불과하지 않은가???\n\nsupport vector classifier을 찾기 위해서는 관측치들간의 내적(inner product)을 계산하는 것으로 충분함이 알려져 있음\n이러한 내적을 여러 방면으로 일반화하여 표현할 수 있는데 이를 규정해 주는 함수를 kernel 이라 한다. (이 부분은 설명 생략!)\n\n- kernel 종류\n\npoly(다항), rbf(Radial Basis Function), sigmoid, linear\n\n\n\n- 걍 넘어가려고 했는데 안되겠음 \\(\\to\\) ㅅㅂ… 결과를 납득할 수 없다. 진짜 다시보자\n\n\nCode\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nfrom sklearn import svm\n\n# we create 40 separable points\nnp.random.seed(0)\nX = np.r_[np.random.randn(20, 2) - [2, 2], np.random.randn(20, 2) + [2, 2]]\nY = [0] * 20 + [1] * 20\n\n# figure number\nfignum = 1\n\n# fit the model\nfor name, penalty in ((\"unreg\", 1), (\"reg\", 0.05)):\n    clf = svm.SVC(kernel=\"linear\", C=penalty)\n    clf.fit(X, Y)\n\n    # get the separating hyperplane\n    w = clf.coef_[0]\n    a = -w[0] / w[1]\n    xx = np.linspace(-5, 5)\n    yy = a * xx - (clf.intercept_[0]) / w[1]\n\n    # plot the parallels to the separating hyperplane that pass through the\n    # support vectors (margin away from hyperplane in direction\n    # perpendicular to hyperplane). This is sqrt(1+a^2) away vertically in\n    # 2-d.\n    margin = 1 / np.sqrt(np.sum(clf.coef_**2))\n    yy_down = yy - np.sqrt(1 + a**2) * margin\n    yy_up = yy + np.sqrt(1 + a**2) * margin\n\n    # plot the line, the points, and the nearest vectors to the plane\n    plt.figure(fignum, figsize=(4, 3))\n    plt.clf()\n    plt.plot(xx, yy, \"k-\")\n    plt.plot(xx, yy_down, \"k--\")\n    plt.plot(xx, yy_up, \"k--\")\n    plt.title(f\"C={penalty}\")\n    plt.scatter(\n        clf.support_vectors_[:, 0],\n        clf.support_vectors_[:, 1],\n        s=80,\n        facecolors=\"none\",\n        zorder=10,\n        edgecolors=\"k\",\n    )\n    plt.scatter(\n        X[:, 0], X[:, 1], c=Y, zorder=10, cmap=plt.get_cmap(\"RdBu\"), edgecolors=\"k\"\n    )\n\n    plt.axis(\"tight\")\n    x_min = -4.8\n    x_max = 4.2\n    y_min = -6\n    y_max = 6\n\n    YY, XX = np.meshgrid(yy, xx)\n    xy = np.vstack([XX.ravel(), YY.ravel()]).T\n    Z = clf.decision_function(xy).reshape(XX.shape)\n\n    # Put the result into a contour plot\n    plt.contourf(XX, YY, Z, cmap=plt.get_cmap(\"RdBu\"), alpha=0.5, linestyles=[\"-\"])\n\n    plt.xlim(x_min, x_max)\n    plt.ylim(y_min, y_max)\n    fignum = fignum + 1\n\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n- 우리가 기존의 하던 방식\n\nfrom sklearn.model_selection import train_test_split\n\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3, random_state = 2023)\n- 단점\n\n랜덤하게 자료를 분할하기 때문에 분할결과에 따라 추정의 변동성이 크다….\n특히 자료위 크기가 작거나 이상/영향치들이 포함되어 있는 경우에 더더욱 그러함.\n또한, 원 자료의 크기 보다 작은 집합의 훈련자료가 모형적합에 사용되기 때문에 test error가 과대추정될 수 있음.\n\n\n이러한 방법을 \\(\\text {Validation set Approach}\\)라고 한다….\n\n- K-fold Cross Validation 방식\n\n\n\n\n전체 자료를 \\(k\\)개의 집합으로 분할한 후그 중 하나의 집합 (\\(i\\))번째 집합을 평가자료롤 설정(위 그림의 경우 \\(i=1,2 \\dots 5\\))\n그 후 각 정확도를 평균냄 (교제에서는 \\(MSE\\)를 평균 냈는데, 이번 강의에서는 정확도를 평균내더라…)\n\n\\[\\text {CV}_{5} = \\frac {1}{5} \\sum_{i=1}^{5} \\text{Accuracy}_{i}\\]\n# 1단계: 불러오기\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import cross_val_score\n\n# 2단계: 선언하기\nmodel = DecisionTreeClassifier(max_depth=3)\n\n# 3단계: 검증하기\ncv_score = cross_val_score(model, x_train, y_train, cv=10)\n\n# 확인\nprint(cv_score)\nprint(cv_score.mean())\n= 장점\n\n모든 데이터가 학습과 평가에 사용됨\n데이터가 부족해서 발생하는 과소적합 문제을 방지할 수 있음\n 좀 더 일반화된 모델 을 만들 수 있음\ntest error의 과대추정을 방지\n\n- 단점\n\n반복 횟수가 많아서 모델 학습과 평가에 많은 시간이 소요\n\n\n\n\n\n\n\n- 일단, 튜닝 시 모델들의 각 파라미터들에 값을 어떻게 하느냐에 따라 성능이 달라지는 것을 확인할 수 있었음\n- grid search의 아이디어는 가능한 파라미터 값 범위를 지정해 해당 범위에서의 값을 모두 사용하는 것이다.\n\n당연히 정확도는 높으나….시간이 오래 걸리겠지라는 생각을 해볼 수 있다.\n\n\n요런느낌\n\n# 함수 불러오기\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import GridSearchCV\n\n# 파라미터 선언\nparam = {'n_neighbors': range(1, 500, 10), 'metric': ['euclidean', 'manhattan']}\n\n# 기본모델 선언\nknn_model = KNeighborsClassifier()\n\n# Grid Search 선언\nmodel = GridSearchCV(knn_model, param, cv=3)\n\n\n\n- 그리드 서치처럼 파라미터 범위를 지정하는 것은 동일\n- 설정한 파라미터 값 범위에서 몇 개를 선택할지를 정하여 Random Search 모델 선언 후 학습\n- 학습 데이터에 대해 가장 좋은 성능을 보인 파라미터 값으로 자동 학습함.\n\n참고로 Grid Search, Random Search를 사용할 때 내부적으로 K-Fold Cross Validation을 위해 cv값을 지정하므로!\n실제 수행되는 횟수는  파라미터 조합 수 x CV값이 된다.\n\n\ncode\n\n# 함수 불러오기\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import RandomizedSearchCV\n\n\n# 파라미터 선언\nparam = {'n_neighbors': range(1, 500, 10),\n'metric': ['euclidean', 'manhattan']}\n\n# 기본모델 선언\nknn_model = KNeighborsClassifier()\n# Random Search 선언\nmodel = RandomizedSearchCV(knn_model, \n                                                       param, cv=3, # (default = 5)\n                                                           n_iter=20) ### 전체 파라미터 범위에서 몇 개를 뽑을 것인지 (default = 10)\n\n또한, 두 가지 기법을 섞어서 사용할 수 있음! (강의자료 참고)\n\n\n\n\n\n\n- 머신러닝 알고리즘은 데이터가 클래스 간에 균형 있게 분포되어 있다고 가정함\n\nexample : 생존자와 사망자 수가 거의 같을 것이다~~\n\n- 클래스 불균형으로 인한 재현율이 형편없어지는 경우는 아래 링크를 참고!\n\n재현율\n\n\n\n- under sampling\n\n다수 클래스 데이터를 소수 클래스 수 만큼 랜덤 샘플링\n\n- over sampling\n\n소수의 클래스 데이터를 다수 클래스 수 만큼 랜덤 샘플링\n\n# pip install imbalanced-learn\n# 불러오기\nfrom imblearn.under_sampling import RandomUnderSampler\n\n# Under Sampling\nunder_sample = RandomUnderSampler()\nu_x_train, u_y_train = under_sample.fit_resample(x_train, y_train)\n\n# 확인\nprint('전:', np.bincount(y_train))\nprint('후:', np.bincount(u_y_train))\n\n# 불러오기\nfrom imblearn.over_sampling import RandomOverSampler\n\n# Over Sampling\nover_sample = RandomOverSampler()\no_x_train, o_y_train = over_sample.fit_resample(x_train, y_train)\n\n# 확인\nprint('전:', np.bincount(y_train))\nprint('후:', np.bincount(o_y_train))\n- over sampling (2)\n# 불러오기\nfrom imblearn.over_sampling import SMOTE\n\n# Over Sampling\nsmote = SMOTE()\ns_x_train, s_y_train = smote.fit_resample(x_train, y_train)\n\n# 확인\nprint('전:', np.bincount(y_train))\nprint('후:', np.bincount(s_y_train))\n\n\n\n- resampling 없이 클래스에 가중치를 부여하여 클래스 불균형 문제를 해결해줌\n\n학습하는 동안 알고리즘의 비용함수에서 소수 클래스에 더 많은 가중치를 부여하여 소수 클래스에 더 높은 패널티를 제공함으로써, 소수 클래스에 대한 오류를 줄이게 됨\nsklearn에서 제공하는 알고리즘 대부분 class_weight라는 하이퍼 파라미터를 제공한다.\n\nclass_weight = ‘None’ : 기본값\nclass_weight = ‘balanced’: y_train의 class 비율을 역으로 적용\nclass_weight={0:0.2, 1:0.8}: 비율 지정, 단 비율의 합은 1\n\n주의! \\(\\to\\) 전반적인 성능을 높이기 위한 작업이 아니라, 소수 클래스 성능을 높이기 위한 작업임!\n\n\n\n\n\n\n\n\n\n# 라이브러리 불러오기\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nimport plotly.io as pio\npio.renderers.default = \"plotly_mimetype+notebook_connected\"\n\nwarnings.filterwarnings(action='ignore')\n%config InlineBackend.figure_format = 'retina'\n\n\n\n\n\n# 데이터 불러오기\npath = 'https://raw.githubusercontent.com/jangrae/csv/master/airline_satisfaction_small.csv'\ndata = pd.read_csv(path)\n\n\ndata.head()\n\n\n\n\n\n\n\n\nid\ngender\ncustomer_type\nage\ntype_of_travel\nclass\nflight_distance\ninflight_wifi_service\ndeparture/arrival_time_convenient\nease_of_online_booking\n...\ninflight_entertainment\non-board_service\nleg_room_service\nbaggage_handling\ncheckin_service\ninflight_service\ncleanliness\ndeparture_delay_in_minutes\narrival_delay_in_minutes\nsatisfaction\n\n\n\n\n0\n70172\nMale\nLoyal Customer\n13\nPersonal Travel\nEco Plus\n460\n3\n4\n3\n...\n5\n4\n3\n4\n4\n5\n5\n25\n18.0\n0\n\n\n1\n5047\nMale\ndisloyal Customer\n25\nBusiness travel\nBusiness\n235\n3\n2\n3\n...\n1\n1\n5\n3\n1\n4\n1\n1\n6.0\n0\n\n\n2\n110028\nFemale\nLoyal Customer\n26\nBusiness travel\nBusiness\n1142\n2\n2\n2\n...\n5\n4\n3\n4\n4\n4\n5\n0\n0.0\n1\n\n\n3\n24026\nFemale\nLoyal Customer\n25\nBusiness travel\nBusiness\n562\n2\n5\n5\n...\n2\n2\n5\n3\n1\n4\n2\n11\n9.0\n0\n\n\n4\n119299\nMale\nLoyal Customer\n61\nBusiness travel\nBusiness\n214\n3\n3\n3\n...\n3\n3\n4\n4\n3\n3\n3\n0\n0.0\n1\n\n\n\n\n5 rows × 24 columns\n\n\n\n\ndata.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 2580 entries, 0 to 2579\nData columns (total 24 columns):\n #   Column                             Non-Null Count  Dtype  \n---  ------                             --------------  -----  \n 0   id                                 2580 non-null   int64  \n 1   gender                             2580 non-null   object \n 2   customer_type                      2580 non-null   object \n 3   age                                2580 non-null   int64  \n 4   type_of_travel                     2580 non-null   object \n 5   class                              2580 non-null   object \n 6   flight_distance                    2580 non-null   int64  \n 7   inflight_wifi_service              2580 non-null   int64  \n 8   departure/arrival_time_convenient  2580 non-null   int64  \n 9   ease_of_online_booking             2580 non-null   int64  \n 10  gate_location                      2580 non-null   int64  \n 11  food_and_drink                     2580 non-null   int64  \n 12  online_boarding                    2580 non-null   int64  \n 13  seat_comfort                       2580 non-null   int64  \n 14  inflight_entertainment             2580 non-null   int64  \n 15  on-board_service                   2580 non-null   int64  \n 16  leg_room_service                   2580 non-null   int64  \n 17  baggage_handling                   2580 non-null   int64  \n 18  checkin_service                    2580 non-null   int64  \n 19  inflight_service                   2580 non-null   int64  \n 20  cleanliness                        2580 non-null   int64  \n 21  departure_delay_in_minutes         2580 non-null   int64  \n 22  arrival_delay_in_minutes           2574 non-null   float64\n 23  satisfaction                       2580 non-null   int64  \ndtypes: float64(1), int64(19), object(4)\nmemory usage: 483.9+ KB\n\n\n- 쓸모없는 변수 제거\n\n# 변수 제거\nd_cols = [\"id\", \"departure/arrival_time_convenient\", \"gate_location\", \"departure_delay_in_minutes\"]\n\n\ndata.drop(d_cols,axis=1, inplace = True)\ndata.head()\n\n\n\n\n\n\n\n\ngender\ncustomer_type\nage\ntype_of_travel\nclass\nflight_distance\ninflight_wifi_service\nease_of_online_booking\nfood_and_drink\nonline_boarding\nseat_comfort\ninflight_entertainment\non-board_service\nleg_room_service\nbaggage_handling\ncheckin_service\ninflight_service\ncleanliness\narrival_delay_in_minutes\nsatisfaction\n\n\n\n\n0\nMale\nLoyal Customer\n13\nPersonal Travel\nEco Plus\n460\n3\n3\n5\n3\n5\n5\n4\n3\n4\n4\n5\n5\n18.0\n0\n\n\n1\nMale\ndisloyal Customer\n25\nBusiness travel\nBusiness\n235\n3\n3\n1\n3\n1\n1\n1\n5\n3\n1\n4\n1\n6.0\n0\n\n\n2\nFemale\nLoyal Customer\n26\nBusiness travel\nBusiness\n1142\n2\n2\n5\n5\n5\n5\n4\n3\n4\n4\n4\n5\n0.0\n1\n\n\n3\nFemale\nLoyal Customer\n25\nBusiness travel\nBusiness\n562\n2\n5\n2\n2\n2\n2\n2\n5\n3\n1\n4\n2\n9.0\n0\n\n\n4\nMale\nLoyal Customer\n61\nBusiness travel\nBusiness\n214\n3\n3\n4\n5\n5\n3\n3\n4\n4\n3\n3\n3\n0.0\n1\n\n\n\n\n\n\n\n- 결측치 확인\n\nprint(data.columns[data.isna().sum() !=0])\n\nIndex(['arrival_delay_in_minutes'], dtype='object')\n\n\n\ndata.arrival_delay_in_minutes.isna().sum()\n\n6\n\n\n- 현재 arrival_delay_in_minutes의 6개 결측치가 확인된다.\n\n결측치 제거를 위해 해당 변수의 분포를 확인하자.\n\n\ndata.plot(x=\"arrival_delay_in_minutes\",  kind = \"hist\", backend  = \"plotly\",\n                  width = 1000, height = 400,nbins=100)\n\n\n                                                \n\n\n- 대부분의 값들이 0값 근처에 몰려있으니 결측값을 0으로 대체하자.\n\ndata.arrival_delay_in_minutes.fillna(0, inplace = True)\nprint(data.columns[data.isna().sum() !=0])\n\nIndex([], dtype='object')\n\n\n- x, y 분리\n\ntarget = \"satisfaction\"\n\nx = data.drop(target, axis = 1)\ny = data[target]\n\n- 가변수화\n\nd = [\"gender\", \"customer_type\", \"type_of_travel\", \"class\"]\n\nx = pd.get_dummies(x, columns = d, drop_first = True, dtype = float)\nx.head()\n\n\n\n\n\n\n\n\nage\nflight_distance\ninflight_wifi_service\nease_of_online_booking\nfood_and_drink\nonline_boarding\nseat_comfort\ninflight_entertainment\non-board_service\nleg_room_service\nbaggage_handling\ncheckin_service\ninflight_service\ncleanliness\narrival_delay_in_minutes\ngender_Male\ncustomer_type_disloyal Customer\ntype_of_travel_Personal Travel\nclass_Eco\nclass_Eco Plus\n\n\n\n\n0\n13\n460\n3\n3\n5\n3\n5\n5\n4\n3\n4\n4\n5\n5\n18.0\n1.0\n0.0\n1.0\n0.0\n1.0\n\n\n1\n25\n235\n3\n3\n1\n3\n1\n1\n1\n5\n3\n1\n4\n1\n6.0\n1.0\n1.0\n0.0\n0.0\n0.0\n\n\n2\n26\n1142\n2\n2\n5\n5\n5\n5\n4\n3\n4\n4\n4\n5\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n\n\n3\n25\n562\n2\n5\n2\n2\n2\n2\n2\n5\n3\n1\n4\n2\n9.0\n0.0\n0.0\n0.0\n0.0\n0.0\n\n\n4\n61\n214\n3\n3\n4\n5\n5\n3\n3\n4\n4\n3\n3\n3\n0.0\n1.0\n0.0\n0.0\n0.0\n0.0\n\n\n\n\n\n\n\n- 학습, 평가용 데이터 분리\n\nfrom sklearn.model_selection import train_test_split\n\nx_train, x_test, y_train, y_test = train_test_split(x, y, random_state = 1, test_size = 0.3)\n\n\n\n\n\n\nCode\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import cross_val_score\n# 1. tree\ntree = DecisionTreeClassifier(max_depth = 5, random_state = 1)\ntree.cv = cross_val_score(tree, x_train, y_train, cv = 5)\ntree.cv_m = tree.cv.mean()\n\n# 2. logistic\nfrom sklearn.linear_model import LogisticRegression\nlogit = LogisticRegression()\nlogit.cv = cross_val_score(logit, x_train, y_train, cv = 5)\nlogit.cv_m = logit.cv.mean()\n\n# 3. RF\nfrom sklearn.ensemble import RandomForestClassifier\n\nrf = RandomForestClassifier(max_depth = 5,  random_state = 1)\nrf.cv = cross_val_score(rf, x_train,y_train)\nrf.cv_m = rf.cv.mean()\n\n# 4. XGBoost\n\nfrom xgboost import XGBClassifier\nxgb =  XGBClassifier(max_depth = 5, random_state = 1)\nxgb.cv = cross_val_score(xgb, x_train, y_train, cv = 5)\nxgb.cv_m  = xgb.cv.mean()\n\n\n\nresult = [tree.cv_m, logit.cv_m, rf.cv_m,  xgb.cv_m]\nmodel = [\"tree\",\"logit\", \"rf\", \"xgb\"]\n\nfig = pd.DataFrame({\"model\" : model, \"result\" : result}).\\\n            sort_values(\"result\", ascending = False).plot(x = \"result\", y = \"model\", kind = \"bar\", backend = \"plotly\",color = \"model\")\n\nfig.update_xaxes(range = [0.7, 1.0])\n\n\n                                                \n\n\n- cv를 기준으로 XGB 모델이 최적의 모델인 것 같다.\n\ngrid search기법을 이용하여 모델 튜닝\n\n\nfrom sklearn.model_selection import GridSearchCV\nmodel = XGBClassifier(max_depth= 5, random_state = 1)\n\nparams=  {\"max_depth\" : range(1,21)}\n\nmodel = GridSearchCV(model,\n                     params,\n                     cv=5,\n                     scoring=\"accuracy\")\n\n\nmodel.fit(x_train, y_train)\n\nGridSearchCV(cv=5,\n             estimator=XGBClassifier(base_score=None, booster=None,\n                                     callbacks=None, colsample_bylevel=None,\n                                     colsample_bynode=None,\n                                     colsample_bytree=None, device=None,\n                                     early_stopping_rounds=None,\n                                     enable_categorical=False, eval_metric=None,\n                                     feature_types=None, gamma=None,\n                                     grow_policy=None, importance_type=None,\n                                     interaction_constraints=None,\n                                     learning_rate=None, max_bin=None,\n                                     max_cat_threshold=None,\n                                     max_cat_to_onehot=None,\n                                     max_delta_step=None, max_depth=5,\n                                     max_leaves=None, min_child_weight=None,\n                                     missing=nan, monotone_constraints=None,\n                                     multi_strategy=None, n_estimators=None,\n                                     n_jobs=None, num_parallel_tree=None,\n                                     random_state=1, ...),\n             param_grid={'max_depth': range(1, 21)}, scoring='accuracy')In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.GridSearchCVGridSearchCV(cv=5,\n             estimator=XGBClassifier(base_score=None, booster=None,\n                                     callbacks=None, colsample_bylevel=None,\n                                     colsample_bynode=None,\n                                     colsample_bytree=None, device=None,\n                                     early_stopping_rounds=None,\n                                     enable_categorical=False, eval_metric=None,\n                                     feature_types=None, gamma=None,\n                                     grow_policy=None, importance_type=None,\n                                     interaction_constraints=None,\n                                     learning_rate=None, max_bin=None,\n                                     max_cat_threshold=None,\n                                     max_cat_to_onehot=None,\n                                     max_delta_step=None, max_depth=5,\n                                     max_leaves=None, min_child_weight=None,\n                                     missing=nan, monotone_constraints=None,\n                                     multi_strategy=None, n_estimators=None,\n                                     n_jobs=None, num_parallel_tree=None,\n                                     random_state=1, ...),\n             param_grid={'max_depth': range(1, 21)}, scoring='accuracy')estimator: XGBClassifierXGBClassifier(base_score=None, booster=None, callbacks=None,\n              colsample_bylevel=None, colsample_bynode=None,\n              colsample_bytree=None, device=None, early_stopping_rounds=None,\n              enable_categorical=False, eval_metric=None, feature_types=None,\n              gamma=None, grow_policy=None, importance_type=None,\n              interaction_constraints=None, learning_rate=None, max_bin=None,\n              max_cat_threshold=None, max_cat_to_onehot=None,\n              max_delta_step=None, max_depth=5, max_leaves=None,\n              min_child_weight=None, missing=nan, monotone_constraints=None,\n              multi_strategy=None, n_estimators=None, n_jobs=None,\n              num_parallel_tree=None, random_state=1, ...)XGBClassifierXGBClassifier(base_score=None, booster=None, callbacks=None,\n              colsample_bylevel=None, colsample_bynode=None,\n              colsample_bytree=None, device=None, early_stopping_rounds=None,\n              enable_categorical=False, eval_metric=None, feature_types=None,\n              gamma=None, grow_policy=None, importance_type=None,\n              interaction_constraints=None, learning_rate=None, max_bin=None,\n              max_cat_threshold=None, max_cat_to_onehot=None,\n              max_delta_step=None, max_depth=5, max_leaves=None,\n              min_child_weight=None, missing=nan, monotone_constraints=None,\n              multi_strategy=None, n_estimators=None, n_jobs=None,\n              num_parallel_tree=None, random_state=1, ...)\n\n\n\ny_pred = model.predict(x_test)\n\n\n# 예측 결과 확인\nprint(model.best_params_)\nprint(model.best_score_)\n\n{'max_depth': 3}\n0.9363202277283789\n\n\n\nfig = pd.DataFrame([model.best_estimator_.feature_names_in_,model.best_estimator_.feature_importances_]).T.\\\n        rename(columns = {0 : \"feature\", 1 : \"importance\"}).sort_values(\"importance\", ascending = False).\\\n            plot(y = \"feature\", x=  \"importance\", kind = \"barh\",\n                    backend = \"plotly\",color = \"feature\")\n\nfig.update_layout(showlegend = False)\n\n\n                                                \n\n\n\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n\nmeasure = [\"accuracy\", \"precision\", \"reacll\", \"f1-score\"]\n\nacc = accuracy_score(y_test, y_pred)\npre = precision_score(y_test, y_pred)\nre = recall_score(y_test, y_pred)\nf1_score = f1_score(y_test, y_pred)\n\n\npd.DataFrame({\"measure\" : measure, \"score\" : [acc, pre, re, f1_score]})\n\n\n\n\n\n\n\n\nmeasure\nscore\n\n\n\n\n0\naccuracy\n0.931525\n\n\n1\nprecision\n0.949102\n\n\n2\nreacll\n0.898017\n\n\n3\nf1-score\n0.922853"
  },
  {
    "objectID": "posts/advanced/2023-01-21-Extra 01. summary (1).html#모델링-단계",
    "href": "posts/advanced/2023-01-21-Extra 01. summary (1).html#모델링-단계",
    "title": "Extra 01. summary (1)",
    "section": "",
    "text": "- knn의 경우 필요하다면 스케일링 단계가 필요\n- 이산형 변수, 즉 범주형 변수를 모델의 예측변수로 사용할 경우 더미변수로 변환해주어야한다.\npd.get_dummies(data, columns = 더미화할컬럼리스트, dtype = (int or float))\n- 결측치 처리 : 히스토그램, boxplot, 시계열 데이터인 경우 등등을 고려하여 각 case에 맞게 적절히 결측치를 처리해준다.\n\nmisforest, EM 알고리즘을 통한 결측치 처리를 한다지만, 개인적인 생각으로는 좀 과한 결측치 처리가 아닌지 싶음\n이유는 즉슨, 결측치를 처리하기위해 결측치 처리 단계에서 모델링을 한번 더 수행하는데 이 때 시간이 생각보다 오래 걸림\n\n\n\n\n- 아래와 같이 여러개의 모델을 생성한다음 cross-validation 통해 최적의 모델을 선택하였다.\n\nexample\n\n\n# 1. knn\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import cross_val_score\nknn = KNeighborsClassifier(n_neighbors=5)\n\nknn.cv = cross_val_score(knn, x_train_s, y_train, cv = 5)\n\nknn.cv_m = knn.cv.mean()\n\n# 2. tree\nfrom sklearn.tree import DecisionTreeClassifier\ntree = DecisionTreeClassifier(max_depth = 5, random_state = 1)\n\ntree.cv = cross_val_score(tree, x_train, y_train, cv = 5)\n\ntree.cv_m = tree.cv.mean()\n\n# 3. logistic\nfrom sklearn.linear_model import LogisticRegression\nlogit = LogisticRegression()\nlogit.cv = cross_val_score(logit, x_train, y_train, cv = 5)\n\nlogit.cv_m = logit.cv.mean()\n\n# 4. RF\nfrom sklearn.ensemble import RandomForestClassifier\n\nrf = RandomForestClassifier(max_depth = 5,  random_state = 1)\n\nrf.cv = cross_val_score(rf, x_train,y_train)\n\nrf.cv_m = rf.cv.mean()\n\n# 5. XGBoost\nfrom xgboost import XGBClassifier\nxgb =  XGBClassifier(max_depth = 5, random_state = 1)\n\nxgb.cv = cross_val_score(xgb, x_train, y_train, cv = 5)\n\nxgb.cv_m  = xgb.cv.mean()\n\nfrom lightgbm import LGBMClassifier\n\nlgbm = LGBMClassifier(max_depth = 5, random_state = 1,verbose = -100) \n\nlgbm.cv = cross_val_score(lgbm, x_train, y_train, cv = 5)\n\nlgbm.cv_m = lgbm.cv.mean()\n\n\n\n- 그 후 선택한 최종 모델을 튜닝해 최종 모델을 select\nfrom sklearn.model_selection import GridSearchCV\nmodel = XGBClassifier(max_depth= 5, random_state = 1)\n\nparams=  {\"max_depth\" : range(1,21)}\n\nmodel = GridSearchCV(model,\n                     params,\n                     cv=5,\n                     scoring='r2')"
  },
  {
    "objectID": "posts/advanced/2023-01-21-Extra 01. summary (1).html#각-모델-소개",
    "href": "posts/advanced/2023-01-21-Extra 01. summary (1).html#각-모델-소개",
    "title": "Extra 01. summary (1)",
    "section": "",
    "text": "- 아래 링크를 참조해서 까먹을때 마다 보자~~\n- ISLP2023-00.Linear Regression\n\n\n\n- 이것두 아래 링크를 참조하자.\n- ISLP2023-01. Classification\n\n\n\n- 학습을 안함, 그냥 그 근처 K개의 녀석들을 보고 값을 할당\n\\[P(y= j | X = x_0) = \\frac {1}{K}  \\sum_{i\\in N_0} I(y_i = j)\\]\n\\[N_0  : x_0\\text {와 가장 가까운  K개의 자료의 집합}\\]\n- \\(k\\)가 작을수록 모델은 복잡해지고, 클수록 단순해짐\n\n솔직히 와닿지 않지만, 내 방식대로 이해해보자.\n이전에 선형회귀분석에서 모델 복잡도를 생각해보자, 모델을 일직선으로 예측한 경우 단순선형회귀분석이다.\n즉, 모델 하나하나의 포인트를 고려하지 않고 전체 평균적인 선형회귀식을 하나 구한 것이다.\n이를 다시 KNN예제로 생각해 \\(K\\)가 클경우 생각해보변, 주변 녀석들의 하나하나 개인적은 특성을 고려하기보단 전체적인 특성에 기반하여 주어진\\(x_0\\)에 대한 \\(y\\)를 예측하는 것이다.\n따라서, \\(k\\)가 작을수록 주변 녀석들의 특징을 하나하나 잘 고려해서 모델이 복잡한 것이고, \\(k\\)가 크면 전체적인 평균을 고려한 것이기 때문에 모델이 단순해진다… \\(\\to\\) 사실 이것도 그렇게 와닿지 않음 나중에 더 찾아보자…\n\n\n\n\n\n나무모형은 간단하고 해석상에 장점이 있으나 다른 방법들에 비해 좋은 성능을 보이지 못하는 경우가 있음\n\n\n\n1 설명변수들의 가능한 조합을 이용하여 예측공간을 \\(J\\)개의 겹치지 않는(non-overlaping)구역으로 분할\n2 각 관측값은 \\(R_j\\) 구역에 포함되며, \\(R_j\\) 구역에 포함된 training data의 반응변수 (\\(y\\))의 평균 (분류문제에선 voting방식)을 이용하여 예측\n\\[\\hat {y}_{R_j} = \\frac {1}{n_j} \\sum_{k\\in R_J} y_k \\]\n3 목표 : 다음의 RSS를 최소화 하는 구역 \\(R_1,R_2, R_J\\)를 찾는 것\n\\[RSS = \\sum_{j=1}^{J} \\sum_{i \\in R_j} (y_i - \\hat {y}_{R_{j}})^2\\]\n4 모든 조합을 확인하는 것은 불가능…(사실 가능하다. tree를 무한정 쪼개면)\n\n근데 tree를 무한정 쪼갤경우 과적합문제가 무조건 발생\n\n5 정지규칙 (stopping rule)\n\n모든 자료가 한 범주에 속할 때\n노드에 속하는 자료가 일정 수 이하일 떄\nMSE의 감소량이 아주 작을 떄\n뿌리마디로부터의 깊이가 일정 수 이상일 떄 등 (max_depth)\n\n6 가지치기 : 과적합을 막기위한 방법\n\n사실 정지규칙도 이에 포함됨, 따라서 위에거 + 빠진 내용을 적겠음\nmin_samples_leaf(default = 1) : leaf노드가 되기 위한 최소한의 샘플 수\nmin_samples_split(default = 20 : 노드를 분할하기 위한 최소한의 샘플 수 (값을 적게 설정할수록 계순 분할되어, 과적합 발생 위험 증가)\nmax_feature : 최선의 분할을 위해 고려할 변수(feature) 개수\n\nsqrt : 전체 변수 개수의 루트\nauto : sqrt와 같은 의미\nlog : \\(\\log_{2}\\) (전체 변수의 수)\n\nmax_leaf_node : 리프 노드의 최대 개수 \\(\\to\\) \\(\\text{Cost complexity Pruning}\\)\n\n\\(|T|\\)는 터미널도드로 리프노드의 개수를 뜻한다.\n\\(R_{\\alpha}(T)\\)는 변하지 않는 비용함수로 \\(R(T)\\)는 우리가 알고 있는 \\(RSS\\)와 같다.\n아래식이 뜻하는 바는 리프노드의 개수가 클수록 \\(R(T)\\) 훈련 데이터 셋에대한 \\(RSS\\)가 작아져 과적합 문제가 발생할 수 있기 때문에 적절한 리프노드의 개수를 설정해야한다는 의미이다.\n\\(\\alpha\\)는 \\(\\text {tuning parameter}\\)로 복잡도를 조절한다. 만약 \\(\\alpha\\)가 0이라면 기존의 비용함수와 같고 1에 가까워질수록 \\(R(T)\\)값이 작아진다.\n따라서 우리는 적절한 \\(\\alpha\\)값과 \\(|T|\\)값을 교차검증 기법을 통해 찾아내어 가지치기를 수행하여야한다.\n\n\n\\[\\begin {align}R_{\\alpha}(T) &= \\sum R(T) + \\alpha |T|  \\\\ \\\\\n                                                          &= \\sum_{m=1}^{|T|} \\sum_{x_i \\in R_m} (y_i - \\hat {y}_{R_m})^2 +  \\alpha |T|  \\end {align}\\]\n7 비용함수\n\n지니 지수 (Gini Index)\n\n\\[Gini (D) = 1- \\sum_{k=1}^{K}p_{k}^2 = \\sum_{k=1}^{K} p_k(1-p_k)\\]\n\\[p_k : \\text{Node D에서 k번째 범주에 속하는 관측 비율}\\]\n\n\n\n\n순수하게 분류되면 값은 0이다.\n만약 분리규칙 \\(A\\)에 의해서 Node D가 \\(D_1, D_2\\)로 분리된다면, 분리규칙 \\(A\\)에서 Ginin지수는 다음과 같다.\n\n\\[Gini_A(D) =\\frac {|D_1|}{|D|}Gini(D_1) +\\frac {|D_2|}{|D|}Gini(D_2) \\]\n\n위에 근거하여 분리규칙 A에서 발생한 불순도 감소량은 다음과 같이 정의할 수 있다.\n\n\\[\\Delta Gini(A) = Gini(D) - Gini_{A}(D)\\]\n\n따라서, \\(Gini_{A}(D)\\)를 가장 작게 하거나 \\(\\Delta Gini(A)\\)를 가장 크게 하는 분리 규칙을 선택!\n\n\n\n엔트로피(Entropy)\n\n\\[\\text {Entropy}  = -\\sum_{i=1}^m p_i\\log_{2} p_i\\]\n\n순수하게 분류되면 0\n\n\n정보 이득\n\n\n엔트로피와 지니지수는 단지 속성의 불순도를 표현한다.\n우리가 알고 싶은 것은 “어떠한 속성이 얼마나 많은 정보를 제공하는가!” 이다.\n\n\\[\\text {Gain}(T,X)= \\text{Entropy}(T)-\\text{Entropy}(T,X)\\]\n\n위 식을 살펴보니 지니지수에서 했던 불순도 감소량과 비슷하지 않은가?\n\n\\[\\Delta Gini(A) = Gini(D) - Gini_{A}(D)\\]\n\n\n\n\n\n앞서 언급한 tree는 과대적합의 위험이 큰 모형임 \\(\\to\\) max_depth를 무작정 깊게 하면 과대적합이 발생하므로\n앙상블의 아이디어 : 이러한 test데이터 셋에 예측력이 약한 모델을 결합해서 성능이 좋은 모델을 만들자!\n\n\n\n- 여러 모델들의 예측결과를 투표를 통해 최종 예측결과를 결정\n\n하드 보팅 : 다수 모델이 예측한 값이 최종 결과값\n소프트 보팅 : 모든 모델이 예측한 레이블 값의 결정 확률 평균을 구한 뒤 가장 확률이 높은 값을 최종 선택\n\n\n\n\n- Boostrap Aggregating\n- 아이디어 : 모형의 분산을 줄여 과적합을 방지하자.\n\n만약, 모집단으로부터 여러개의 훈련자료를 얻을 수 있고 이로부터 여러개의 모형 \\(\\hat{f}_1(x)\\dots \\hat{f}_b(x)\\)를 얻을 수 있다면, 다음과 같이 분산을 줄일 수 있다.\n\n\\[\\hat{f}_{avg}(x) = \\frac {1}{B} \\sum_{i=1}^{B} \\hat{f}_b(x)\\]\n\n보통은 한 set의 자료만이 주어지게 되므로 위 방식은 직접 적용이 불가능\n그래서 우리는 복원추출을 기반으로 같은 size의 표본을 추출해 각각의 모델링을 수행한다. (Bootstrap sample)\n\n\\[X_1^{*}\\dots X_B^{*}\\]\n\\[\\hat{f}_{\\text{bag}}(x) = \\frac {1}{B} \\sum_{i=1}^{B} \\hat{f}^{*}_b(x)\\]\n\n보팅과 다른점은 보팅은 여러개의 예측모델, 배깅은 동일한 예측모델 여러개를 앙상블하는 것임!\n대표적인 모델 : Randoms Forest\n\n\n\n- 여러 tree모델이 전체 데이터에서 배깅 방식으로 각자의 데이터를 샘플링\n\n모델들이 개별적으로 학습을 수행한 뒤 모든 결과를 집계하여 최종 결과를 결정\n\n# 불러오기\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import *\n\n# 선언하기\nmodel = RandomForestClassifier(max_depth=5, random_state=1)\n\n# 학습하기\nmodel.fit(x_train, y_train)\n\n# 예측하기\ny_pred = model.predict(x_test)\n- Out-of-Bag은 생략 (ISLP 교재참고)\n- RF 모델의 변수 선택\n\n하나의 트리를 형성하는 과정에서, 각 노드에서 전체 \\(p\\)개의 설명변수 중 \\(m\\)개만을 임의로 추출하여 분리 규칙을 생성한다.\n\n일반적으로 \\(m \\approx \\sqrt {p}\\)\n\n\nRandomForestClassifier( max_features='sqrt') ## default\n- 변수 중요도 (Variable Importance measur)\n\n사실 여러 형태의 나무를 결합하여 산출된 모델은…. 해석이 거의 불가능해진다.\n대안적으로, 나무들을 생성할 떄 어떠한 변수들이 RSS 혹은 Gini index 등에 큰 감소를 가져왔는지를 요약한 값으로 변수의 중요도를 파악할 수 있음.\n\\(B\\)개의 모형에 대한 평균적인 기여 정도로 변수의 중요도를 평가하게 된다!\nscikit-learn 참고링크\n\n\n\n\n\n\n\n\n\n\n같은 유형의 약한 예측 모형을 결합하여 매우 정확한 예측 모형을 만드는 방법\n예측 모형을 순차적으로(Sequentially) 학습하여 먼저 학습된 모형의 결과가 다음 모형의 학습 시 정보를 제공\n즉, 이전 모형의 약점(잔차)를 학습하여 보완한다.\n\n\n\n\n\n배깅에 비해 성능이 좋지만, 속도가 느리고 과적합 발생 가능성이 있음.\n대표적인 부스팅 알고리즘 : XGBoost, LightGBM\n\n- Boosting의 원리 (ISLP 기준)\n\n초기값 셋팅 \\(\\hat{f}(x) = 0, r_1 = y_1\\)\nFor \\(b = 1, 2\\dots B , repaet\\) :\n\n\\[\\hat {f}(x)_{i+1} = \\hat {f}(x)_{i} + \\lambda \\hat {f}^{b}(x)\\]\n\nupdate the residual,\n\n\\[r_{i+1} = r_{i}- \\lambda \\hat{f}^{b} (x) \\]\n\n초기 셋팅된 \\(\\hat {f}_1 = 0\\) 이므로\n\n\\[\\hat {f}(x)_{\\text{final}} = \\sum_{i=1}^{B} \\lambda \\hat {f}^{b}(x)\\]\n- 위 같은 방식의 문제점 \\(\\to\\) 과적합발생… 당연하다. 예측 모형을 순차적으로 학습한다는 것은 모형간 자기 상관성이 존재하고 모형의 분산이 증가하기 때문에 과적합이 발생할 수 밖에 없다…\n- 이를 막기위해 나온 모델이 XGBoost!\n\n\n- Extreme Gradient Boost\n\nreview : 방금 정리했던 Boosting기법과 같이 기본 학습기를 의사결정나무로 하며, 잔차를 이용해 이전 모형의 약점을 보완하는 방식으로 학습한다.\n+\\(\\alpha\\) : 기존의 Graident Tree Boosting에 과적합 방지를 위한 파라미터\\((\\lambda, \\gamma)\\)가 추가된 알고리즘이다.\n\n\n\n0 parameter\n\n\\(L\\) : 손실함수\n\\(M\\) : 개별 모형의 최대 개수\n\\(l\\) : 학습률\n\\(\\gamma, \\lambda\\) : 과적합 방지를 위한 파라미터\n\n1. 초기 모형은 상수로 설정하며 다음과 같이 손실함수를 최소화 하는 모형으로 설정한다.\n\n초기 모형(상수값)을 아무렇게나 설정해도 된다고 하지만… 최적화 관점에서 아래처럼 잡아주는게 적절한 듯 하다.\n\n\\[F_{0}(x) = \\underset {c}{\\text{arg min}}  \\sum_{i=1}^{n} L(y_i,c)  \\]\n2 \\(m = 1,\\dots M\\)에 대하여 다음을 반복\n\n\nGradient \\(g_i\\)와 Hessian \\(h_i\\)를 계산\n\n\n\\[g_i = \\left[ \\frac {\\partial L(y_i, F(x_i))}{\\partial  F(x_i)}\\right],\\quad F(x_i) = \\hat {F}_{m-1}(x)\\]\n\\[h_i = \\left[ \\frac {\\partial^2 L(y_i, F(x_i))}{\\partial  F(x_i)^2}\\right],\\quad F(x_i) = \\hat {F}_{m-1}(x)\\]\n\n\n회귀나무 \\(\\phi_m\\)을 다음과 같이 적합\n\n\n\\[l = \\sum_{i=1}^{n} \\frac {1}{2}h_i \\left [ - \\frac {g_i}{h_i} - \\phi(x_i) \\right ]  + \\gamma T + \\frac {1}{2} \\lambda ||\\phi||^2\\]\n\\[\\phi_m = \\underset {\\phi} {\\text{arg min}} \\sum_{i=1}^{n} \\frac {1}{2}h_i \\left [ - \\frac {g_i}{h_i} - \\phi(x_i) \\right ]  + \\gamma T + \\frac {1}{2} \\lambda ||\\phi||^2\\]\n\n여기서 \\(T\\)는 \\(\\phi\\)의 끝마디 개수, \\(||\\phi||^2 = \\sum_{j=1}^{T} w_j^2\\) 이며 \\(w_j\\)는 \\(j\\)번째 끝마디에서의 출력값이다.\n\n잘 살펴보면 릿지회귀분석에 L2 penalty와 비슷한데, L1 penalty 방식도 지원하는 것 같다.\n\n\n다음과 같이 업데이트 한다.\n\n\n\\[ F_{m}(x) = F_{m-1}(x) + l\\cdot \\phi_m(x)\\]\n3 최종모형은?\n\\[F_M(x) =  \\sum_{m=0}^{M} F_m(x)\\]\n4 summary\n\nXGBoost는 기존 Gradient Boosting기법에 문제인 과적합문제를 해결하기 위해 \\(\\gamma, \\lambda\\) 파라미터를 사용한다.(규제)\n손실함수를 살펴보면 터미널 노드(끝마디 노드)의 수와 끝마디에서의 출력값에 대한 패널티 파라미터가 들어가있다,\n의사결정나무에 가지치기 과정에서 터미널 노드의 개수에 따라 panelty를 부여하는 방식을 생각해보면 비슷한 방식이다.\n또한, 내장된 교차 검증? (이거는 이론적으로 구현되어있다기보단 사이킷런에서 내부적으로 동작하게 만든것 같음)\n\n여튼 여기서 조기 중단을 가능하게끔 지원해준다.\n\n결측치 자체 처리 : 알아서 결측치를 고려해서 학습을 한다.(결측치 여부를 노드 분기를 위한 질문에 포함시킴)\n\n이것도 사이킷런에서 내부적으로 구현한듯\n그래도 명시적으로 결측치에 대한 처리를 진행하기를 권고…\n\n\n5 실습 코드\n# 불러오기\nfrom xgboost import XGBRegressor\nfrom sklearn.metrics import mean_absolute_error, r2_score\n\n# 선언하기\nmodel = XGBRegressor(max_depth=5, n_estimators=100, random_state=1)\n\n# 학습하기\nmodel.fit(x_train, y_train)\n\n# 예측하기\ny_pred = model.predict(x_test)\n\n# 평가하기\nprint(mean_absolute_error(y_test, y_pred))\nprint(r2_score(y_test, y_pred))\n6 주요 파라미터\n\nlearning_rate : 학습률(default = 0.1)\nn_estimators : 나무의 개수 (default = 100)\nmid_child_weight : 트리에서 추가적으로 분할할 지를 결정하기 위해 필요한 데이터들의 weight(\\(w_i\\))들의 총함 (default = 1)\ngamma : 트리에서 추가적으로 분할할지를 결정하기 위한 값 \\(\\gamma T\\) (default = 0)\nmax_depth : 나무의 깊이 (default = 6)\nsub_sample : weak learner가 학습에 사용되는 데이터 샘플링 비율\n\n과적합이 염려되는 경우 1보다 작은 값으로 설정, (default = 1)\n\ncolsample_bytree : 트리 생성에 필요한 변수 선택 비율\n\n변수가 많은 경우 과적합을 조절하기 위해서 사용, 기본값 = 1\n\nreg_lambda : L2규제 적용값 (\\(\\lambda \\sum_{j=1}^{T} w_j^2\\), 기본값 \\(\\lambda = 1\\))\nreg_alpha : L1규제 적용값 (\\(\\alpha \\sum_{j=1}^{T} |w|\\), 기본값 \\(\\alpha = 0\\))\nearly_stopping_rounds : n_estimators만큼 학습을 반복하지 않더라도 조기 종료 가능(default = 10, 10번 동안 성능 향상이 없으면 학습 중단.)\n\n\n\n\n\n\n\n- 기본 아이디어 : 두 클래스 사이에 가장 넓은 도로를 내는 것\n- 용어 정리\n\n결정 경계 (Decision Boundary) or 초평면\n\n클래스를 구분하는 경계선\n결정 경계가 바로 모델 (Hyper plane)이라고 부름\n\n벡터 : 모든 데이터 포인트\n서포트 벡터 : 결정경계와 가끼운 데이터 포인트\n\n마진의 크기와 결정경계에 영향을 미침\n\n마진(margin) : 서포트 벡터와 결정경계 사이의 거리\n\n폭이 가장 넓은 도로를 찾는 것이 SVM의 목표\n마진이 클수록 새로운 데이터에 대해 안정적인 분류가 가능해지는 것임\n\n잘 생각해보면 마진의 크기가 좁을수록 정확한 분류가 일어나나 과적합 문제가 발생하므로\n마진의 크기와 오류에 대한 허용 정도는 Trade-off 관계에 있는 것을 알 수 있다.\n이것을 조절하는 파라미터 \\(\\to\\) 비용(C)\n\n- 이를 이해하기 위해서!\n\nSupport vector classifier의 decision boundary는 다음과 같은 최적화 문제의 해로 정의된다.\n\n\n만약, label = {1,-1}이라 하면 초평면은 다음과 같은 성질을 가진다.\n\n\\[\\text {Hyper plane}=  \\beta_0+ \\beta_1x_{i1}+\\dots \\beta_1x_{ip} = 0\\]\n\\[\\beta_0+ \\beta_1x_{i1}+\\dots \\beta_1x_{ip} &gt; 0, \\quad \\text{if }  y_i=1\\]\n\\[\\beta_0+ \\beta_1x_{i1}+\\dots \\beta_1x_{ip} &lt; 0, \\quad \\text{if }  y_i=-1\\]\n\n이는 다음과 같이 간단히 표현할 수 있다.\n\n\\[y_i(\\beta_0+ \\beta_1x_{i1}+\\dots \\beta_1x_{ip}) &gt; 0\\]\n\n아래의 두 식은 관측치가 초평면을 중심으로 두 class를 정확히 구분되고, 관측치와 초평면사이의 직교거리가 최소 \\(M\\)이상이 되도록 보장해 주는 조건이다.\n\n\\[\\underset{\\beta_0,\\beta_1 \\dots \\beta_p, M}{\\text {maximize} M} \\]\n\\[ \\sum_{i=1}^{p} \\beta_j^2 =  1\\]\n\\[y_i(\\beta_0+ \\beta_1x_{i1}+\\dots \\beta_1x_{ip}) &gt; M\\]\n\n그러나 실제로 관측치는 두 개의 class로 정확히 구분되지 않은 경우가 더 많으며 한 두개의 관측치에 큰 영향을 받을 수 있다,(Not robust)\n\n\n관측치에 영향을 받아 초평면이 영향을 받은 예시\n\n\n\n\n\n이를 해결하기 위해 \\(C&gt;0\\), tuning parameter와 \\(\\epsilon_i\\)(slack bariable)를 사용\n\n\\[\\underset{\\beta_0,\\beta_1 \\dots \\beta_p, M}{\\text {maximize} M}, \\sum_{i=1}^{p} \\beta_j^2 =  1 \\]\n\\[y_i(\\beta_0+ \\beta_1x_{i1}+\\dots \\beta_1x_{ip}) &gt; M(1-\\epsilon_i) \\quad  (\\epsilon_i &gt; 0,  \\sum_{i=1}^n \\epsilon_i \\leq C)\\]\n\n\\(C\\)가 커질수록 margin이 넓어짐\n\\(C\\)를 작게하면 현 데이터의 정확한 분류에 더 집중하게 되므로 자료 적합성이 좋아짐, 즉 bias는 감소하고 variance는 증가\nmargin 위 혹은 안쪽에 위치한 관측치들을 일컬어 support vector라고 한다.\n\n\nC값에 따른 margin 변화\n\n\n\n\n\n여기에서 \\(C\\)값이 가장 큰 것은 왼쪽 맨위 그림이다. \\(\\to\\) 직관적으로 \\(C\\)는 허용한계이므로 \\(M\\)즉, 마진의 넓이를 넓힌다고 생각하자.\n잠깐 생각해야될 문제\n\n\n\n\n\n우리는 여태껏 직선의 경우인 Support vector classifier를 생각했다. 근데 위에 처럼 생긴다면….\n\n- 그래서 고안된 방법이 본격적인 SVM(support vector machine)이다.\n\n고차원의 decision boundary를 고려함. \\(\\to\\) 예를 들어, 2차항까지 고려한 최적화 문제의 해로써 decision boundary를 정의할 수 있음…\n\n\\[\\underset{\\beta_0,\\beta_{11},\\dots,\\beta_{p1},\\beta_{12},\\dots,\\beta_{p2},\\varepsilon_1,\\dots ,\\varepsilon_n,M} {\\text {maximize}}M\\]\n\\[\\sum_{i=1}^{p}\\sum_{k=1}^2 \\beta_{jk}^2 = 1\\]\n\\[y_i \\left( \\beta_0 + \\sum_{j=1}^{p} \\beta_{j1}x_{ij} + \\sum_{j=1}^{p}\\beta_{i2}x_{ij}^2\\right) &gt; M(1-\\varepsilon_i)\\]\n\\[\\epsilon_i &gt; 0,  \\sum_{i=1}^n \\epsilon_i \\leq C\\]\n- 단순히 확장한 것에 불과하지 않은가???\n\nsupport vector classifier을 찾기 위해서는 관측치들간의 내적(inner product)을 계산하는 것으로 충분함이 알려져 있음\n이러한 내적을 여러 방면으로 일반화하여 표현할 수 있는데 이를 규정해 주는 함수를 kernel 이라 한다. (이 부분은 설명 생략!)\n\n- kernel 종류\n\npoly(다항), rbf(Radial Basis Function), sigmoid, linear\n\n\n\n- 걍 넘어가려고 했는데 안되겠음 \\(\\to\\) ㅅㅂ… 결과를 납득할 수 없다. 진짜 다시보자\n\n\nCode\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nfrom sklearn import svm\n\n# we create 40 separable points\nnp.random.seed(0)\nX = np.r_[np.random.randn(20, 2) - [2, 2], np.random.randn(20, 2) + [2, 2]]\nY = [0] * 20 + [1] * 20\n\n# figure number\nfignum = 1\n\n# fit the model\nfor name, penalty in ((\"unreg\", 1), (\"reg\", 0.05)):\n    clf = svm.SVC(kernel=\"linear\", C=penalty)\n    clf.fit(X, Y)\n\n    # get the separating hyperplane\n    w = clf.coef_[0]\n    a = -w[0] / w[1]\n    xx = np.linspace(-5, 5)\n    yy = a * xx - (clf.intercept_[0]) / w[1]\n\n    # plot the parallels to the separating hyperplane that pass through the\n    # support vectors (margin away from hyperplane in direction\n    # perpendicular to hyperplane). This is sqrt(1+a^2) away vertically in\n    # 2-d.\n    margin = 1 / np.sqrt(np.sum(clf.coef_**2))\n    yy_down = yy - np.sqrt(1 + a**2) * margin\n    yy_up = yy + np.sqrt(1 + a**2) * margin\n\n    # plot the line, the points, and the nearest vectors to the plane\n    plt.figure(fignum, figsize=(4, 3))\n    plt.clf()\n    plt.plot(xx, yy, \"k-\")\n    plt.plot(xx, yy_down, \"k--\")\n    plt.plot(xx, yy_up, \"k--\")\n    plt.title(f\"C={penalty}\")\n    plt.scatter(\n        clf.support_vectors_[:, 0],\n        clf.support_vectors_[:, 1],\n        s=80,\n        facecolors=\"none\",\n        zorder=10,\n        edgecolors=\"k\",\n    )\n    plt.scatter(\n        X[:, 0], X[:, 1], c=Y, zorder=10, cmap=plt.get_cmap(\"RdBu\"), edgecolors=\"k\"\n    )\n\n    plt.axis(\"tight\")\n    x_min = -4.8\n    x_max = 4.2\n    y_min = -6\n    y_max = 6\n\n    YY, XX = np.meshgrid(yy, xx)\n    xy = np.vstack([XX.ravel(), YY.ravel()]).T\n    Z = clf.decision_function(xy).reshape(XX.shape)\n\n    # Put the result into a contour plot\n    plt.contourf(XX, YY, Z, cmap=plt.get_cmap(\"RdBu\"), alpha=0.5, linestyles=[\"-\"])\n\n    plt.xlim(x_min, x_max)\n    plt.ylim(y_min, y_max)\n    fignum = fignum + 1\n\nplt.show()"
  },
  {
    "objectID": "posts/advanced/2023-01-21-Extra 01. summary (1).html#k-fold-cross-validation",
    "href": "posts/advanced/2023-01-21-Extra 01. summary (1).html#k-fold-cross-validation",
    "title": "Extra 01. summary (1)",
    "section": "",
    "text": "- 우리가 기존의 하던 방식\n\nfrom sklearn.model_selection import train_test_split\n\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3, random_state = 2023)\n- 단점\n\n랜덤하게 자료를 분할하기 때문에 분할결과에 따라 추정의 변동성이 크다….\n특히 자료위 크기가 작거나 이상/영향치들이 포함되어 있는 경우에 더더욱 그러함.\n또한, 원 자료의 크기 보다 작은 집합의 훈련자료가 모형적합에 사용되기 때문에 test error가 과대추정될 수 있음.\n\n\n이러한 방법을 \\(\\text {Validation set Approach}\\)라고 한다….\n\n- K-fold Cross Validation 방식\n\n\n\n\n전체 자료를 \\(k\\)개의 집합으로 분할한 후그 중 하나의 집합 (\\(i\\))번째 집합을 평가자료롤 설정(위 그림의 경우 \\(i=1,2 \\dots 5\\))\n그 후 각 정확도를 평균냄 (교제에서는 \\(MSE\\)를 평균 냈는데, 이번 강의에서는 정확도를 평균내더라…)\n\n\\[\\text {CV}_{5} = \\frac {1}{5} \\sum_{i=1}^{5} \\text{Accuracy}_{i}\\]\n# 1단계: 불러오기\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import cross_val_score\n\n# 2단계: 선언하기\nmodel = DecisionTreeClassifier(max_depth=3)\n\n# 3단계: 검증하기\ncv_score = cross_val_score(model, x_train, y_train, cv=10)\n\n# 확인\nprint(cv_score)\nprint(cv_score.mean())\n= 장점\n\n모든 데이터가 학습과 평가에 사용됨\n데이터가 부족해서 발생하는 과소적합 문제을 방지할 수 있음\n 좀 더 일반화된 모델 을 만들 수 있음\ntest error의 과대추정을 방지\n\n- 단점\n\n반복 횟수가 많아서 모델 학습과 평가에 많은 시간이 소요"
  },
  {
    "objectID": "posts/advanced/2023-01-21-Extra 01. summary (1).html#search",
    "href": "posts/advanced/2023-01-21-Extra 01. summary (1).html#search",
    "title": "Extra 01. summary (1)",
    "section": "",
    "text": "- 일단, 튜닝 시 모델들의 각 파라미터들에 값을 어떻게 하느냐에 따라 성능이 달라지는 것을 확인할 수 있었음\n- grid search의 아이디어는 가능한 파라미터 값 범위를 지정해 해당 범위에서의 값을 모두 사용하는 것이다.\n\n당연히 정확도는 높으나….시간이 오래 걸리겠지라는 생각을 해볼 수 있다.\n\n\n요런느낌\n\n# 함수 불러오기\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import GridSearchCV\n\n# 파라미터 선언\nparam = {'n_neighbors': range(1, 500, 10), 'metric': ['euclidean', 'manhattan']}\n\n# 기본모델 선언\nknn_model = KNeighborsClassifier()\n\n# Grid Search 선언\nmodel = GridSearchCV(knn_model, param, cv=3)\n\n\n\n- 그리드 서치처럼 파라미터 범위를 지정하는 것은 동일\n- 설정한 파라미터 값 범위에서 몇 개를 선택할지를 정하여 Random Search 모델 선언 후 학습\n- 학습 데이터에 대해 가장 좋은 성능을 보인 파라미터 값으로 자동 학습함.\n\n참고로 Grid Search, Random Search를 사용할 때 내부적으로 K-Fold Cross Validation을 위해 cv값을 지정하므로!\n실제 수행되는 횟수는  파라미터 조합 수 x CV값이 된다.\n\n\ncode\n\n# 함수 불러오기\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import RandomizedSearchCV\n\n\n# 파라미터 선언\nparam = {'n_neighbors': range(1, 500, 10),\n'metric': ['euclidean', 'manhattan']}\n\n# 기본모델 선언\nknn_model = KNeighborsClassifier()\n# Random Search 선언\nmodel = RandomizedSearchCV(knn_model, \n                                                       param, cv=3, # (default = 5)\n                                                           n_iter=20) ### 전체 파라미터 범위에서 몇 개를 뽑을 것인지 (default = 10)\n\n또한, 두 가지 기법을 섞어서 사용할 수 있음! (강의자료 참고)"
  },
  {
    "objectID": "posts/advanced/2023-01-21-Extra 01. summary (1).html#클래스-불균형",
    "href": "posts/advanced/2023-01-21-Extra 01. summary (1).html#클래스-불균형",
    "title": "Extra 01. summary (1)",
    "section": "",
    "text": "- 머신러닝 알고리즘은 데이터가 클래스 간에 균형 있게 분포되어 있다고 가정함\n\nexample : 생존자와 사망자 수가 거의 같을 것이다~~\n\n- 클래스 불균형으로 인한 재현율이 형편없어지는 경우는 아래 링크를 참고!\n\n재현율\n\n\n\n- under sampling\n\n다수 클래스 데이터를 소수 클래스 수 만큼 랜덤 샘플링\n\n- over sampling\n\n소수의 클래스 데이터를 다수 클래스 수 만큼 랜덤 샘플링\n\n# pip install imbalanced-learn\n# 불러오기\nfrom imblearn.under_sampling import RandomUnderSampler\n\n# Under Sampling\nunder_sample = RandomUnderSampler()\nu_x_train, u_y_train = under_sample.fit_resample(x_train, y_train)\n\n# 확인\nprint('전:', np.bincount(y_train))\nprint('후:', np.bincount(u_y_train))\n\n# 불러오기\nfrom imblearn.over_sampling import RandomOverSampler\n\n# Over Sampling\nover_sample = RandomOverSampler()\no_x_train, o_y_train = over_sample.fit_resample(x_train, y_train)\n\n# 확인\nprint('전:', np.bincount(y_train))\nprint('후:', np.bincount(o_y_train))\n- over sampling (2)\n# 불러오기\nfrom imblearn.over_sampling import SMOTE\n\n# Over Sampling\nsmote = SMOTE()\ns_x_train, s_y_train = smote.fit_resample(x_train, y_train)\n\n# 확인\nprint('전:', np.bincount(y_train))\nprint('후:', np.bincount(s_y_train))\n\n\n\n- resampling 없이 클래스에 가중치를 부여하여 클래스 불균형 문제를 해결해줌\n\n학습하는 동안 알고리즘의 비용함수에서 소수 클래스에 더 많은 가중치를 부여하여 소수 클래스에 더 높은 패널티를 제공함으로써, 소수 클래스에 대한 오류를 줄이게 됨\nsklearn에서 제공하는 알고리즘 대부분 class_weight라는 하이퍼 파라미터를 제공한다.\n\nclass_weight = ‘None’ : 기본값\nclass_weight = ‘balanced’: y_train의 class 비율을 역으로 적용\nclass_weight={0:0.2, 1:0.8}: 비율 지정, 단 비율의 합은 1\n\n주의! \\(\\to\\) 전반적인 성능을 높이기 위한 작업이 아니라, 소수 클래스 성능을 높이기 위한 작업임!"
  },
  {
    "objectID": "posts/advanced/2023-01-21-Extra 01. summary (1).html#excersise",
    "href": "posts/advanced/2023-01-21-Extra 01. summary (1).html#excersise",
    "title": "Extra 01. summary (1)",
    "section": "",
    "text": "# 라이브러리 불러오기\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nimport plotly.io as pio\npio.renderers.default = \"plotly_mimetype+notebook_connected\"\n\nwarnings.filterwarnings(action='ignore')\n%config InlineBackend.figure_format = 'retina'\n\n\n\n\n\n# 데이터 불러오기\npath = 'https://raw.githubusercontent.com/jangrae/csv/master/airline_satisfaction_small.csv'\ndata = pd.read_csv(path)\n\n\ndata.head()\n\n\n\n\n\n\n\n\nid\ngender\ncustomer_type\nage\ntype_of_travel\nclass\nflight_distance\ninflight_wifi_service\ndeparture/arrival_time_convenient\nease_of_online_booking\n...\ninflight_entertainment\non-board_service\nleg_room_service\nbaggage_handling\ncheckin_service\ninflight_service\ncleanliness\ndeparture_delay_in_minutes\narrival_delay_in_minutes\nsatisfaction\n\n\n\n\n0\n70172\nMale\nLoyal Customer\n13\nPersonal Travel\nEco Plus\n460\n3\n4\n3\n...\n5\n4\n3\n4\n4\n5\n5\n25\n18.0\n0\n\n\n1\n5047\nMale\ndisloyal Customer\n25\nBusiness travel\nBusiness\n235\n3\n2\n3\n...\n1\n1\n5\n3\n1\n4\n1\n1\n6.0\n0\n\n\n2\n110028\nFemale\nLoyal Customer\n26\nBusiness travel\nBusiness\n1142\n2\n2\n2\n...\n5\n4\n3\n4\n4\n4\n5\n0\n0.0\n1\n\n\n3\n24026\nFemale\nLoyal Customer\n25\nBusiness travel\nBusiness\n562\n2\n5\n5\n...\n2\n2\n5\n3\n1\n4\n2\n11\n9.0\n0\n\n\n4\n119299\nMale\nLoyal Customer\n61\nBusiness travel\nBusiness\n214\n3\n3\n3\n...\n3\n3\n4\n4\n3\n3\n3\n0\n0.0\n1\n\n\n\n\n5 rows × 24 columns\n\n\n\n\ndata.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 2580 entries, 0 to 2579\nData columns (total 24 columns):\n #   Column                             Non-Null Count  Dtype  \n---  ------                             --------------  -----  \n 0   id                                 2580 non-null   int64  \n 1   gender                             2580 non-null   object \n 2   customer_type                      2580 non-null   object \n 3   age                                2580 non-null   int64  \n 4   type_of_travel                     2580 non-null   object \n 5   class                              2580 non-null   object \n 6   flight_distance                    2580 non-null   int64  \n 7   inflight_wifi_service              2580 non-null   int64  \n 8   departure/arrival_time_convenient  2580 non-null   int64  \n 9   ease_of_online_booking             2580 non-null   int64  \n 10  gate_location                      2580 non-null   int64  \n 11  food_and_drink                     2580 non-null   int64  \n 12  online_boarding                    2580 non-null   int64  \n 13  seat_comfort                       2580 non-null   int64  \n 14  inflight_entertainment             2580 non-null   int64  \n 15  on-board_service                   2580 non-null   int64  \n 16  leg_room_service                   2580 non-null   int64  \n 17  baggage_handling                   2580 non-null   int64  \n 18  checkin_service                    2580 non-null   int64  \n 19  inflight_service                   2580 non-null   int64  \n 20  cleanliness                        2580 non-null   int64  \n 21  departure_delay_in_minutes         2580 non-null   int64  \n 22  arrival_delay_in_minutes           2574 non-null   float64\n 23  satisfaction                       2580 non-null   int64  \ndtypes: float64(1), int64(19), object(4)\nmemory usage: 483.9+ KB\n\n\n- 쓸모없는 변수 제거\n\n# 변수 제거\nd_cols = [\"id\", \"departure/arrival_time_convenient\", \"gate_location\", \"departure_delay_in_minutes\"]\n\n\ndata.drop(d_cols,axis=1, inplace = True)\ndata.head()\n\n\n\n\n\n\n\n\ngender\ncustomer_type\nage\ntype_of_travel\nclass\nflight_distance\ninflight_wifi_service\nease_of_online_booking\nfood_and_drink\nonline_boarding\nseat_comfort\ninflight_entertainment\non-board_service\nleg_room_service\nbaggage_handling\ncheckin_service\ninflight_service\ncleanliness\narrival_delay_in_minutes\nsatisfaction\n\n\n\n\n0\nMale\nLoyal Customer\n13\nPersonal Travel\nEco Plus\n460\n3\n3\n5\n3\n5\n5\n4\n3\n4\n4\n5\n5\n18.0\n0\n\n\n1\nMale\ndisloyal Customer\n25\nBusiness travel\nBusiness\n235\n3\n3\n1\n3\n1\n1\n1\n5\n3\n1\n4\n1\n6.0\n0\n\n\n2\nFemale\nLoyal Customer\n26\nBusiness travel\nBusiness\n1142\n2\n2\n5\n5\n5\n5\n4\n3\n4\n4\n4\n5\n0.0\n1\n\n\n3\nFemale\nLoyal Customer\n25\nBusiness travel\nBusiness\n562\n2\n5\n2\n2\n2\n2\n2\n5\n3\n1\n4\n2\n9.0\n0\n\n\n4\nMale\nLoyal Customer\n61\nBusiness travel\nBusiness\n214\n3\n3\n4\n5\n5\n3\n3\n4\n4\n3\n3\n3\n0.0\n1\n\n\n\n\n\n\n\n- 결측치 확인\n\nprint(data.columns[data.isna().sum() !=0])\n\nIndex(['arrival_delay_in_minutes'], dtype='object')\n\n\n\ndata.arrival_delay_in_minutes.isna().sum()\n\n6\n\n\n- 현재 arrival_delay_in_minutes의 6개 결측치가 확인된다.\n\n결측치 제거를 위해 해당 변수의 분포를 확인하자.\n\n\ndata.plot(x=\"arrival_delay_in_minutes\",  kind = \"hist\", backend  = \"plotly\",\n                  width = 1000, height = 400,nbins=100)\n\n\n                                                \n\n\n- 대부분의 값들이 0값 근처에 몰려있으니 결측값을 0으로 대체하자.\n\ndata.arrival_delay_in_minutes.fillna(0, inplace = True)\nprint(data.columns[data.isna().sum() !=0])\n\nIndex([], dtype='object')\n\n\n- x, y 분리\n\ntarget = \"satisfaction\"\n\nx = data.drop(target, axis = 1)\ny = data[target]\n\n- 가변수화\n\nd = [\"gender\", \"customer_type\", \"type_of_travel\", \"class\"]\n\nx = pd.get_dummies(x, columns = d, drop_first = True, dtype = float)\nx.head()\n\n\n\n\n\n\n\n\nage\nflight_distance\ninflight_wifi_service\nease_of_online_booking\nfood_and_drink\nonline_boarding\nseat_comfort\ninflight_entertainment\non-board_service\nleg_room_service\nbaggage_handling\ncheckin_service\ninflight_service\ncleanliness\narrival_delay_in_minutes\ngender_Male\ncustomer_type_disloyal Customer\ntype_of_travel_Personal Travel\nclass_Eco\nclass_Eco Plus\n\n\n\n\n0\n13\n460\n3\n3\n5\n3\n5\n5\n4\n3\n4\n4\n5\n5\n18.0\n1.0\n0.0\n1.0\n0.0\n1.0\n\n\n1\n25\n235\n3\n3\n1\n3\n1\n1\n1\n5\n3\n1\n4\n1\n6.0\n1.0\n1.0\n0.0\n0.0\n0.0\n\n\n2\n26\n1142\n2\n2\n5\n5\n5\n5\n4\n3\n4\n4\n4\n5\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n\n\n3\n25\n562\n2\n5\n2\n2\n2\n2\n2\n5\n3\n1\n4\n2\n9.0\n0.0\n0.0\n0.0\n0.0\n0.0\n\n\n4\n61\n214\n3\n3\n4\n5\n5\n3\n3\n4\n4\n3\n3\n3\n0.0\n1.0\n0.0\n0.0\n0.0\n0.0\n\n\n\n\n\n\n\n- 학습, 평가용 데이터 분리\n\nfrom sklearn.model_selection import train_test_split\n\nx_train, x_test, y_train, y_test = train_test_split(x, y, random_state = 1, test_size = 0.3)\n\n\n\n\n\n\nCode\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import cross_val_score\n# 1. tree\ntree = DecisionTreeClassifier(max_depth = 5, random_state = 1)\ntree.cv = cross_val_score(tree, x_train, y_train, cv = 5)\ntree.cv_m = tree.cv.mean()\n\n# 2. logistic\nfrom sklearn.linear_model import LogisticRegression\nlogit = LogisticRegression()\nlogit.cv = cross_val_score(logit, x_train, y_train, cv = 5)\nlogit.cv_m = logit.cv.mean()\n\n# 3. RF\nfrom sklearn.ensemble import RandomForestClassifier\n\nrf = RandomForestClassifier(max_depth = 5,  random_state = 1)\nrf.cv = cross_val_score(rf, x_train,y_train)\nrf.cv_m = rf.cv.mean()\n\n# 4. XGBoost\n\nfrom xgboost import XGBClassifier\nxgb =  XGBClassifier(max_depth = 5, random_state = 1)\nxgb.cv = cross_val_score(xgb, x_train, y_train, cv = 5)\nxgb.cv_m  = xgb.cv.mean()\n\n\n\nresult = [tree.cv_m, logit.cv_m, rf.cv_m,  xgb.cv_m]\nmodel = [\"tree\",\"logit\", \"rf\", \"xgb\"]\n\nfig = pd.DataFrame({\"model\" : model, \"result\" : result}).\\\n            sort_values(\"result\", ascending = False).plot(x = \"result\", y = \"model\", kind = \"bar\", backend = \"plotly\",color = \"model\")\n\nfig.update_xaxes(range = [0.7, 1.0])\n\n\n                                                \n\n\n- cv를 기준으로 XGB 모델이 최적의 모델인 것 같다.\n\ngrid search기법을 이용하여 모델 튜닝\n\n\nfrom sklearn.model_selection import GridSearchCV\nmodel = XGBClassifier(max_depth= 5, random_state = 1)\n\nparams=  {\"max_depth\" : range(1,21)}\n\nmodel = GridSearchCV(model,\n                     params,\n                     cv=5,\n                     scoring=\"accuracy\")\n\n\nmodel.fit(x_train, y_train)\n\nGridSearchCV(cv=5,\n             estimator=XGBClassifier(base_score=None, booster=None,\n                                     callbacks=None, colsample_bylevel=None,\n                                     colsample_bynode=None,\n                                     colsample_bytree=None, device=None,\n                                     early_stopping_rounds=None,\n                                     enable_categorical=False, eval_metric=None,\n                                     feature_types=None, gamma=None,\n                                     grow_policy=None, importance_type=None,\n                                     interaction_constraints=None,\n                                     learning_rate=None, max_bin=None,\n                                     max_cat_threshold=None,\n                                     max_cat_to_onehot=None,\n                                     max_delta_step=None, max_depth=5,\n                                     max_leaves=None, min_child_weight=None,\n                                     missing=nan, monotone_constraints=None,\n                                     multi_strategy=None, n_estimators=None,\n                                     n_jobs=None, num_parallel_tree=None,\n                                     random_state=1, ...),\n             param_grid={'max_depth': range(1, 21)}, scoring='accuracy')In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.GridSearchCVGridSearchCV(cv=5,\n             estimator=XGBClassifier(base_score=None, booster=None,\n                                     callbacks=None, colsample_bylevel=None,\n                                     colsample_bynode=None,\n                                     colsample_bytree=None, device=None,\n                                     early_stopping_rounds=None,\n                                     enable_categorical=False, eval_metric=None,\n                                     feature_types=None, gamma=None,\n                                     grow_policy=None, importance_type=None,\n                                     interaction_constraints=None,\n                                     learning_rate=None, max_bin=None,\n                                     max_cat_threshold=None,\n                                     max_cat_to_onehot=None,\n                                     max_delta_step=None, max_depth=5,\n                                     max_leaves=None, min_child_weight=None,\n                                     missing=nan, monotone_constraints=None,\n                                     multi_strategy=None, n_estimators=None,\n                                     n_jobs=None, num_parallel_tree=None,\n                                     random_state=1, ...),\n             param_grid={'max_depth': range(1, 21)}, scoring='accuracy')estimator: XGBClassifierXGBClassifier(base_score=None, booster=None, callbacks=None,\n              colsample_bylevel=None, colsample_bynode=None,\n              colsample_bytree=None, device=None, early_stopping_rounds=None,\n              enable_categorical=False, eval_metric=None, feature_types=None,\n              gamma=None, grow_policy=None, importance_type=None,\n              interaction_constraints=None, learning_rate=None, max_bin=None,\n              max_cat_threshold=None, max_cat_to_onehot=None,\n              max_delta_step=None, max_depth=5, max_leaves=None,\n              min_child_weight=None, missing=nan, monotone_constraints=None,\n              multi_strategy=None, n_estimators=None, n_jobs=None,\n              num_parallel_tree=None, random_state=1, ...)XGBClassifierXGBClassifier(base_score=None, booster=None, callbacks=None,\n              colsample_bylevel=None, colsample_bynode=None,\n              colsample_bytree=None, device=None, early_stopping_rounds=None,\n              enable_categorical=False, eval_metric=None, feature_types=None,\n              gamma=None, grow_policy=None, importance_type=None,\n              interaction_constraints=None, learning_rate=None, max_bin=None,\n              max_cat_threshold=None, max_cat_to_onehot=None,\n              max_delta_step=None, max_depth=5, max_leaves=None,\n              min_child_weight=None, missing=nan, monotone_constraints=None,\n              multi_strategy=None, n_estimators=None, n_jobs=None,\n              num_parallel_tree=None, random_state=1, ...)\n\n\n\ny_pred = model.predict(x_test)\n\n\n# 예측 결과 확인\nprint(model.best_params_)\nprint(model.best_score_)\n\n{'max_depth': 3}\n0.9363202277283789\n\n\n\nfig = pd.DataFrame([model.best_estimator_.feature_names_in_,model.best_estimator_.feature_importances_]).T.\\\n        rename(columns = {0 : \"feature\", 1 : \"importance\"}).sort_values(\"importance\", ascending = False).\\\n            plot(y = \"feature\", x=  \"importance\", kind = \"barh\",\n                    backend = \"plotly\",color = \"feature\")\n\nfig.update_layout(showlegend = False)\n\n\n                                                \n\n\n\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n\nmeasure = [\"accuracy\", \"precision\", \"reacll\", \"f1-score\"]\n\nacc = accuracy_score(y_test, y_pred)\npre = precision_score(y_test, y_pred)\nre = recall_score(y_test, y_pred)\nf1_score = f1_score(y_test, y_pred)\n\n\npd.DataFrame({\"measure\" : measure, \"score\" : [acc, pre, re, f1_score]})\n\n\n\n\n\n\n\n\nmeasure\nscore\n\n\n\n\n0\naccuracy\n0.931525\n\n\n1\nprecision\n0.949102\n\n\n2\nreacll\n0.898017\n\n\n3\nf1-score\n0.922853"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "GoldKiss",
    "section": "",
    "text": "Order By\n       Default\n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Title\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\nDate\n\n\nTitle\n\n\nAuthor\n\n\n\n\n\n\nNov 2, 2023\n\n\n03. Titanic\n\n\ngc \n\n\n\n\nNov 1, 2023\n\n\n02. iris\n\n\ngc \n\n\n\n\nOct 31, 2023\n\n\n01. VOC\n\n\ngc \n\n\n\n\nOct 30, 2023\n\n\n00. Churn\n\n\ngc \n\n\n\n\nJan 25, 2023\n\n\n05. MNIST\n\n\ngc \n\n\n\n\nJan 24, 2023\n\n\n04. 네이버 영화 리뷰 분류\n\n\ngc \n\n\n\n\nJan 22, 2023\n\n\n01. 텍스트 분류\n\n\nGC \n\n\n\n\nJan 22, 2023\n\n\n02. 이미지 분류\n\n\nGC \n\n\n\n\nJan 21, 2023\n\n\n00. Intro\n\n\nGC \n\n\n\n\nJan 21, 2023\n\n\n03. titanic\n\n\nGC \n\n\n\n\nJan 21, 2023\n\n\nExtra 01. summary (1)\n\n\nGC \n\n\n\n\nFeb 8, 2021\n\n\n07. pretrained Model (2)\n\n\nCIC \n\n\n\n\nFeb 8, 2021\n\n\n08. CNN with Text\n\n\nCIC \n\n\n\n\nFeb 7, 2021\n\n\n06. pretrained Model (1)\n\n\nCIC \n\n\n\n\nFeb 5, 2021\n\n\n05. MNIST\n\n\nCIC \n\n\n\n\nFeb 3, 2021\n\n\n04. image DA (3)\n\n\nCIC \n\n\n\n\nFeb 2, 2021\n\n\n03. image DA (2)\n\n\nCIC \n\n\n\n\nFeb 1, 2021\n\n\n02. image DA (1)\n\n\nCIC \n\n\n\n\nJan 30, 2021\n\n\n01. MNIST\n\n\nCIC \n\n\n\n\nJan 29, 2021\n\n\n00. CIFAR10\n\n\nCIC \n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site"
  },
  {
    "objectID": "posts/advanced/2023-01-21-00. Intro.html",
    "href": "posts/advanced/2023-01-21-00. Intro.html",
    "title": "00. Intro",
    "section": "",
    "text": "import pandas as pd\n\ndf = pd.read_csv(\"/content/voc_data.csv\")"
  },
  {
    "objectID": "posts/advanced/2023-01-21-00. Intro.html#voc_trt_perd_itg_cd-변수의-고유값-count",
    "href": "posts/advanced/2023-01-21-00. Intro.html#voc_trt_perd_itg_cd-변수의-고유값-count",
    "title": "00. Intro",
    "section": "voc_trt_perd_itg_cd 변수의 고유값 count",
    "text": "voc_trt_perd_itg_cd 변수의 고유값 count\n\ndf[\"voc_trt_perd_itg_cd\"].value_counts()\n\n_        5422\n10000    4283\n10001     163\n10002      58\n10003      25\n10004      16\n10005      10\n10006       6\n10008       3\n10009       3\n10016       2\n10011       2\n10012       2\n10007       2\n10014       1\n10013       1\n10015       1\nName: voc_trt_perd_itg_cd, dtype: int64\n\n\n\ndf[\"voc_trt_perd_itg_cd\"].value_counts(normalize = True)\n\n_        0.5422\n10000    0.4283\n10001    0.0163\n10002    0.0058\n10003    0.0025\n10004    0.0016\n10005    0.0010\n10006    0.0006\n10008    0.0003\n10009    0.0003\n10016    0.0002\n10011    0.0002\n10012    0.0002\n10007    0.0002\n10014    0.0001\n10013    0.0001\n10015    0.0001\nName: voc_trt_perd_itg_cd, dtype: float64"
  },
  {
    "objectID": "posts/advanced/2023-01-21-00. Intro.html#라벨인코딩",
    "href": "posts/advanced/2023-01-21-00. Intro.html#라벨인코딩",
    "title": "00. Intro",
    "section": "라벨인코딩",
    "text": "라벨인코딩\ncat_cols 데이터프레임에서 cust_clas_itg_cd 열의 범주형 데이터를 숫자로 인코딩하고, 그 결과를 le_cust_clas_itg_cd 열에 저장\n\nfrom sklearn.preprocessing import LabelEncoder\n\nle = LabelEncoder()\n\ncat_cols[\"le_cust_clas_itg_cd\"] = le.fit_transform(cat_cols[\"cust_clas_itg_cd\"])\n\n\ncat_cols.head()\n\n\n  \n    \n\n\n\n\n\n\ncust_clas_itg_cd\ncont_sttus_itg_cd\ncust_dtl_ctg_itg_cd\ntrm_yn\nle_cust_clas_itg_cd\n\n\n\n\n0\nF\n10001\n10003\nN\n0\n\n\n1\nG\n10001\n10002\nN\n1\n\n\n2\nG\n10001\n10003\nN\n1\n\n\n3\nL\n10001\n90024\nN\n5\n\n\n4\nG\n10001\n90024\nN\n1"
  },
  {
    "objectID": "posts/advanced/2023-01-22-01. 텍스트 분류.html",
    "href": "posts/advanced/2023-01-22-01. 텍스트 분류.html",
    "title": "01. 텍스트 분류",
    "section": "",
    "text": "- tensorflow 튜토리얼 : 영화 리뷰를 사용한 텍스트 분류\n- environment : [colab]"
  },
  {
    "objectID": "posts/advanced/2023-01-22-01. 텍스트 분류.html#리뷰-길이-분포-확인",
    "href": "posts/advanced/2023-01-22-01. 텍스트 분류.html#리뷰-길이-분포-확인",
    "title": "01. 텍스트 분류",
    "section": "리뷰 길이 분포 확인",
    "text": "리뷰 길이 분포 확인\n- train 리뷰 길이 분포 시각화\n\nimport numpy as np\n\n\nreview_length = [len(i) for i in x_train]\n\nfig,axes = plt.subplots(1,2, figsize = (12,4))\n\nax1, ax2 = axes\n\nax1.hist(review_length)\n#ax1.set_title(\"리뷰길이 hist\")\nax2.boxplot(review_length)\n#ax2.set_title(\"리뷰길이 boxplot\")\nfig.tight_layout()\nplt.show()\n\nprint(f\"리뷰의 최대 길이  : {max(review_length)}\")\nprint(f\"리뷰의 평균 길이  : {np.mean(review_length)}\")\n\n\n\n\n리뷰의 최대 길이  : 2494\n리뷰의 평균 길이  : 238.71364"
  },
  {
    "objectID": "posts/advanced/2023-01-22-01. 텍스트 분류.html#라벨-분포-확인",
    "href": "posts/advanced/2023-01-22-01. 텍스트 분류.html#라벨-분포-확인",
    "title": "01. 텍스트 분류",
    "section": "라벨 분포 확인",
    "text": "라벨 분포 확인\n\nindex = np.unique(y_train, return_counts=True)[0]\ncounts = np.unique(y_train, return_counts=True)[1]\n\nnp.asarray((index, counts))\n\narray([[    0,     1],\n       [12500, 12500]])"
  },
  {
    "objectID": "posts/advanced/2023-01-22-01. 텍스트 분류.html#정수-맵핑-단어-확인",
    "href": "posts/advanced/2023-01-22-01. 텍스트 분류.html#정수-맵핑-단어-확인",
    "title": "01. 텍스트 분류",
    "section": "정수 맵핑 단어 확인",
    "text": "정수 맵핑 단어 확인\n- imdb.get_word_index()에 각 단어와 맵핑되는 정수가 저장되어 있음\n\n주의 : 저장된 값에 +3을 해야 실제 맵핑되는 정수임 (이것은 IMDB 리뷰 데이터 셋에서 정한 규칙이다.)\n\n\nword_to_index = imdb.get_word_index()\n#word_to_index\n\n\nindex_to_word = {}\n\nfor key, value in word_to_index.items() :\n    index_to_word[value+3] = key\n\n\nindex_to_word에 인덱스를 집어넣으면 전처리 전에 어떤 단어였는지 확인할 수 있음.\n\n0,1,2,3은 특별토큰, 정수 4부터가 실제 IMDB 리뷰 데이터셋에서 내림차순으로 빈도수가 영단어임\n\n\n\nprint(f\"빈도수 상위 1등 단어 : {index_to_word[4]}\" )\n\n빈도수 상위 1등 단어 : the\n\n\n\nprint(f\"빈도수 상위 3938등 단어 : {index_to_word[3941]}\")\n\n빈도수 상위 3938등 단어 : suited\n\n\n- 첫 번째 훈련용 리뷰의 각 단어가 정수로 바뀌기 전에 어떤 단어들이 었는지 확인\n\n아래작업은 0,1,2,3 특별토큰의 값을 집어넣는 과정\n\n\nfor index, token in enumerate((\"&lt;pad&gt;\", \"&lt;sos&gt;\", \"&lt;unk&gt;\")):\n  index_to_word[index] = token\n\n\nindex_to_word[0], index_to_word[1], index_to_word[2]\n\n('&lt;pad&gt;', '&lt;sos&gt;', '&lt;unk&gt;')\n\n\n\nprint(\" \".join([index_to_word[i] for i in x_train[0]]))\n\n&lt;sos&gt; this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert redford's is an amazing actor and now the same being director norman's father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for retail and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also congratulations to the two little boy's that played the part's of norman and paul they were just brilliant children are often left out of the praising list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all"
  },
  {
    "objectID": "posts/advanced/2023-01-22-01. 텍스트 분류.html#loss-시각화",
    "href": "posts/advanced/2023-01-22-01. 텍스트 분류.html#loss-시각화",
    "title": "01. 텍스트 분류",
    "section": "loss 시각화",
    "text": "loss 시각화\n\nplt.figure(figsize = (8,4))\nplt.plot(history1[\"loss\"], label = \"train_loss\")\nplt.plot(history1[\"val_loss\"], label = \"val_loss\")\nplt.legend()\nplt.show()"
  },
  {
    "objectID": "posts/advanced/2023-01-22-01. 텍스트 분류.html#predict",
    "href": "posts/advanced/2023-01-22-01. 텍스트 분류.html#predict",
    "title": "01. 텍스트 분류",
    "section": "predict",
    "text": "predict\n\nrnn_pred1 =  model.predict(x_test)\n\n782/782 [==============================] - 3s 3ms/step\n\n\n\nrnn_pred1 = np.where(rnn_pred1&gt;0.5,1,0)\n\n\nfrom sklearn.metrics import *\n\n\nprint(confusion_matrix(y_test, rnn_pred1))\nprint(classification_report(y_test, rnn_pred1))\n\n[[8756 3744]\n [3500 9000]]\n              precision    recall  f1-score   support\n\n           0       0.71      0.70      0.71     12500\n           1       0.71      0.72      0.71     12500\n\n    accuracy                           0.71     25000\n   macro avg       0.71      0.71      0.71     25000\nweighted avg       0.71      0.71      0.71     25000"
  },
  {
    "objectID": "posts/advanced/2023-01-22-03. titanic.html",
    "href": "posts/advanced/2023-01-22-03. titanic.html",
    "title": "03. titanic",
    "section": "",
    "text": "1 Associate와 달리 성능 달성을 목적으로 이루어지는 시험\n2 별도의 가이드 라인 없이 응시자가 알아서 수행\n3 Tabular, Text(한글, 영문), Image(영상 제외) 데이터에 대한 문제가 1개씩 주어지면 3시간 동안 문제를 풀어야함.\n4 제출할 파일 목록\n\n본인핸드폰번호_1.h5(또는 다른 확장자의 모델 파일)\n본인핸드폰번호_1.csv\n시스템매핑번호_1.ipynb(본 문제지 상단 저장버튼을 눌러 저장)\n예시 : 01082478779_1.h5\n\n5 GPU 할당 코드\nimport tensorflow as tf\ngpus = tf.config.list_physical_devices(\"GPU\")\n\nif gpus :\n  try :\n    for gpu in gpus :\n          tf.config.experimental.set_memory_growth(gpu, True)\n    logical_gpus = tf.config.experimental.list_logical_devices(\"GPU\")\n    print(len(gpus), \"Physical GPUS\", len(logical_gpus), \"Logical GPUs\")\n  except RuntimeErroe as e :\n    print(e)\n6 수시로 임시저장 누르기\n7 인터넷 검색만 활용해서 문제를 풀어야 한다…(그리고 듀얼모니터 사용 불가)"
  },
  {
    "objectID": "posts/advanced/2023-01-22-03. titanic.html#데이터-로드",
    "href": "posts/advanced/2023-01-22-03. titanic.html#데이터-로드",
    "title": "03. titanic",
    "section": "데이터 로드",
    "text": "데이터 로드\n\nimport pandas as pd\nimport seaborn as sns\n\n\ndf = sns.load_dataset(\"titanic\")\ndf.head()\n\n\n  \n    \n\n\n\n\n\n\nsurvived\npclass\nsex\nage\nsibsp\nparch\nfare\nembarked\nclass\nwho\nadult_male\ndeck\nembark_town\nalive\nalone\n\n\n\n\n0\n0\n3\nmale\n22.0\n1\n0\n7.2500\nS\nThird\nman\nTrue\nNaN\nSouthampton\nno\nFalse\n\n\n1\n1\n1\nfemale\n38.0\n1\n0\n71.2833\nC\nFirst\nwoman\nFalse\nC\nCherbourg\nyes\nFalse\n\n\n2\n1\n3\nfemale\n26.0\n0\n0\n7.9250\nS\nThird\nwoman\nFalse\nNaN\nSouthampton\nyes\nTrue\n\n\n3\n1\n1\nfemale\n35.0\n1\n0\n53.1000\nS\nFirst\nwoman\nFalse\nC\nSouthampton\nyes\nFalse\n\n\n4\n0\n3\nmale\n35.0\n0\n0\n8.0500\nS\nThird\nman\nTrue\nNaN\nSouthampton\nno\nTrue\n\n\n\n\n\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n\n  \n\n\n    \n        \n    \n\n  \n\n\n\n  \n\n\n    \n  \n\n\n\ndf.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 891 entries, 0 to 890\nData columns (total 15 columns):\n #   Column       Non-Null Count  Dtype   \n---  ------       --------------  -----   \n 0   survived     891 non-null    int64   \n 1   pclass       891 non-null    int64   \n 2   sex          891 non-null    object  \n 3   age          714 non-null    float64 \n 4   sibsp        891 non-null    int64   \n 5   parch        891 non-null    int64   \n 6   fare         891 non-null    float64 \n 7   embarked     889 non-null    object  \n 8   class        891 non-null    category\n 9   who          891 non-null    object  \n 10  adult_male   891 non-null    bool    \n 11  deck         203 non-null    category\n 12  embark_town  889 non-null    object  \n 13  alive        891 non-null    object  \n 14  alone        891 non-null    bool    \ndtypes: bool(2), category(2), float64(2), int64(4), object(5)\nmemory usage: 80.7+ KB"
  },
  {
    "objectID": "posts/advanced/2023-01-22-03. titanic.html#데이터-전처리-1.-결측치가-많은-deck-변수-제거",
    "href": "posts/advanced/2023-01-22-03. titanic.html#데이터-전처리-1.-결측치가-많은-deck-변수-제거",
    "title": "03. titanic",
    "section": "데이터 전처리 1. 결측치가 많은 deck 변수 제거",
    "text": "데이터 전처리 1. 결측치가 많은 deck 변수 제거\n\ndf1 = df.drop(\"deck\", axis = 1)\n\n\ndf1.isna().sum()\n\nsurvived         0\npclass           0\nsex              0\nage            177\nsibsp            0\nparch            0\nfare             0\nembarked         2\nclass            0\nwho              0\nadult_male       0\nembark_town      2\nalive            0\nalone            0\ndtype: int64"
  },
  {
    "objectID": "posts/advanced/2023-01-22-03. titanic.html#데이터-전처리2.-결측치-채우기",
    "href": "posts/advanced/2023-01-22-03. titanic.html#데이터-전처리2.-결측치-채우기",
    "title": "03. titanic",
    "section": "데이터 전처리2. 결측치 채우기",
    "text": "데이터 전처리2. 결측치 채우기\n1 age 결측치 변수 평균값으로 대체\n\nage_m = df1.age.mean()\n\ndf1.age.fillna(age_m, inplace = True)\n\n2 embarked, embark_town 변수 결측치 채우기\n\ndf1.embark_town.value_counts()\n\nSouthampton    644\nCherbourg      168\nQueenstown      77\nName: embark_town, dtype: int64\n\n\n\ndf1.embarked.value_counts()\n\nS    644\nC    168\nQ     77\nName: embarked, dtype: int64\n\n\n- 두 변수 모두 최빈값으로 채우자..\n\nm1, m2  = df1.embark_town.mode()[0], df1.embarked.mode()[0]\n\ndf1.embark_town.fillna(m1, inplace = True)\ndf1.embarked.fillna(m2, inplace = True)\n\n\ndf1.isna().sum()\n\nsurvived       0\npclass         0\nsex            0\nage            0\nsibsp          0\nparch          0\nfare           0\nembarked       0\nclass          0\nwho            0\nadult_male     0\nembark_town    0\nalive          0\nalone          0\ndtype: int64"
  },
  {
    "objectID": "posts/advanced/2023-01-22-03. titanic.html#필요없는-컬럼-삭제",
    "href": "posts/advanced/2023-01-22-03. titanic.html#필요없는-컬럼-삭제",
    "title": "03. titanic",
    "section": "필요없는 컬럼 삭제",
    "text": "필요없는 컬럼 삭제\n\ndf1.head()\n\n\n  \n    \n\n\n\n\n\n\nsurvived\npclass\nsex\nage\nsibsp\nparch\nfare\nembarked\nclass\nwho\nadult_male\nembark_town\nalive\nalone\n\n\n\n\n0\n0\n3\nmale\n22.0\n1\n0\n7.2500\nS\nThird\nman\nTrue\nSouthampton\nno\nFalse\n\n\n1\n1\n1\nfemale\n38.0\n1\n0\n71.2833\nC\nFirst\nwoman\nFalse\nCherbourg\nyes\nFalse\n\n\n2\n1\n3\nfemale\n26.0\n0\n0\n7.9250\nS\nThird\nwoman\nFalse\nSouthampton\nyes\nTrue\n\n\n3\n1\n1\nfemale\n35.0\n1\n0\n53.1000\nS\nFirst\nwoman\nFalse\nSouthampton\nyes\nFalse\n\n\n4\n0\n3\nmale\n35.0\n0\n0\n8.0500\nS\nThird\nman\nTrue\nSouthampton\nno\nTrue\n\n\n\n\n\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n\n  \n\n\n    \n        \n    \n\n  \n\n\n\n  \n\n\n    \n  \n\n\n\ndf1.embarked.value_counts()\n\nS    646\nC    168\nQ     77\nName: embarked, dtype: int64\n\n\n\nd_col = [\"parch\", \"sibsp\", \"who\", \"embark_town\", \"alive\", \"alone\", \"class\"]\n\ndf1 = df1.drop(d_col, axis =1 )\n\n\ndf1.head()\n\n\n  \n    \n\n\n\n\n\n\nsurvived\npclass\nsex\nage\nfare\nembarked\nadult_male\n\n\n\n\n0\n0\n3\nmale\n22.0\n7.2500\nS\nTrue\n\n\n1\n1\n1\nfemale\n38.0\n71.2833\nC\nFalse\n\n\n2\n1\n3\nfemale\n26.0\n7.9250\nS\nFalse\n\n\n3\n1\n1\nfemale\n35.0\n53.1000\nS\nFalse\n\n\n4\n0\n3\nmale\n35.0\n8.0500\nS\nTrue"
  },
  {
    "objectID": "posts/advanced/2023-01-22-03. titanic.html#x-y-분리",
    "href": "posts/advanced/2023-01-22-03. titanic.html#x-y-분리",
    "title": "03. titanic",
    "section": "X, y 분리",
    "text": "X, y 분리\n\ntarget = \"survived\"\n\nX = df1.drop(target, axis = 1)\ny = df1[target]"
  },
  {
    "objectID": "posts/advanced/2023-01-22-03. titanic.html#더미-변수화",
    "href": "posts/advanced/2023-01-22-03. titanic.html#더미-변수화",
    "title": "03. titanic",
    "section": "더미 변수화",
    "text": "더미 변수화\n\nd_col = [\"pclass\", \"sex\", \"embarked\", \"adult_male\"]\n\nX = pd.get_dummies(X,columns = d_col, drop_first = True)"
  },
  {
    "objectID": "posts/advanced/2023-01-22-03. titanic.html#train-test-분리",
    "href": "posts/advanced/2023-01-22-03. titanic.html#train-test-분리",
    "title": "03. titanic",
    "section": "train, test 분리",
    "text": "train, test 분리\n\nfrom sklearn.model_selection import  train_test_split\n\nx_train, x_test, y_train, y_test  = train_test_split(X, y, test_size = 0.2, random_state = 2024, stratify = y)"
  },
  {
    "objectID": "posts/advanced/2023-01-22-03. titanic.html#모델-설계-1.-ml",
    "href": "posts/advanced/2023-01-22-03. titanic.html#모델-설계-1.-ml",
    "title": "03. titanic",
    "section": "모델 설계 1. ml",
    "text": "모델 설계 1. ml\n\nfrom xgboost import XGBClassifier\nfrom sklearn.model_selection import cross_val_score\n\nxgb = XGBClassifier(max_depth = 5, n_estimators = 100)\n\nxgb_cv = cross_val_score(xgb, x_train, y_train, cv = 5 )\n\nprint(xgb_cv.mean())\n\nfrom sklearn.ensemble import RandomForestClassifier\n\nrf = RandomForestClassifier(max_depth = 5, n_estimators = 100)\n\nrf_cv = cross_val_score(rf, x_train, y_train, cv = 5)\n\nprint(rf_cv.mean())\n\n0.8230375258544272\n0.8287107258938246\n\n\n- 오 랜덤포레스트 성능이 더 좋으니 저거 튜닝하자..\n\nfrom sklearn.model_selection import GridSearchCV\n\nrf_model = RandomForestClassifier()\n\nparams =  {\"max_depth\" : range(5,21),\n                    \"n_estimators\" : [100, 150, 200]}\n\n\nrf_model_grid =  GridSearchCV(rf_model, params, cv = 5, error_score='raise')\n\n\nrf_model_grid.fit(x_train, y_train)\n\nGridSearchCV(cv=5, error_score='raise', estimator=RandomForestClassifier(),\n             param_grid={'max_depth': range(5, 21),\n                         'n_estimators': [100, 150, 200]})In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.GridSearchCVGridSearchCV(cv=5, error_score='raise', estimator=RandomForestClassifier(),\n             param_grid={'max_depth': range(5, 21),\n                         'n_estimators': [100, 150, 200]})estimator: RandomForestClassifierRandomForestClassifier()RandomForestClassifierRandomForestClassifier()\n\n\n\nprint(rf_model_grid.best_params_)\nprint(rf_model_grid.best_score_)\n\n{'max_depth': 7, 'n_estimators': 100}\n0.8385206342952822\n\n\n\n예측\n\nrf_pred = rf_model_grid.predict(x_test)\n\n\nfrom sklearn.metrics import *\n\nprint(classification_report(y_test, rf_pred))\n\n              precision    recall  f1-score   support\n\n           0       0.83      0.92      0.87       110\n           1       0.84      0.70      0.76        69\n\n    accuracy                           0.83       179\n   macro avg       0.83      0.81      0.82       179\nweighted avg       0.83      0.83      0.83       179"
  },
  {
    "objectID": "posts/advanced/2023-01-22-03. titanic.html#모델-설계-2.-dl",
    "href": "posts/advanced/2023-01-22-03. titanic.html#모델-설계-2.-dl",
    "title": "03. titanic",
    "section": "모델 설계 2. DL",
    "text": "모델 설계 2. DL\n\nfrom keras.layers import *\nfrom keras.models import *\nfrom keras.callbacks import *\nfrom keras.backend import *\nfrom keras.optimizers import *\n\n\nnf = x_train.shape[1]\nnf\n\n8\n\n\n\nfrom sklearn.preprocessing import MinMaxScaler\n\nmm = MinMaxScaler()\n\nx_train_s = mm.fit_transform(x_train)\nx_test_s = mm.transform(x_test)\n\n\nmodel = Sequential()\nmodel.add(Dense(1024, activation = \"relu\", input_shape = (nf,)))\nmodel.add(Dense(1, activation = \"sigmoid\"))\n\nmodel.compile(optimizer = Adam(0.001), loss = \"binary_crossentropy\", metrics = [\"acc\"])\n\nmodel.fit(x_train_s, y_train, epochs = 30, validation_split = 0.2, batch_size = 16)\n\nEpoch 1/30\n36/36 [==============================] - 2s 15ms/step - loss: 0.5679 - acc: 0.7487 - val_loss: 0.4910 - val_acc: 0.7902\nEpoch 2/30\n36/36 [==============================] - 0s 7ms/step - loss: 0.4692 - acc: 0.7979 - val_loss: 0.4549 - val_acc: 0.7972\nEpoch 3/30\n36/36 [==============================] - 0s 8ms/step - loss: 0.4350 - acc: 0.8014 - val_loss: 0.4457 - val_acc: 0.7902\nEpoch 4/30\n36/36 [==============================] - 0s 7ms/step - loss: 0.4210 - acc: 0.8137 - val_loss: 0.4386 - val_acc: 0.8182\nEpoch 5/30\n36/36 [==============================] - 0s 5ms/step - loss: 0.4155 - acc: 0.8102 - val_loss: 0.4365 - val_acc: 0.8252\nEpoch 6/30\n36/36 [==============================] - 0s 4ms/step - loss: 0.4104 - acc: 0.8243 - val_loss: 0.4331 - val_acc: 0.8252\nEpoch 7/30\n36/36 [==============================] - 0s 4ms/step - loss: 0.4039 - acc: 0.8278 - val_loss: 0.4316 - val_acc: 0.8252\nEpoch 8/30\n36/36 [==============================] - 0s 4ms/step - loss: 0.4063 - acc: 0.8278 - val_loss: 0.4330 - val_acc: 0.8252\nEpoch 9/30\n36/36 [==============================] - 0s 4ms/step - loss: 0.4010 - acc: 0.8295 - val_loss: 0.4292 - val_acc: 0.8252\nEpoch 10/30\n36/36 [==============================] - 0s 4ms/step - loss: 0.3970 - acc: 0.8225 - val_loss: 0.4292 - val_acc: 0.8252\nEpoch 11/30\n36/36 [==============================] - 0s 4ms/step - loss: 0.3977 - acc: 0.8278 - val_loss: 0.4348 - val_acc: 0.8182\nEpoch 12/30\n36/36 [==============================] - 0s 5ms/step - loss: 0.3931 - acc: 0.8295 - val_loss: 0.4313 - val_acc: 0.8252\nEpoch 13/30\n36/36 [==============================] - 0s 4ms/step - loss: 0.3934 - acc: 0.8313 - val_loss: 0.4280 - val_acc: 0.8252\nEpoch 14/30\n36/36 [==============================] - 0s 4ms/step - loss: 0.3913 - acc: 0.8260 - val_loss: 0.4312 - val_acc: 0.8252\nEpoch 15/30\n36/36 [==============================] - 0s 6ms/step - loss: 0.3903 - acc: 0.8330 - val_loss: 0.4302 - val_acc: 0.8252\nEpoch 16/30\n36/36 [==============================] - 0s 4ms/step - loss: 0.3897 - acc: 0.8313 - val_loss: 0.4284 - val_acc: 0.8252\nEpoch 17/30\n36/36 [==============================] - 0s 7ms/step - loss: 0.3875 - acc: 0.8348 - val_loss: 0.4323 - val_acc: 0.8182\nEpoch 18/30\n36/36 [==============================] - 0s 7ms/step - loss: 0.3878 - acc: 0.8330 - val_loss: 0.4272 - val_acc: 0.8252\nEpoch 19/30\n36/36 [==============================] - 0s 6ms/step - loss: 0.3916 - acc: 0.8348 - val_loss: 0.4438 - val_acc: 0.8112\nEpoch 20/30\n36/36 [==============================] - 0s 7ms/step - loss: 0.3898 - acc: 0.8172 - val_loss: 0.4303 - val_acc: 0.8252\nEpoch 21/30\n36/36 [==============================] - 0s 7ms/step - loss: 0.3883 - acc: 0.8313 - val_loss: 0.4347 - val_acc: 0.8042\nEpoch 22/30\n36/36 [==============================] - 0s 6ms/step - loss: 0.3861 - acc: 0.8348 - val_loss: 0.4282 - val_acc: 0.8182\nEpoch 23/30\n36/36 [==============================] - 0s 7ms/step - loss: 0.3860 - acc: 0.8278 - val_loss: 0.4358 - val_acc: 0.8112\nEpoch 24/30\n36/36 [==============================] - 0s 7ms/step - loss: 0.3847 - acc: 0.8348 - val_loss: 0.4309 - val_acc: 0.8182\nEpoch 25/30\n36/36 [==============================] - 0s 7ms/step - loss: 0.3875 - acc: 0.8313 - val_loss: 0.4299 - val_acc: 0.8252\nEpoch 26/30\n36/36 [==============================] - 0s 7ms/step - loss: 0.3850 - acc: 0.8190 - val_loss: 0.4339 - val_acc: 0.8112\nEpoch 27/30\n36/36 [==============================] - 0s 7ms/step - loss: 0.3824 - acc: 0.8313 - val_loss: 0.4317 - val_acc: 0.8182\nEpoch 28/30\n36/36 [==============================] - 0s 5ms/step - loss: 0.3851 - acc: 0.8348 - val_loss: 0.4373 - val_acc: 0.8182\nEpoch 29/30\n36/36 [==============================] - 0s 5ms/step - loss: 0.3849 - acc: 0.8348 - val_loss: 0.4308 - val_acc: 0.8252\nEpoch 30/30\n36/36 [==============================] - 0s 4ms/step - loss: 0.3832 - acc: 0.8330 - val_loss: 0.4298 - val_acc: 0.8182\n\n\n&lt;keras.src.callbacks.History at 0x7a3514520130&gt;\n\n\n\nimport numpy as np\nd_pred = np.where(model.predict(x_test_s)&gt; 0.5, 1, 0)\n\n6/6 [==============================] - 0s 2ms/step"
  },
  {
    "objectID": "posts/advanced/2023-01-22-03. titanic.html#결과-비교",
    "href": "posts/advanced/2023-01-22-03. titanic.html#결과-비교",
    "title": "03. titanic",
    "section": "결과 비교",
    "text": "결과 비교\n\nprint(classification_report(y_test, rf_pred))\nprint(classification_report(y_test, d_pred))\n\n              precision    recall  f1-score   support\n\n           0       0.83      0.92      0.87       110\n           1       0.84      0.70      0.76        69\n\n    accuracy                           0.83       179\n   macro avg       0.83      0.81      0.82       179\nweighted avg       0.83      0.83      0.83       179\n\n              precision    recall  f1-score   support\n\n           0       0.78      0.91      0.84       110\n           1       0.80      0.59      0.68        69\n\n    accuracy                           0.79       179\n   macro avg       0.79      0.75      0.76       179\nweighted avg       0.79      0.79      0.78       179"
  },
  {
    "objectID": "posts/advanced/2023-01-22-03. titanic.html#모델-저장",
    "href": "posts/advanced/2023-01-22-03. titanic.html#모델-저장",
    "title": "03. titanic",
    "section": "모델 저장",
    "text": "모델 저장\n- 튜닝한 rf 모델 성능이 좋으므로 rf 모델을 저장\n\nimport joblib\n\njoblib.dump(rf_model_grid, \"01082478779_01.pkl\")\n\n['01082478779_01.pkl']\n\n\n- 저장한 모델 load 후 예측해보기\n\nrf_model = joblib.load(\"01082478779_01.pkl\")\n\n\nrf_pred = rf_model.predict(x_test)\n\n\nprint(classification_report(y_test, rf_pred))\n\n              precision    recall  f1-score   support\n\n           0       0.83      0.92      0.87       110\n           1       0.84      0.70      0.76        69\n\n    accuracy                           0.83       179\n   macro avg       0.83      0.81      0.82       179\nweighted avg       0.83      0.83      0.83       179"
  },
  {
    "objectID": "posts/advanced/2023-01-25-05. MNIST.html",
    "href": "posts/advanced/2023-01-25-05. MNIST.html",
    "title": "05. MNIST",
    "section": "",
    "text": "import tensorflow as tf\nfrom tensorflow import keras"
  },
  {
    "objectID": "posts/advanced/2023-01-25-05. MNIST.html#one-hot-encoding",
    "href": "posts/advanced/2023-01-25-05. MNIST.html#one-hot-encoding",
    "title": "05. MNIST",
    "section": "one-hot encoding",
    "text": "one-hot encoding\n\nfrom keras.utils import to_categorical\n\n\ntrain_y_c = to_categorical(y_train, 10)\ntest_y_c = to_categorical(y_test, 10)"
  },
  {
    "objectID": "posts/advanced/2023-01-25-05. MNIST.html#import-1",
    "href": "posts/advanced/2023-01-25-05. MNIST.html#import-1",
    "title": "05. MNIST",
    "section": "import",
    "text": "import\n\nimport tensorflow as tf\nfrom tensorflow import keras\n\nfrom tensorflow.keras.backend import clear_session\nfrom tensorflow.keras.models import Sequential, Model\nfrom tensorflow.keras.layers import Input, Dense, Flatten, BatchNormalization, Dropout"
  },
  {
    "objectID": "posts/advanced/2023-01-25-05. MNIST.html#모델-설계",
    "href": "posts/advanced/2023-01-25-05. MNIST.html#모델-설계",
    "title": "05. MNIST",
    "section": "모델 설계",
    "text": "모델 설계\n\n# 1. 세션 클리어\nclear_session()\n\n# 2. 모델 설계\n\nmodel1 = Sequential()\n\nmodel1.add( Input(shape = (28,28,1)))\nmodel1.add( Flatten() )\nmodel1.add( Dense(1024, activation = \"relu\"))\nmodel1.add( Dense(1024, activation = \"relu\"))\nmodel1.add( BatchNormalization())\nmodel1.add( Dropout(0.25) )\n\nmodel1.add( Dense(512, activation = \"relu\"))\nmodel1.add( Dense(512, activation = \"relu\"))\nmodel1.add( BatchNormalization())\nmodel1.add( Dropout(0.25) )\n\nmodel1.add( Dense (10, activation = \"softmax\"))\n\n# 3. 모델 컴파일\nmodel1.compile(optimizer = \"adam\", loss = tf.keras.losses.categorical_crossentropy,\n               metrics = [\"accuracy\"])\n\n\nmodel1.summary()\n\nModel: \"sequential\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n flatten (Flatten)           (None, 784)               0         \n                                                                 \n dense (Dense)               (None, 1024)              803840    \n                                                                 \n dense_1 (Dense)             (None, 1024)              1049600   \n                                                                 \n batch_normalization (Batch  (None, 1024)              4096      \n Normalization)                                                  \n                                                                 \n dropout (Dropout)           (None, 1024)              0         \n                                                                 \n dense_2 (Dense)             (None, 512)               524800    \n                                                                 \n dense_3 (Dense)             (None, 512)               262656    \n                                                                 \n batch_normalization_1 (Bat  (None, 512)               2048      \n chNormalization)                                                \n                                                                 \n dropout_1 (Dropout)         (None, 512)               0         \n                                                                 \n dense_4 (Dense)             (None, 10)                5130      \n                                                                 \n=================================================================\nTotal params: 2652170 (10.12 MB)\nTrainable params: 2649098 (10.11 MB)\nNon-trainable params: 3072 (12.00 KB)\n_________________________________________________________________"
  },
  {
    "objectID": "posts/advanced/2023-01-25-05. MNIST.html#학습",
    "href": "posts/advanced/2023-01-25-05. MNIST.html#학습",
    "title": "05. MNIST",
    "section": "학습",
    "text": "학습\n\nfrom keras.callbacks import EarlyStopping\n\n\nes = EarlyStopping(monitor = \"val_loss\",\n                  min_delta = 0,\n                  patience = 3,\n                   verbose = 1,\n                   restore_best_weights = True)\n\n\nhistory = model1.fit(train_x_rel, train_y_c,\n                     epochs = 10000, verbose = 1,\n                     validation_split = 0.2,\n                     callbacks = [es]).history\n\nEpoch 1/10000\n1500/1500 [==============================] - 10s 7ms/step - loss: 0.5921 - accuracy: 0.7939 - val_loss: 0.5014 - val_accuracy: 0.8234\nEpoch 2/10000\n1500/1500 [==============================] - 12s 8ms/step - loss: 0.4375 - accuracy: 0.8434 - val_loss: 0.5076 - val_accuracy: 0.8056\nEpoch 3/10000\n1500/1500 [==============================] - 14s 9ms/step - loss: 0.3908 - accuracy: 0.8593 - val_loss: 0.4336 - val_accuracy: 0.8573\nEpoch 4/10000\n1500/1500 [==============================] - 12s 8ms/step - loss: 0.3534 - accuracy: 0.8709 - val_loss: 0.3595 - val_accuracy: 0.8655\nEpoch 5/10000\n1500/1500 [==============================] - 14s 10ms/step - loss: 0.3349 - accuracy: 0.8790 - val_loss: 0.3693 - val_accuracy: 0.8729\nEpoch 6/10000\n1500/1500 [==============================] - 13s 9ms/step - loss: 0.3183 - accuracy: 0.8831 - val_loss: 0.3335 - val_accuracy: 0.8810\nEpoch 7/10000\n1500/1500 [==============================] - 11s 7ms/step - loss: 0.3068 - accuracy: 0.8870 - val_loss: 0.3397 - val_accuracy: 0.8715\nEpoch 8/10000\n1500/1500 [==============================] - 11s 7ms/step - loss: 0.2890 - accuracy: 0.8942 - val_loss: 0.3358 - val_accuracy: 0.8773\nEpoch 9/10000\n1500/1500 [==============================] - 12s 8ms/step - loss: 0.2774 - accuracy: 0.8978 - val_loss: 0.3327 - val_accuracy: 0.8827\nEpoch 10/10000\n1500/1500 [==============================] - 10s 7ms/step - loss: 0.2664 - accuracy: 0.9011 - val_loss: 0.3199 - val_accuracy: 0.8850\nEpoch 11/10000\n1500/1500 [==============================] - 11s 7ms/step - loss: 0.2569 - accuracy: 0.9037 - val_loss: 0.3585 - val_accuracy: 0.8722\nEpoch 12/10000\n1500/1500 [==============================] - 15s 10ms/step - loss: 0.2463 - accuracy: 0.9079 - val_loss: 0.3201 - val_accuracy: 0.8879\nEpoch 13/10000\n1498/1500 [============================&gt;.] - ETA: 0s - loss: 0.2410 - accuracy: 0.9102Restoring model weights from the end of the best epoch: 10.\n1500/1500 [==============================] - 10s 6ms/step - loss: 0.2413 - accuracy: 0.9100 - val_loss: 0.3282 - val_accuracy: 0.8843\nEpoch 13: early stopping"
  },
  {
    "objectID": "posts/advanced/2023-01-25-05. MNIST.html#결과-시각화",
    "href": "posts/advanced/2023-01-25-05. MNIST.html#결과-시각화",
    "title": "05. MNIST",
    "section": "결과 시각화",
    "text": "결과 시각화\n\nplt.figure(figsize = (12,4))\nplt.plot(history[\"loss\"],\"--.\",label = \"train_loss\")\nplt.plot(history[\"val_loss\"], \"--.\",label = \"val_loss\")\nplt.legend()\nplt.show()"
  },
  {
    "objectID": "posts/advanced/2023-01-25-05. MNIST.html#예측",
    "href": "posts/advanced/2023-01-25-05. MNIST.html#예측",
    "title": "05. MNIST",
    "section": "예측",
    "text": "예측\n\ny_pred =  model1.predict(test_x_rel).argmax(axis = 1)\n\n313/313 [==============================] - 1s 2ms/step\n\n\n\nfrom sklearn.metrics import *\n\n\nconfusion_matrix(y_test, y_pred)\n\narray([[875,   0,  18,  27,   1,   0,  70,   0,   9,   0],\n       [  5, 958,   3,  30,   1,   0,   2,   0,   1,   0],\n       [ 19,   0, 842,  15,  65,   0,  55,   0,   4,   0],\n       [ 26,   2,   9, 920,  17,   0,  22,   0,   4,   0],\n       [  1,   0, 146,  52, 721,   0,  73,   0,   7,   0],\n       [  0,   0,   0,   0,   0, 987,   0,   9,   2,   2],\n       [162,   0, 109,  31,  48,   0, 639,   0,  11,   0],\n       [  0,   0,   0,   0,   0,  52,   0, 921,   0,  27],\n       [  5,   0,  10,   2,   5,   4,   0,   4, 970,   0],\n       [  0,   0,   0,   0,   0,  17,   1,  27,   0, 955]])\n\n\n\nprint(classification_report(y_test, y_pred))\n\n              precision    recall  f1-score   support\n\n           0       0.80      0.88      0.84      1000\n           1       1.00      0.96      0.98      1000\n           2       0.74      0.84      0.79      1000\n           3       0.85      0.92      0.89      1000\n           4       0.84      0.72      0.78      1000\n           5       0.93      0.99      0.96      1000\n           6       0.74      0.64      0.69      1000\n           7       0.96      0.92      0.94      1000\n           8       0.96      0.97      0.97      1000\n           9       0.97      0.95      0.96      1000\n\n    accuracy                           0.88     10000\n   macro avg       0.88      0.88      0.88     10000\nweighted avg       0.88      0.88      0.88     10000"
  },
  {
    "objectID": "posts/advanced/2023-01-25-05. MNIST.html#import-2",
    "href": "posts/advanced/2023-01-25-05. MNIST.html#import-2",
    "title": "05. MNIST",
    "section": "import",
    "text": "import\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom keras.backend import clear_session\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Input, Conv2D, MaxPool2D"
  },
  {
    "objectID": "posts/advanced/2023-01-25-05. MNIST.html#모델-설계-1",
    "href": "posts/advanced/2023-01-25-05. MNIST.html#모델-설계-1",
    "title": "05. MNIST",
    "section": "모델 설계",
    "text": "모델 설계\n\n\n# 1. 세션클리어\nkeras.backend.clear_session()\n\n# 2. 모델 설계\nmodel2 = Sequential()\n\nmodel2.add(Input(shape = (28, 28, 1)))\n\nmodel2.add( Conv2D(filters = 28, kernel_size = (3,3),\n            strides = (1,1), padding = \"same\",\n             activation = \"relu\"))\n\nmodel2.add( Conv2D(filters = 28, kernel_size = (3,3),\n            strides = (1,1), padding = \"same\",\n             activation = \"relu\"))\n\nmodel2.add( BatchNormalization() )\nmodel2.add(MaxPool2D(pool_size = (2,2), strides= (2,2)))\nmodel2.add ( keras.layers.Dropout(0.25) )\n\nmodel2.add( keras.layers.Flatten() )\n# Fully Connected Layer : 노드 1024개\nmodel2.add( keras.layers.Dense(1024, activation = \"relu\"))\n\n# BatchNormalization\n\nmodel2.add(keras.layers.BatchNormalization())\n\n# DropOut : 35% 비활성화\n\nmodel2.add( keras.layers.Dropout(0.35) )\n\n# 아웃풋레이어\nmodel2.add( keras.layers.Dense(10, activation = \"softmax\"))\n\nmodel2.compile(optimizer = \"adam\",\n                              loss = keras.losses.categorical_crossentropy,\n                              metrics = [\"accuracy\"])\nmodel2.summary()\n\nModel: \"sequential\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n conv2d (Conv2D)             (None, 28, 28, 28)        280       \n                                                                 \n conv2d_1 (Conv2D)           (None, 28, 28, 28)        7084      \n                                                                 \n batch_normalization (Batch  (None, 28, 28, 28)        112       \n Normalization)                                                  \n                                                                 \n max_pooling2d (MaxPooling2  (None, 14, 14, 28)        0         \n D)                                                              \n                                                                 \n dropout (Dropout)           (None, 14, 14, 28)        0         \n                                                                 \n flatten (Flatten)           (None, 5488)              0         \n                                                                 \n dense (Dense)               (None, 1024)              5620736   \n                                                                 \n batch_normalization_1 (Bat  (None, 1024)              4096      \n chNormalization)                                                \n                                                                 \n dropout_1 (Dropout)         (None, 1024)              0         \n                                                                 \n dense_1 (Dense)             (None, 10)                10250     \n                                                                 \n=================================================================\nTotal params: 5642558 (21.52 MB)\nTrainable params: 5640454 (21.52 MB)\nNon-trainable params: 2104 (8.22 KB)\n_________________________________________________________________"
  },
  {
    "objectID": "posts/advanced/2023-01-25-05. MNIST.html#모델-학습",
    "href": "posts/advanced/2023-01-25-05. MNIST.html#모델-학습",
    "title": "05. MNIST",
    "section": "모델 학습",
    "text": "모델 학습\n\nfrom tensorflow.keras.callbacks import EarlyStopping\n\n\ntrain_x_rel.shape\n\n(60000, 28, 28, 1)\n\n\n\nes = EarlyStopping(\n      monitor = \"val_loss\",\n      min_delta = 0,\n      patience = 3,\n      verbose = 1,\n      restore_best_weights  = True\n)\n\n\nhistory = model2.fit(train_x_rel, train_y_c,\n                     epochs = 10000, verbose = 1,\n                     validation_split = 0.2,\n                     callbacks = [es]).history\n\nEpoch 1/10000\n1500/1500 [==============================] - 15s 7ms/step - loss: 0.4567 - accuracy: 0.8470 - val_loss: 0.2840 - val_accuracy: 0.9010\nEpoch 2/10000\n1500/1500 [==============================] - 11s 7ms/step - loss: 0.3097 - accuracy: 0.8893 - val_loss: 0.4721 - val_accuracy: 0.8445\nEpoch 3/10000\n1500/1500 [==============================] - 10s 7ms/step - loss: 0.2647 - accuracy: 0.9051 - val_loss: 0.2349 - val_accuracy: 0.9137\nEpoch 4/10000\n1500/1500 [==============================] - 10s 7ms/step - loss: 0.2322 - accuracy: 0.9162 - val_loss: 0.2548 - val_accuracy: 0.9100\nEpoch 5/10000\n1500/1500 [==============================] - 10s 6ms/step - loss: 0.2109 - accuracy: 0.9235 - val_loss: 0.2960 - val_accuracy: 0.8965\nEpoch 6/10000\n1496/1500 [============================&gt;.] - ETA: 0s - loss: 0.1827 - accuracy: 0.9339Restoring model weights from the end of the best epoch: 3.\n1500/1500 [==============================] - 10s 7ms/step - loss: 0.1826 - accuracy: 0.9339 - val_loss: 0.2662 - val_accuracy: 0.9133\nEpoch 6: early stopping"
  },
  {
    "objectID": "posts/advanced/2023-01-25-05. MNIST.html#결과-시각화-1",
    "href": "posts/advanced/2023-01-25-05. MNIST.html#결과-시각화-1",
    "title": "05. MNIST",
    "section": "결과 시각화",
    "text": "결과 시각화\n\nplt.figure(figsize = (12,4))\nplt.plot(history[\"loss\"],\"--.\",label = \"train_loss\")\nplt.plot(history[\"val_loss\"], \"--.\",label = \"val_loss\")\nplt.legend()\nplt.show()"
  },
  {
    "objectID": "posts/advanced/2023-01-25-05. MNIST.html#예측-1",
    "href": "posts/advanced/2023-01-25-05. MNIST.html#예측-1",
    "title": "05. MNIST",
    "section": "예측",
    "text": "예측\n\ny_pred =  model1.predict(test_x_rel).argmax(axis = 1)\n\n313/313 [==============================] - 1s 3ms/step\n\n\n\nprint(classification_report(y_test, y_pred))\n\n              precision    recall  f1-score   support\n\n           0       0.80      0.88      0.84      1000\n           1       1.00      0.96      0.98      1000\n           2       0.74      0.84      0.79      1000\n           3       0.85      0.92      0.89      1000\n           4       0.84      0.72      0.78      1000\n           5       0.93      0.99      0.96      1000\n           6       0.74      0.64      0.69      1000\n           7       0.96      0.92      0.94      1000\n           8       0.96      0.97      0.97      1000\n           9       0.97      0.95      0.96      1000\n\n    accuracy                           0.88     10000\n   macro avg       0.88      0.88      0.88     10000\nweighted avg       0.88      0.88      0.88     10000"
  },
  {
    "objectID": "posts/basic/2023-10-31-01. VOC.html",
    "href": "posts/basic/2023-10-31-01. VOC.html",
    "title": "01. VOC",
    "section": "",
    "text": "#!pip install tensorflow\n\n\n\nCode\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport plotly.express as px\nimport plotly.io as pio\npio.renderers.dafault = \"plotly_mimetype+notebook_connected\"\nimport scipy.stats as spst\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import *\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout\nfrom keras.optimizers import Adam\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint\nimport seaborn as sns\nfrom sklearn.preprocessing import MinMaxScaler\n\nplt.rcParams[\"font.family\"] = \"Malgun Gothic\"\nplt.rcParams[\"axes.unicode_minus\"] = False\n\n\n\nimport warnings\nwarnings.filterwarnings(action =\"ignore\")"
  },
  {
    "objectID": "posts/basic/2023-10-31-01. VOC.html#sklearn의-모듈을-읽어와-범주형-데이터를-카테고리화starstarstar",
    "href": "posts/basic/2023-10-31-01. VOC.html#sklearn의-모듈을-읽어와-범주형-데이터를-카테고리화starstarstar",
    "title": "01. VOC",
    "section": "sklearn의 모듈을 읽어와 범주형 데이터를 카테고리화(\\(\\star\\star\\star\\))",
    "text": "sklearn의 모듈을 읽어와 범주형 데이터를 카테고리화(\\(\\star\\star\\star\\))\n- cat_cols 데이터프레임에서 cust_clas_itg_cd 열의 범주형 데이터를 숫자로 인코딩하고, 그 결과를 le_cust_clas_itg_cd 열에 저장\n\nfrom sklearn.preprocessing import LabelEncoder\n\nle = LabelEncoder()\ncat_cols[\"le_cust_clas_itg_cd\"] = le.fit_transform(cat_cols[\"cust_clas_itg_cd\"])\n\n\ncat_cols.head()\n\n\n\n\n\n\n\n\ncust_clas_itg_cd\ncont_sttus_itg_cd\ncust_dtl_ctg_itg_cd\ntrm_yn\nle_cust_clas_itg_cd\n\n\n\n\n0\nF\n10001\n10003\nN\n0\n\n\n1\nG\n10001\n10002\nN\n1\n\n\n2\nG\n10001\n10003\nN\n1\n\n\n3\nL\n10001\n90024\nN\n5\n\n\n4\nG\n10001\n90024\nN\n1"
  },
  {
    "objectID": "posts/basic/2023-11-01-03. Titanic.html",
    "href": "posts/basic/2023-11-01-03. Titanic.html",
    "title": "03. Titanic",
    "section": "",
    "text": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nplt.rcParams[\"font.family\"] = \"Malgun Gothic\"\nplt.rcParams[\"axes.unicode_minus\"] = False\n\n\ndf = sns.load_dataset(\"titanic\")\ndf.head()\n\n\n\n\n\n\n\n\nsurvived\npclass\nsex\nage\nsibsp\nparch\nfare\nembarked\nclass\nwho\nadult_male\ndeck\nembark_town\nalive\nalone\n\n\n\n\n0\n0\n3\nmale\n22.0\n1\n0\n7.2500\nS\nThird\nman\nTrue\nNaN\nSouthampton\nno\nFalse\n\n\n1\n1\n1\nfemale\n38.0\n1\n0\n71.2833\nC\nFirst\nwoman\nFalse\nC\nCherbourg\nyes\nFalse\n\n\n2\n1\n3\nfemale\n26.0\n0\n0\n7.9250\nS\nThird\nwoman\nFalse\nNaN\nSouthampton\nyes\nTrue\n\n\n3\n1\n1\nfemale\n35.0\n1\n0\n53.1000\nS\nFirst\nwoman\nFalse\nC\nSouthampton\nyes\nFalse\n\n\n4\n0\n3\nmale\n35.0\n0\n0\n8.0500\nS\nThird\nman\nTrue\nNaN\nSouthampton\nno\nTrue\n\n\n\n\n\n\n\n\ndf.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 891 entries, 0 to 890\nData columns (total 15 columns):\n #   Column       Non-Null Count  Dtype   \n---  ------       --------------  -----   \n 0   survived     891 non-null    int64   \n 1   pclass       891 non-null    int64   \n 2   sex          891 non-null    object  \n 3   age          714 non-null    float64 \n 4   sibsp        891 non-null    int64   \n 5   parch        891 non-null    int64   \n 6   fare         891 non-null    float64 \n 7   embarked     889 non-null    object  \n 8   class        891 non-null    category\n 9   who          891 non-null    object  \n 10  adult_male   891 non-null    bool    \n 11  deck         203 non-null    category\n 12  embark_town  889 non-null    object  \n 13  alive        891 non-null    object  \n 14  alone        891 non-null    bool    \ndtypes: bool(2), category(2), float64(2), int64(4), object(5)\nmemory usage: 80.7+ KB"
  },
  {
    "objectID": "posts/basic/2023-11-01-03. Titanic.html#pclass분포-확인",
    "href": "posts/basic/2023-11-01-03. Titanic.html#pclass분포-확인",
    "title": "03. Titanic",
    "section": "pclass분포 확인",
    "text": "pclass분포 확인\n\ndf.pclass.value_counts()\n\npclass\n3    491\n1    216\n2    184\nName: count, dtype: int64\n\n\n\ndf.pclass.value_counts().plot(kind = \"bar\")\n\n&lt;Axes: xlabel='pclass'&gt;"
  },
  {
    "objectID": "posts/basic/2023-11-01-03. Titanic.html#sex-값-분포-확인",
    "href": "posts/basic/2023-11-01-03. Titanic.html#sex-값-분포-확인",
    "title": "03. Titanic",
    "section": "sex 값 분포 확인",
    "text": "sex 값 분포 확인\n\ndf.sex.value_counts().plot(kind = \"bar\")\n\n&lt;Axes: xlabel='sex'&gt;"
  },
  {
    "objectID": "posts/basic/2023-11-01-03. Titanic.html#age-boxplot",
    "href": "posts/basic/2023-11-01-03. Titanic.html#age-boxplot",
    "title": "03. Titanic",
    "section": "age boxplot",
    "text": "age boxplot\n\ndf.age.plot(kind = \"box\")\n\n&lt;Axes: &gt;\n\n\n\n\n\n\npclass별 age 분포확인\n\nimport plotly.express as px\nimport plotly.io as pio\npio.renderers.default = \"plotly_mimetype+notebook_connected\"\n\n\ndf.plot(y = \"age\", kind = \"box\", backend = \"plotly\",\n        color = \"pclass\")\n\n\n                                                \n\n\n\n\npclass별 age 분포 + Survived 추가\n\ndf.plot(x = \"pclass\", y = \"age\", kind = \"box\", backend = \"plotly\",\n        color = \"survived\")"
  },
  {
    "objectID": "posts/basic/2023-11-01-03. Titanic.html#pclass별-생존률-평균-구하기",
    "href": "posts/basic/2023-11-01-03. Titanic.html#pclass별-생존률-평균-구하기",
    "title": "03. Titanic",
    "section": "pclass별 생존률 평균 구하기",
    "text": "pclass별 생존률 평균 구하기\n- 결과를 pclass_grp 변수에 저장\n\ntarget = \"survived\"\n\n\npclass_grp = df.groupby(\"pclass\", as_index = True)[[target]].mean().reset_index()\n\n\npclass_grp\n\n\n\n\n\n\n\n\npclass\nsurvived\n\n\n\n\n0\n1\n0.629630\n\n\n1\n2\n0.472826\n\n\n2\n3\n0.242363\n\n\n\n\n\n\n\n\npclass_grp.plot(kind = \"bar\", backend = \"plotly\",\n                x = \"pclass\", y = target,color = \"pclass\", width = 400, height = 400)"
  },
  {
    "objectID": "posts/basic/2023-11-01-03. Titanic.html#중복컬럼삭제",
    "href": "posts/basic/2023-11-01-03. Titanic.html#중복컬럼삭제",
    "title": "03. Titanic",
    "section": "(1) 중복컬럼삭제",
    "text": "(1) 중복컬럼삭제\n\ndf.drop([\"class\",\"alive\"], axis = 1, inplace = True)\n\n\ndf.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 891 entries, 0 to 890\nData columns (total 13 columns):\n #   Column       Non-Null Count  Dtype   \n---  ------       --------------  -----   \n 0   survived     891 non-null    int64   \n 1   pclass       891 non-null    int64   \n 2   sex          891 non-null    object  \n 3   age          714 non-null    float64 \n 4   sibsp        891 non-null    int64   \n 5   parch        891 non-null    int64   \n 6   fare         891 non-null    float64 \n 7   embarked     889 non-null    object  \n 8   who          891 non-null    object  \n 9   adult_male   891 non-null    bool    \n 10  deck         203 non-null    category\n 11  embark_town  889 non-null    object  \n 12  alone        891 non-null    bool    \ndtypes: bool(2), category(1), float64(2), int64(4), object(4)\nmemory usage: 72.7+ KB"
  },
  {
    "objectID": "posts/basic/2023-11-01-03. Titanic.html#필요없는-열-삭제",
    "href": "posts/basic/2023-11-01-03. Titanic.html#필요없는-열-삭제",
    "title": "03. Titanic",
    "section": "(2) 필요없는 열 삭제",
    "text": "(2) 필요없는 열 삭제\n\nd_col = ['embarked', 'who', 'adult_male', 'deck', 'embark_town', 'alone'] \n\ndf.drop(d_col, axis = 1, inplace = True)\n\n\ndf.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 891 entries, 0 to 890\nData columns (total 7 columns):\n #   Column    Non-Null Count  Dtype  \n---  ------    --------------  -----  \n 0   survived  891 non-null    int64  \n 1   pclass    891 non-null    int64  \n 2   sex       891 non-null    object \n 3   age       714 non-null    float64\n 4   sibsp     891 non-null    int64  \n 5   parch     891 non-null    int64  \n 6   fare      891 non-null    float64\ndtypes: float64(2), int64(4), object(1)\nmemory usage: 48.9+ KB\n\n\n\ndf.head()\n\n\n\n\n\n\n\n\nsurvived\npclass\nsex\nage\nsibsp\nparch\nfare\n\n\n\n\n0\n0\n3\nmale\n22.0\n1\n0\n7.2500\n\n\n1\n1\n1\nfemale\n38.0\n1\n0\n71.2833\n\n\n2\n1\n3\nfemale\n26.0\n0\n0\n7.9250\n\n\n3\n1\n1\nfemale\n35.0\n1\n0\n53.1000\n\n\n4\n0\n3\nmale\n35.0\n0\n0\n8.0500"
  },
  {
    "objectID": "posts/basic/2023-11-01-03. Titanic.html#성별-컬럼-정수-인코딩",
    "href": "posts/basic/2023-11-01-03. Titanic.html#성별-컬럼-정수-인코딩",
    "title": "03. Titanic",
    "section": "(3) 성별 컬럼 정수 인코딩",
    "text": "(3) 성별 컬럼 정수 인코딩\n\ndf[\"sex\"].replace([\"male\",\"female\"], [0, 1], inplace = True)\n\n\ndf.head()\n\n\n\n\n\n\n\n\nsurvived\npclass\nsex\nage\nsibsp\nparch\nfare\n\n\n\n\n0\n0\n3\n0\n22.0\n1\n0\n7.2500\n\n\n1\n1\n1\n1\n38.0\n1\n0\n71.2833\n\n\n2\n1\n3\n1\n26.0\n0\n0\n7.9250\n\n\n3\n1\n1\n1\n35.0\n1\n0\n53.1000\n\n\n4\n0\n3\n0\n35.0\n0\n0\n8.0500"
  },
  {
    "objectID": "posts/basic/2023-11-01-03. Titanic.html#결측치-확인",
    "href": "posts/basic/2023-11-01-03. Titanic.html#결측치-확인",
    "title": "03. Titanic",
    "section": "(4) 결측치 확인",
    "text": "(4) 결측치 확인\n\ndf.isnull().sum()\n\nsurvived      0\npclass        0\nsex           0\nage         177\nsibsp         0\nparch         0\nfare          0\ndtype: int64"
  },
  {
    "objectID": "posts/basic/2023-11-01-03. Titanic.html#결측치-평균값으로-대체",
    "href": "posts/basic/2023-11-01-03. Titanic.html#결측치-평균값으로-대체",
    "title": "03. Titanic",
    "section": "(5) 결측치 평균값으로 대체",
    "text": "(5) 결측치 평균값으로 대체\n\nm = df.age.mean()\n\ndf.age.fillna(m, inplace = True)\n\n\ndf.isnull().sum()\n\nsurvived    0\npclass      0\nsex         0\nage         0\nsibsp       0\nparch       0\nfare        0\ndtype: int64"
  },
  {
    "objectID": "posts/basic/2023-11-01-03. Titanic.html#tree",
    "href": "posts/basic/2023-11-01-03. Titanic.html#tree",
    "title": "03. Titanic",
    "section": "(1) tree",
    "text": "(1) tree\n\nfrom sklearn.tree import DecisionTreeClassifier\n\ntree = DecisionTreeClassifier(max_depth = 5)\n\ntree.fit(X_train, y_train)\n\ntree_pred = tree.predict(X_test)\n\nfrom sklearn.metrics import *\n\naccuracy_score(y_test, tree_pred)\n\n0.8044692737430168"
  },
  {
    "objectID": "posts/basic/2023-11-01-03. Titanic.html#rf",
    "href": "posts/basic/2023-11-01-03. Titanic.html#rf",
    "title": "03. Titanic",
    "section": "(2) RF",
    "text": "(2) RF\n\nfrom sklearn.ensemble import RandomForestClassifier\n\nrf = RandomForestClassifier(max_depth=5, n_estimators = 10)\n\nrf.fit(X_train, y_train)\n\nrf_pred = rf.predict(X_test)\n\naccuracy_score(y_test, rf_pred)\n\n0.7932960893854749"
  },
  {
    "objectID": "posts/image/2021-01-30-02. CNNwithMNIST.html",
    "href": "posts/image/2021-01-30-02. CNNwithMNIST.html",
    "title": "01. MNIST",
    "section": "",
    "text": "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\n\nimport tensorflow as tf\nfrom tensorflow import keras\n\nfrom tensorflow.keras.backend import clear_session\nfrom tensorflow.keras.models import Sequential, Model\nfrom tensorflow.keras.layers import Input, Dense, BatchNormalization, Dropout, Flatten, Conv2D, MaxPool2D\nfrom tensorflow.keras.callbacks import EarlyStopping\n\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\n\n\n\n\n(train_x, train_y), (test_x, test_y) = keras.datasets.mnist.load_data()\n\nDownloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n11490434/11490434 [==============================] - 0s 0us/step\n\n\n\nprint(train_x.shape, train_y.shape, test_x.shape, test_y.shape)\n\n(60000, 28, 28) (60000,) (10000, 28, 28) (10000,)\n\n\n\n데이터 살펴보기\n\n\nid = np.random.randint(0, 10000)\n\nprint(f'id = {id}')\nprint(f'다음 그림은 숫자 {test_y[id]} 입니다.')\n\nplt.imshow(test_x[id], cmap='Greys')\nplt.show()\n\nid = 1749\n다음 그림은 숫자 2 입니다.\n\n\n\n\n\n\n\n\n\nData split\n\ntraining set : validation set = 8 : 2\n재연을 위한 난수 고정 : 2023\n\n\n\ntrain_x, val_x, train_y, val_y = train_test_split(train_x, train_y, test_size=0.2, random_state=2023)\n\n\nScaling\n\nmin-max scaling\n\n\n\nprint('max :', train_x.max(),'  min :', train_x.min())\n\nmax : 255   min : 0\n\n\n\nmax_v, min_v = train_x.max(), train_x.min()\nmax_v, min_v\n\n(255, 0)\n\n\n\ntrain_x = (train_x - min_v) / (max_v - min_v)\nval_x = (val_x - min_v) / (max_v - min_v)\ntest_x = (test_x - min_v) / (max_v - min_v)\n\n\nprint('max :', train_x.max(),'  min :', train_x.min())\n\nmax : 1.0   min : 0.0\n\n\n\nOne-Hot Encoding\n\n\nfrom tensorflow.keras.utils import to_categorical\n\n\nclass_n = len(np.unique(train_y))\n\n\ntrain_y = to_categorical(train_y, class_n)\nval_y = to_categorical(val_y, class_n)\ntest_y = to_categorical(test_y, class_n)\n\n\ntrain_x.shape, train_y.shape\n\n((48000, 28, 28), (48000, 10))\n\n\n\n흑백 정보를 명시하기 위한 reshape\n\n\ntrain_x = np.expand_dims(train_x, axis=-1)\nval_x = np.expand_dims(val_x, axis=-1)\ntest_x = np.expand_dims(test_x, axis=-1)\n\n\ntrain_x.shape, train_y.shape, val_x.shape, val_y.shape, test_x.shape, test_y.shape\n\n((48000, 28, 28, 1),\n (48000, 10),\n (12000, 28, 28, 1),\n (12000, 10),\n (10000, 28, 28, 1),\n (10000, 10))\n\n\n\n\n\n\nImageDataGenerator\n.flow( )\n\n\ntrainIDG = ImageDataGenerator(rotation_range=15,    # randomly rotate images in the range (degrees, 0 to 180)\n                            zoom_range = 0.1,       # Randomly zoom image\n                            width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n                            height_shift_range=0.1, # randomly shift images vertically (fraction of total height)\n                            horizontal_flip=False,  # randomly flip images\n                            vertical_flip=False)    # randomly flip images\n\nvalIDG = ImageDataGenerator()\n\n\n## ImageDataGenerator 설정에 따라 불필요 할 수 있다\n# trainIDG.fit(train_x)\n# valIDG.fit(val_x)\n\n\nflow_trainIDG = trainIDG.flow(train_x, train_y, batch_size=256)\nflow_valIDG = valIDG.flow(val_x, val_y, batch_size=256)\n\n\n\n\n\n조건\n\nSequential API, Functiona API 중 택일.\n이 구조를 미니 버전으로 활용. 참고 링크\nDropOut, BatchNormalization 등의 기능도 같이 활용\nEarly Stopping을 사용\n\nSequential API\n\n\n# 1. 세션 클리어\nclear_session()\n\n# 2. 모델 선언\nmodel1 = Sequential()\n\n# 3. 레이어 블록 조립\nmodel1.add( Input(shape=(28,28,1)) )\n\nmodel1.add( Conv2D(filters=64,          # Conv2D 필터를 통해 새롭게 제작하려는 feature map의 수\n                   kernel_size=(3,3),   # Conv2D 필터의 가로 세로 사이즈\n                   strides=(1,1),       # Conv2D 필터의 이동 보폭\n                   padding='same',      # 1. 기존의 사이즈를 보존하겠다. | 2. 외곽의 정보를 조금 더 반영하려고!\n                   activation='relu',   # 빼먹지 않게 주의!\n                   ) )\nmodel1.add( Conv2D(filters=64,          # Conv2D 필터를 통해 새롭게 제작하려는 feature map의 수\n                   kernel_size=(3,3),   # Conv2D 필터의 가로 세로 사이즈\n                   strides=(1,1),       # Conv2D 필터의 이동 보폭\n                   padding='same',      # 1. 기존의 사이즈를 보존하겠다. | 2. 외곽의 정보를 조금 더 반영하려고!\n                   activation='relu',   # 빼먹지 않게 주의!\n                   ) )\nmodel1.add( MaxPool2D(pool_size=(2,2),  # Maxpool2D 필터의 가로 세로 사이즈\n                      strides=(2,2)     # Maxpool2D 필터의 이동 보폭 : 기본적으로 pool_size를 따른다.\n                      ) )\nmodel1.add( BatchNormalization() )\nmodel1.add( Dropout(0.2) )\n\nmodel1.add( Conv2D(filters=128,         # Conv2D 필터를 통해 새롭게 제작하려는 feature map의 수\n                   kernel_size=(3,3),   # Conv2D 필터의 가로 세로 사이즈\n                   strides=(1,1),       # Conv2D 필터의 이동 보폭\n                   padding='same',      # 1. 기존의 사이즈를 보존하겠다. | 2. 외곽의 정보를 조금 더 반영하려고!\n                   activation='relu',   # 빼먹지 않게 주의!\n                   ) )\nmodel1.add( Conv2D(filters=128,         # Conv2D 필터를 통해 새롭게 제작하려는 feature map의 수\n                   kernel_size=(3,3),   # Conv2D 필터의 가로 세로 사이즈\n                   strides=(1,1),       # Conv2D 필터의 이동 보폭\n                   padding='same',      # 1. 기존의 사이즈를 보존하겠다. | 2. 외곽의 정보를 조금 더 반영하려고!\n                   activation='relu',   # 빼먹지 않게 주의!\n                   ) )\nmodel1.add( MaxPool2D(pool_size=(2,2),  # Maxpool2D 필터의 가로 세로 사이즈\n                      strides=(2,2)     # Maxpool2D 필터의 이동 보폭 : 기본적으로 pool_size를 따른다.\n                      ) )\nmodel1.add( BatchNormalization() )\nmodel1.add( Dropout(0.2) )\n\nmodel1.add( Flatten() )\nmodel1.add( Dense(256, activation='relu') )\nmodel1.add( Dense(10, activation='softmax') )\n\n# 4. 컴파일\nmodel1.compile(optimizer='adam', loss='categorical_crossentropy',\n              metrics=['accuracy'])\n\nmodel1.summary()\n\n\nFunctional API\n\n\n# 1. 세션 클리어\nclear_session()\n\n# 2. 레이어 엮기\nil = Input(shape=(28,28,1))\n\nhl = Conv2D(filters=64,          # Conv2D 필터를 통해 새롭게 제작하려는 feature map의 수\n            kernel_size=(3,3),   # Conv2D 필터의 가로 세로 사이즈\n            strides=(1,1),       # Conv2D 필터의 이동 보폭\n            padding='same',      # 1. 기존의 사이즈를 보존하겠다. | 2. 외곽의 정보를 조금 더 반영하려고!\n            activation='relu',   # 빼먹지 않게 주의!\n            )(il)\nhl = Conv2D(filters=64,          # Conv2D 필터를 통해 새롭게 제작하려는 feature map의 수\n            kernel_size=(3,3),   # Conv2D 필터의 가로 세로 사이즈\n            strides=(1,1),       # Conv2D 필터의 이동 보폭\n            padding='same',      # 1. 기존의 사이즈를 보존하겠다. | 2. 외곽의 정보를 조금 더 반영하려고!\n            activation='relu',   # 빼먹지 않게 주의!\n            )(hl)\nhl = MaxPool2D(pool_size=(2,2),  # Maxpool2D 필터의 가로 세로 사이즈\n               strides=(2,2)     # Maxpool2D 필터의 이동 보폭 : 기본적으로 pool_size를 따른다.\n               )(hl)\nhl = BatchNormalization()(hl)\nhl = Dropout(0.2)(hl)\n\nhl = Conv2D(filters=128,         # Conv2D 필터를 통해 새롭게 제작하려는 feature map의 수\n            kernel_size=(3,3),   # Conv2D 필터의 가로 세로 사이즈\n            strides=(1,1),       # Conv2D 필터의 이동 보폭\n            padding='same',      # 1. 기존의 사이즈를 보존하겠다. | 2. 외곽의 정보를 조금 더 반영하려고!\n            activation='relu',   # 빼먹지 않게 주의!\n            )(hl)\nhl = Conv2D(filters=128,         # Conv2D 필터를 통해 새롭게 제작하려는 feature map의 수\n            kernel_size=(3,3),   # Conv2D 필터의 가로 세로 사이즈\n            strides=(1,1),       # Conv2D 필터의 이동 보폭\n            padding='same',      # 1. 기존의 사이즈를 보존하겠다. | 2. 외곽의 정보를 조금 더 반영하려고!\n            activation='relu',   # 빼먹지 않게 주의!\n            )(hl)\nhl = MaxPool2D(pool_size=(2,2),  # Maxpool2D 필터의 가로 세로 사이즈\n               strides=(2,2)     # Maxpool2D 필터의 이동 보폭 : 기본적으로 pool_size를 따른다.\n               )(hl)\nhl = BatchNormalization()(hl)\nhl = Dropout(0.2)(hl)\n\nhl = Flatten()(hl)\nhl = Dense(256, activation='relu')(hl)\nol = Dense(10, activation='softmax')(hl)\n\n# 3. 모델의 시작과 끝 지정\nmodel2 = Model(il, ol)\n\n# 4. 컴파일\nmodel2.compile(optimizer='adam', loss='categorical_crossentropy',\n              metrics=['accuracy'])\n\nmodel2.summary()\n\nModel: \"model\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n input_1 (InputLayer)        [(None, 28, 28, 1)]       0         \n                                                                 \n conv2d (Conv2D)             (None, 28, 28, 64)        640       \n                                                                 \n conv2d_1 (Conv2D)           (None, 28, 28, 64)        36928     \n                                                                 \n max_pooling2d (MaxPooling2  (None, 14, 14, 64)        0         \n D)                                                              \n                                                                 \n batch_normalization (Batch  (None, 14, 14, 64)        256       \n Normalization)                                                  \n                                                                 \n dropout (Dropout)           (None, 14, 14, 64)        0         \n                                                                 \n conv2d_2 (Conv2D)           (None, 14, 14, 128)       73856     \n                                                                 \n conv2d_3 (Conv2D)           (None, 14, 14, 128)       147584    \n                                                                 \n max_pooling2d_1 (MaxPoolin  (None, 7, 7, 128)         0         \n g2D)                                                            \n                                                                 \n batch_normalization_1 (Bat  (None, 7, 7, 128)         512       \n chNormalization)                                                \n                                                                 \n dropout_1 (Dropout)         (None, 7, 7, 128)         0         \n                                                                 \n flatten (Flatten)           (None, 6272)              0         \n                                                                 \n dense (Dense)               (None, 256)               1605888   \n                                                                 \n dense_1 (Dense)             (None, 10)                2570      \n                                                                 \n=================================================================\nTotal params: 1868234 (7.13 MB)\nTrainable params: 1867850 (7.13 MB)\nNon-trainable params: 384 (1.50 KB)\n_________________________________________________________________\n\n\n\nEarly Stopping\n\n\nes = EarlyStopping(monitor='val_loss',         # 얼리 스토핑을 적용할 관측 대상\n                   min_delta=0,                # Threshold. 설정한 값 이상으로 변화해야 성능이 개선되었다고 간주.\n                   patience=3,                 # 성능 개선이 발생하지 않았을 때, 몇 epoch를 더 지켜볼 것인가\n                   verbose=1,\n                   restore_best_weights=True)  # 성능이 가장 좋은 epoch의 가중치를 적용함.\n\n\nModel Checkpoint\n\n\nfrom tensorflow.keras.callbacks import ModelCheckpoint\n\n\nmcp = ModelCheckpoint(filepath='/content/model1.h5',   # 모델 저장 경로\n                      monitor='val_loss',              # 모델 저장의 관심 대상\n                      verbose=1,                       # 어느 시점에서 저장되는지 알려줌\n                      save_best_only=True,             # 최고 성능 모델만 저장\n                      save_weights_only=False)         # True : 가중치만 저장 | False : 모델 구조 포함하여 저장\n\n\n.fit( )\n\n\nhistory = model1.fit(flow_trainIDG, epochs=10000, verbose=1,\n                     validation_data=flow_valIDG,\n                     callbacks=[es, mcp]\n                     )\n\nEpoch 1/10000\n188/188 [==============================] - ETA: 0s - loss: 0.3212 - accuracy: 0.9084\nEpoch 1: val_loss improved from inf to 2.61382, saving model to /content/model1.h5\n188/188 [==============================] - 30s 92ms/step - loss: 0.3212 - accuracy: 0.9084 - val_loss: 2.6138 - val_accuracy: 0.1226\nEpoch 2/10000\n  1/188 [..............................] - ETA: 20s - loss: 0.0857 - accuracy: 0.9805188/188 [==============================] - ETA: 0s - loss: 0.0771 - accuracy: 0.9756\nEpoch 2: val_loss improved from 2.61382 to 0.95099, saving model to /content/model1.h5\n188/188 [==============================] - 17s 91ms/step - loss: 0.0771 - accuracy: 0.9756 - val_loss: 0.9510 - val_accuracy: 0.6347\nEpoch 3/10000\n188/188 [==============================] - ETA: 0s - loss: 0.0593 - accuracy: 0.9808\nEpoch 3: val_loss improved from 0.95099 to 0.03867, saving model to /content/model1.h5\n188/188 [==============================] - 17s 88ms/step - loss: 0.0593 - accuracy: 0.9808 - val_loss: 0.0387 - val_accuracy: 0.9902\nEpoch 4/10000\n188/188 [==============================] - ETA: 0s - loss: 0.0476 - accuracy: 0.9853\nEpoch 4: val_loss did not improve from 0.03867\n188/188 [==============================] - 17s 89ms/step - loss: 0.0476 - accuracy: 0.9853 - val_loss: 0.0421 - val_accuracy: 0.9869\nEpoch 5/10000\n188/188 [==============================] - ETA: 0s - loss: 0.0443 - accuracy: 0.9863\nEpoch 5: val_loss improved from 0.03867 to 0.03179, saving model to /content/model1.h5\n188/188 [==============================] - 16s 87ms/step - loss: 0.0443 - accuracy: 0.9863 - val_loss: 0.0318 - val_accuracy: 0.9911\nEpoch 6/10000\n188/188 [==============================] - ETA: 0s - loss: 0.0374 - accuracy: 0.9881\nEpoch 6: val_loss did not improve from 0.03179\n188/188 [==============================] - 17s 91ms/step - loss: 0.0374 - accuracy: 0.9881 - val_loss: 0.0564 - val_accuracy: 0.9837\nEpoch 7/10000\n188/188 [==============================] - ETA: 0s - loss: 0.0386 - accuracy: 0.9878\nEpoch 7: val_loss improved from 0.03179 to 0.03126, saving model to /content/model1.h5\n188/188 [==============================] - 17s 89ms/step - loss: 0.0386 - accuracy: 0.9878 - val_loss: 0.0313 - val_accuracy: 0.9915\nEpoch 8/10000\n188/188 [==============================] - ETA: 0s - loss: 0.0346 - accuracy: 0.9897\nEpoch 8: val_loss did not improve from 0.03126\n188/188 [==============================] - 17s 91ms/step - loss: 0.0346 - accuracy: 0.9897 - val_loss: 0.0327 - val_accuracy: 0.9897\nEpoch 9/10000\n188/188 [==============================] - ETA: 0s - loss: 0.0313 - accuracy: 0.9904\nEpoch 9: val_loss did not improve from 0.03126\n188/188 [==============================] - 16s 88ms/step - loss: 0.0313 - accuracy: 0.9904 - val_loss: 0.0387 - val_accuracy: 0.9898\nEpoch 10/10000\n188/188 [==============================] - ETA: 0s - loss: 0.0305 - accuracy: 0.9905Restoring model weights from the end of the best epoch: 7.\n\nEpoch 10: val_loss did not improve from 0.03126\n188/188 [==============================] - 16s 87ms/step - loss: 0.0305 - accuracy: 0.9905 - val_loss: 0.0429 - val_accuracy: 0.9890\nEpoch 10: early stopping\n\n\n/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n  saving_api.save_model(\n\n\n\nperformance_test = model1.evaluate(test_x, test_y, batch_size=256)\n\nprint(f'Test Loss: {performance_test[0]:.6f}')\nprint(f'Test Accuracy: {performance_test[1]*100:.3f}%')\n\n40/40 [==============================] - 1s 14ms/step - loss: 0.0222 - accuracy: 0.9929\nTest Loss: 0.022246\nTest Accuracy: 99.290%\n\n\n\nif not isinstance(history, dict):\n    history = history.history\n\nplt.plot(history['accuracy'])\nplt.plot(history['val_accuracy'])\nplt.title('Accuracy : Training vs Validation')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Training', 'Validation'], loc=0)\nplt.show()\n\n\n\n\n\nif not isinstance(history, dict):\n    history = history.history\n\nplt.plot(history['loss'])\nplt.plot(history['val_loss'])\nplt.title('Loss : Training vs Validation')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Training', 'Validation'], loc=0)\nplt.show()\n\n\n\n\n\n\n\n\n.save( )\n.load_model( )\n모델을 새롭게 저장하여 구조와 가중치 일부를 살펴보자\n\n\nmodel1.save('my_first_save.h5')\n\n\nclear_session()\nmodel = keras.models.load_model('my_first_save.h5')\nmodel.summary()\n\nModel: \"sequential\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n conv2d (Conv2D)             (None, 28, 28, 64)        640       \n                                                                 \n conv2d_1 (Conv2D)           (None, 28, 28, 64)        36928     \n                                                                 \n max_pooling2d (MaxPooling2  (None, 14, 14, 64)        0         \n D)                                                              \n                                                                 \n batch_normalization (Batch  (None, 14, 14, 64)        256       \n Normalization)                                                  \n                                                                 \n dropout (Dropout)           (None, 14, 14, 64)        0         \n                                                                 \n conv2d_2 (Conv2D)           (None, 14, 14, 128)       73856     \n                                                                 \n conv2d_3 (Conv2D)           (None, 14, 14, 128)       147584    \n                                                                 \n max_pooling2d_1 (MaxPoolin  (None, 7, 7, 128)         0         \n g2D)                                                            \n                                                                 \n batch_normalization_1 (Bat  (None, 7, 7, 128)         512       \n chNormalization)                                                \n                                                                 \n dropout_1 (Dropout)         (None, 7, 7, 128)         0         \n                                                                 \n flatten (Flatten)           (None, 6272)              0         \n                                                                 \n dense (Dense)               (None, 256)               1605888   \n                                                                 \n dense_1 (Dense)             (None, 10)                2570      \n                                                                 \n=================================================================\nTotal params: 1868234 (7.13 MB)\nTrainable params: 1867850 (7.13 MB)\nNon-trainable params: 384 (1.50 KB)\n_________________________________________________________________\n\n\n\nmodel.get_weights()[0][0][0]\n\narray([[-0.02984254, -0.12516664, -0.09413426,  0.09054146, -0.07211596,\n        -0.01527972,  0.00230363,  0.04401932, -0.01355622,  0.04863958,\n        -0.08964277, -0.04560584,  0.05172559, -0.11350822, -0.03701778,\n        -0.04161173,  0.02648799, -0.05457827, -0.00339586, -0.03861612,\n        -0.02852188,  0.04478017,  0.09058408,  0.0198766 , -0.07154213,\n        -0.14043497,  0.02664175, -0.07911503, -0.02397238,  0.10413881,\n         0.01074672, -0.02098845,  0.05726629,  0.08587891,  0.04663802,\n        -0.07617614,  0.08382248, -0.05756453, -0.00537495,  0.02765768,\n         0.05966743, -0.09275575,  0.09132898, -0.03411004, -0.11128342,\n        -0.01560384, -0.04309869,  0.08575775,  0.02638629, -0.00027417,\n         0.04176026, -0.02452355, -0.09161343, -0.12658899, -0.0884955 ,\n         0.00123525, -0.03394348, -0.03826233, -0.0472492 , -0.03134252,\n         0.09108598, -0.03336433,  0.09566312, -0.04078798]],\n      dtype=float32)\n\n\n\n학습 과정에서 저장된 모델을 불러와 구조와 가중치 일부를 살펴보자\n\n\nclear_session()\nmodel = keras.models.load_model('/content/model1.h5')\nmodel.summary()\n\n\nmodel.get_weights()[0][0][0]\n\narray([[-0.02984254, -0.12516664, -0.09413426,  0.09054146, -0.07211596,\n        -0.01527972,  0.00230363,  0.04401932, -0.01355622,  0.04863958,\n        -0.08964277, -0.04560584,  0.05172559, -0.11350822, -0.03701778,\n        -0.04161173,  0.02648799, -0.05457827, -0.00339586, -0.03861612,\n        -0.02852188,  0.04478017,  0.09058408,  0.0198766 , -0.07154213,\n        -0.14043497,  0.02664175, -0.07911503, -0.02397238,  0.10413881,\n         0.01074672, -0.02098845,  0.05726629,  0.08587891,  0.04663802,\n        -0.07617614,  0.08382248, -0.05756453, -0.00537495,  0.02765768,\n         0.05966743, -0.09275575,  0.09132898, -0.03411004, -0.11128342,\n        -0.01560384, -0.04309869,  0.08575775,  0.02638629, -0.00027417,\n         0.04176026, -0.02452355, -0.09161343, -0.12658899, -0.0884955 ,\n         0.00123525, -0.03394348, -0.03826233, -0.0472492 , -0.03134252,\n         0.09108598, -0.03336433,  0.09566312, -0.04078798]],\n      dtype=float32)\n\n\n\n.predict( )\n\n\npred_train = model.predict(train_x)\npred_test = model.predict(test_x)\n\nsingle_pred_train = pred_train.argmax(axis=1)\nsingle_pred_test = pred_test.argmax(axis=1)\n\nlogi_train_accuracy = accuracy_score(train_y.argmax(axis=1), single_pred_train)\nlogi_test_accuracy = accuracy_score(test_y.argmax(axis=1), single_pred_test)\n\nprint('CNN')\nprint(f'트레이닝 정확도 : {logi_train_accuracy*100:.2f}%')\nprint(f'테스트 정확도 : {logi_test_accuracy*100:.2f}%')\n\n1500/1500 [==============================] - 4s 2ms/step\n313/313 [==============================] - 1s 2ms/step\nCNN\n트레이닝 정확도 : 99.46%\n테스트 정확도 : 99.29%\n\n\n\n\n\n\n실제 데이터 확인\n\n\n'''\n성능 확인을 위해\nCtrl+Enter를 이용하여\n반복 실행 해보자!\n'''\n\nid = np.random.randint(0,10000)\n\nprint(f'id = {id}')\nprint(f'다음 그림은 숫자 {test_y.argmax(axis=1)[id]} 입니다.')\nprint(f'모델의 예측 : {single_pred_test[id]}')\nprint(f'모델의 카테고리별 확률 : {np.floor(pred_test[id]*100)}')\n\nif test_y.argmax(axis=1)[id] == single_pred_test[id] :\n    print('정답입니다')\nelse :\n    print('틀렸어요')\n\nplt.imshow(test_x[id].reshape([28,-1]), cmap='Greys')\nplt.show()\n\nid = 4950\n다음 그림은 숫자 2 입니다.\n모델의 예측 : 2\n모델의 카테고리별 확률 : [ 0.  0. 99.  0.  0.  0.  0.  0.  0.  0.]\n정답입니다\n\n\n\n\n\n\n틀린 이미지만 확인해보기\n\n\ntrue_false = (test_y.argmax(axis=1) == single_pred_test)\nf_id = np.where(true_false == False)[0]\nf_n = len(f_id)\n\nid = f_id[np.random.randint(0,f_n)]\n\nprint(f'id = {id}')\nprint(f'다음 그림은 숫자 {test_y.argmax(axis=1)[id]} 입니다.')\nprint(f'모델의 예측 : {single_pred_test[id]}')\nprint(f'모델의 카테고리별 확률 : {np.floor(pred_test[id]*100)}')\n\nif test_y.argmax(axis=1)[id] == single_pred_test[id] :\n    print('정답입니다')\nelse :\n    print('틀렸어요')\n\nplt.imshow(test_x[id].reshape([28,-1]), cmap='Greys')\nplt.show()\n\nid = 9594\n다음 그림은 숫자 1 입니다.\n모델의 예측 : 6\n모델의 카테고리별 확률 : [ 0. 24.  0.  0.  0.  0. 73.  0.  1.  0.]\n틀렸어요"
  },
  {
    "objectID": "posts/image/2021-01-30-02. CNNwithMNIST.html#data-loading",
    "href": "posts/image/2021-01-30-02. CNNwithMNIST.html#data-loading",
    "title": "01. MNIST",
    "section": "",
    "text": "(train_x, train_y), (test_x, test_y) = keras.datasets.mnist.load_data()\n\nDownloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n11490434/11490434 [==============================] - 0s 0us/step\n\n\n\nprint(train_x.shape, train_y.shape, test_x.shape, test_y.shape)\n\n(60000, 28, 28) (60000,) (10000, 28, 28) (10000,)\n\n\n\n데이터 살펴보기\n\n\nid = np.random.randint(0, 10000)\n\nprint(f'id = {id}')\nprint(f'다음 그림은 숫자 {test_y[id]} 입니다.')\n\nplt.imshow(test_x[id], cmap='Greys')\nplt.show()\n\nid = 1749\n다음 그림은 숫자 2 입니다."
  },
  {
    "objectID": "posts/image/2021-01-30-02. CNNwithMNIST.html#data-preprocessing",
    "href": "posts/image/2021-01-30-02. CNNwithMNIST.html#data-preprocessing",
    "title": "01. MNIST",
    "section": "",
    "text": "Data split\n\ntraining set : validation set = 8 : 2\n재연을 위한 난수 고정 : 2023\n\n\n\ntrain_x, val_x, train_y, val_y = train_test_split(train_x, train_y, test_size=0.2, random_state=2023)\n\n\nScaling\n\nmin-max scaling\n\n\n\nprint('max :', train_x.max(),'  min :', train_x.min())\n\nmax : 255   min : 0\n\n\n\nmax_v, min_v = train_x.max(), train_x.min()\nmax_v, min_v\n\n(255, 0)\n\n\n\ntrain_x = (train_x - min_v) / (max_v - min_v)\nval_x = (val_x - min_v) / (max_v - min_v)\ntest_x = (test_x - min_v) / (max_v - min_v)\n\n\nprint('max :', train_x.max(),'  min :', train_x.min())\n\nmax : 1.0   min : 0.0\n\n\n\nOne-Hot Encoding\n\n\nfrom tensorflow.keras.utils import to_categorical\n\n\nclass_n = len(np.unique(train_y))\n\n\ntrain_y = to_categorical(train_y, class_n)\nval_y = to_categorical(val_y, class_n)\ntest_y = to_categorical(test_y, class_n)\n\n\ntrain_x.shape, train_y.shape\n\n((48000, 28, 28), (48000, 10))\n\n\n\n흑백 정보를 명시하기 위한 reshape\n\n\ntrain_x = np.expand_dims(train_x, axis=-1)\nval_x = np.expand_dims(val_x, axis=-1)\ntest_x = np.expand_dims(test_x, axis=-1)\n\n\ntrain_x.shape, train_y.shape, val_x.shape, val_y.shape, test_x.shape, test_y.shape\n\n((48000, 28, 28, 1),\n (48000, 10),\n (12000, 28, 28, 1),\n (12000, 10),\n (10000, 28, 28, 1),\n (10000, 10))"
  },
  {
    "objectID": "posts/image/2021-01-30-02. CNNwithMNIST.html#image-data-augmentation",
    "href": "posts/image/2021-01-30-02. CNNwithMNIST.html#image-data-augmentation",
    "title": "01. MNIST",
    "section": "",
    "text": "ImageDataGenerator\n.flow( )\n\n\ntrainIDG = ImageDataGenerator(rotation_range=15,    # randomly rotate images in the range (degrees, 0 to 180)\n                            zoom_range = 0.1,       # Randomly zoom image\n                            width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n                            height_shift_range=0.1, # randomly shift images vertically (fraction of total height)\n                            horizontal_flip=False,  # randomly flip images\n                            vertical_flip=False)    # randomly flip images\n\nvalIDG = ImageDataGenerator()\n\n\n## ImageDataGenerator 설정에 따라 불필요 할 수 있다\n# trainIDG.fit(train_x)\n# valIDG.fit(val_x)\n\n\nflow_trainIDG = trainIDG.flow(train_x, train_y, batch_size=256)\nflow_valIDG = valIDG.flow(val_x, val_y, batch_size=256)"
  },
  {
    "objectID": "posts/image/2021-01-30-02. CNNwithMNIST.html#modeling-cnn",
    "href": "posts/image/2021-01-30-02. CNNwithMNIST.html#modeling-cnn",
    "title": "01. MNIST",
    "section": "",
    "text": "조건\n\nSequential API, Functiona API 중 택일.\n이 구조를 미니 버전으로 활용. 참고 링크\nDropOut, BatchNormalization 등의 기능도 같이 활용\nEarly Stopping을 사용\n\nSequential API\n\n\n# 1. 세션 클리어\nclear_session()\n\n# 2. 모델 선언\nmodel1 = Sequential()\n\n# 3. 레이어 블록 조립\nmodel1.add( Input(shape=(28,28,1)) )\n\nmodel1.add( Conv2D(filters=64,          # Conv2D 필터를 통해 새롭게 제작하려는 feature map의 수\n                   kernel_size=(3,3),   # Conv2D 필터의 가로 세로 사이즈\n                   strides=(1,1),       # Conv2D 필터의 이동 보폭\n                   padding='same',      # 1. 기존의 사이즈를 보존하겠다. | 2. 외곽의 정보를 조금 더 반영하려고!\n                   activation='relu',   # 빼먹지 않게 주의!\n                   ) )\nmodel1.add( Conv2D(filters=64,          # Conv2D 필터를 통해 새롭게 제작하려는 feature map의 수\n                   kernel_size=(3,3),   # Conv2D 필터의 가로 세로 사이즈\n                   strides=(1,1),       # Conv2D 필터의 이동 보폭\n                   padding='same',      # 1. 기존의 사이즈를 보존하겠다. | 2. 외곽의 정보를 조금 더 반영하려고!\n                   activation='relu',   # 빼먹지 않게 주의!\n                   ) )\nmodel1.add( MaxPool2D(pool_size=(2,2),  # Maxpool2D 필터의 가로 세로 사이즈\n                      strides=(2,2)     # Maxpool2D 필터의 이동 보폭 : 기본적으로 pool_size를 따른다.\n                      ) )\nmodel1.add( BatchNormalization() )\nmodel1.add( Dropout(0.2) )\n\nmodel1.add( Conv2D(filters=128,         # Conv2D 필터를 통해 새롭게 제작하려는 feature map의 수\n                   kernel_size=(3,3),   # Conv2D 필터의 가로 세로 사이즈\n                   strides=(1,1),       # Conv2D 필터의 이동 보폭\n                   padding='same',      # 1. 기존의 사이즈를 보존하겠다. | 2. 외곽의 정보를 조금 더 반영하려고!\n                   activation='relu',   # 빼먹지 않게 주의!\n                   ) )\nmodel1.add( Conv2D(filters=128,         # Conv2D 필터를 통해 새롭게 제작하려는 feature map의 수\n                   kernel_size=(3,3),   # Conv2D 필터의 가로 세로 사이즈\n                   strides=(1,1),       # Conv2D 필터의 이동 보폭\n                   padding='same',      # 1. 기존의 사이즈를 보존하겠다. | 2. 외곽의 정보를 조금 더 반영하려고!\n                   activation='relu',   # 빼먹지 않게 주의!\n                   ) )\nmodel1.add( MaxPool2D(pool_size=(2,2),  # Maxpool2D 필터의 가로 세로 사이즈\n                      strides=(2,2)     # Maxpool2D 필터의 이동 보폭 : 기본적으로 pool_size를 따른다.\n                      ) )\nmodel1.add( BatchNormalization() )\nmodel1.add( Dropout(0.2) )\n\nmodel1.add( Flatten() )\nmodel1.add( Dense(256, activation='relu') )\nmodel1.add( Dense(10, activation='softmax') )\n\n# 4. 컴파일\nmodel1.compile(optimizer='adam', loss='categorical_crossentropy',\n              metrics=['accuracy'])\n\nmodel1.summary()\n\n\nFunctional API\n\n\n# 1. 세션 클리어\nclear_session()\n\n# 2. 레이어 엮기\nil = Input(shape=(28,28,1))\n\nhl = Conv2D(filters=64,          # Conv2D 필터를 통해 새롭게 제작하려는 feature map의 수\n            kernel_size=(3,3),   # Conv2D 필터의 가로 세로 사이즈\n            strides=(1,1),       # Conv2D 필터의 이동 보폭\n            padding='same',      # 1. 기존의 사이즈를 보존하겠다. | 2. 외곽의 정보를 조금 더 반영하려고!\n            activation='relu',   # 빼먹지 않게 주의!\n            )(il)\nhl = Conv2D(filters=64,          # Conv2D 필터를 통해 새롭게 제작하려는 feature map의 수\n            kernel_size=(3,3),   # Conv2D 필터의 가로 세로 사이즈\n            strides=(1,1),       # Conv2D 필터의 이동 보폭\n            padding='same',      # 1. 기존의 사이즈를 보존하겠다. | 2. 외곽의 정보를 조금 더 반영하려고!\n            activation='relu',   # 빼먹지 않게 주의!\n            )(hl)\nhl = MaxPool2D(pool_size=(2,2),  # Maxpool2D 필터의 가로 세로 사이즈\n               strides=(2,2)     # Maxpool2D 필터의 이동 보폭 : 기본적으로 pool_size를 따른다.\n               )(hl)\nhl = BatchNormalization()(hl)\nhl = Dropout(0.2)(hl)\n\nhl = Conv2D(filters=128,         # Conv2D 필터를 통해 새롭게 제작하려는 feature map의 수\n            kernel_size=(3,3),   # Conv2D 필터의 가로 세로 사이즈\n            strides=(1,1),       # Conv2D 필터의 이동 보폭\n            padding='same',      # 1. 기존의 사이즈를 보존하겠다. | 2. 외곽의 정보를 조금 더 반영하려고!\n            activation='relu',   # 빼먹지 않게 주의!\n            )(hl)\nhl = Conv2D(filters=128,         # Conv2D 필터를 통해 새롭게 제작하려는 feature map의 수\n            kernel_size=(3,3),   # Conv2D 필터의 가로 세로 사이즈\n            strides=(1,1),       # Conv2D 필터의 이동 보폭\n            padding='same',      # 1. 기존의 사이즈를 보존하겠다. | 2. 외곽의 정보를 조금 더 반영하려고!\n            activation='relu',   # 빼먹지 않게 주의!\n            )(hl)\nhl = MaxPool2D(pool_size=(2,2),  # Maxpool2D 필터의 가로 세로 사이즈\n               strides=(2,2)     # Maxpool2D 필터의 이동 보폭 : 기본적으로 pool_size를 따른다.\n               )(hl)\nhl = BatchNormalization()(hl)\nhl = Dropout(0.2)(hl)\n\nhl = Flatten()(hl)\nhl = Dense(256, activation='relu')(hl)\nol = Dense(10, activation='softmax')(hl)\n\n# 3. 모델의 시작과 끝 지정\nmodel2 = Model(il, ol)\n\n# 4. 컴파일\nmodel2.compile(optimizer='adam', loss='categorical_crossentropy',\n              metrics=['accuracy'])\n\nmodel2.summary()\n\nModel: \"model\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n input_1 (InputLayer)        [(None, 28, 28, 1)]       0         \n                                                                 \n conv2d (Conv2D)             (None, 28, 28, 64)        640       \n                                                                 \n conv2d_1 (Conv2D)           (None, 28, 28, 64)        36928     \n                                                                 \n max_pooling2d (MaxPooling2  (None, 14, 14, 64)        0         \n D)                                                              \n                                                                 \n batch_normalization (Batch  (None, 14, 14, 64)        256       \n Normalization)                                                  \n                                                                 \n dropout (Dropout)           (None, 14, 14, 64)        0         \n                                                                 \n conv2d_2 (Conv2D)           (None, 14, 14, 128)       73856     \n                                                                 \n conv2d_3 (Conv2D)           (None, 14, 14, 128)       147584    \n                                                                 \n max_pooling2d_1 (MaxPoolin  (None, 7, 7, 128)         0         \n g2D)                                                            \n                                                                 \n batch_normalization_1 (Bat  (None, 7, 7, 128)         512       \n chNormalization)                                                \n                                                                 \n dropout_1 (Dropout)         (None, 7, 7, 128)         0         \n                                                                 \n flatten (Flatten)           (None, 6272)              0         \n                                                                 \n dense (Dense)               (None, 256)               1605888   \n                                                                 \n dense_1 (Dense)             (None, 10)                2570      \n                                                                 \n=================================================================\nTotal params: 1868234 (7.13 MB)\nTrainable params: 1867850 (7.13 MB)\nNon-trainable params: 384 (1.50 KB)\n_________________________________________________________________\n\n\n\nEarly Stopping\n\n\nes = EarlyStopping(monitor='val_loss',         # 얼리 스토핑을 적용할 관측 대상\n                   min_delta=0,                # Threshold. 설정한 값 이상으로 변화해야 성능이 개선되었다고 간주.\n                   patience=3,                 # 성능 개선이 발생하지 않았을 때, 몇 epoch를 더 지켜볼 것인가\n                   verbose=1,\n                   restore_best_weights=True)  # 성능이 가장 좋은 epoch의 가중치를 적용함.\n\n\nModel Checkpoint\n\n\nfrom tensorflow.keras.callbacks import ModelCheckpoint\n\n\nmcp = ModelCheckpoint(filepath='/content/model1.h5',   # 모델 저장 경로\n                      monitor='val_loss',              # 모델 저장의 관심 대상\n                      verbose=1,                       # 어느 시점에서 저장되는지 알려줌\n                      save_best_only=True,             # 최고 성능 모델만 저장\n                      save_weights_only=False)         # True : 가중치만 저장 | False : 모델 구조 포함하여 저장\n\n\n.fit( )\n\n\nhistory = model1.fit(flow_trainIDG, epochs=10000, verbose=1,\n                     validation_data=flow_valIDG,\n                     callbacks=[es, mcp]\n                     )\n\nEpoch 1/10000\n188/188 [==============================] - ETA: 0s - loss: 0.3212 - accuracy: 0.9084\nEpoch 1: val_loss improved from inf to 2.61382, saving model to /content/model1.h5\n188/188 [==============================] - 30s 92ms/step - loss: 0.3212 - accuracy: 0.9084 - val_loss: 2.6138 - val_accuracy: 0.1226\nEpoch 2/10000\n  1/188 [..............................] - ETA: 20s - loss: 0.0857 - accuracy: 0.9805188/188 [==============================] - ETA: 0s - loss: 0.0771 - accuracy: 0.9756\nEpoch 2: val_loss improved from 2.61382 to 0.95099, saving model to /content/model1.h5\n188/188 [==============================] - 17s 91ms/step - loss: 0.0771 - accuracy: 0.9756 - val_loss: 0.9510 - val_accuracy: 0.6347\nEpoch 3/10000\n188/188 [==============================] - ETA: 0s - loss: 0.0593 - accuracy: 0.9808\nEpoch 3: val_loss improved from 0.95099 to 0.03867, saving model to /content/model1.h5\n188/188 [==============================] - 17s 88ms/step - loss: 0.0593 - accuracy: 0.9808 - val_loss: 0.0387 - val_accuracy: 0.9902\nEpoch 4/10000\n188/188 [==============================] - ETA: 0s - loss: 0.0476 - accuracy: 0.9853\nEpoch 4: val_loss did not improve from 0.03867\n188/188 [==============================] - 17s 89ms/step - loss: 0.0476 - accuracy: 0.9853 - val_loss: 0.0421 - val_accuracy: 0.9869\nEpoch 5/10000\n188/188 [==============================] - ETA: 0s - loss: 0.0443 - accuracy: 0.9863\nEpoch 5: val_loss improved from 0.03867 to 0.03179, saving model to /content/model1.h5\n188/188 [==============================] - 16s 87ms/step - loss: 0.0443 - accuracy: 0.9863 - val_loss: 0.0318 - val_accuracy: 0.9911\nEpoch 6/10000\n188/188 [==============================] - ETA: 0s - loss: 0.0374 - accuracy: 0.9881\nEpoch 6: val_loss did not improve from 0.03179\n188/188 [==============================] - 17s 91ms/step - loss: 0.0374 - accuracy: 0.9881 - val_loss: 0.0564 - val_accuracy: 0.9837\nEpoch 7/10000\n188/188 [==============================] - ETA: 0s - loss: 0.0386 - accuracy: 0.9878\nEpoch 7: val_loss improved from 0.03179 to 0.03126, saving model to /content/model1.h5\n188/188 [==============================] - 17s 89ms/step - loss: 0.0386 - accuracy: 0.9878 - val_loss: 0.0313 - val_accuracy: 0.9915\nEpoch 8/10000\n188/188 [==============================] - ETA: 0s - loss: 0.0346 - accuracy: 0.9897\nEpoch 8: val_loss did not improve from 0.03126\n188/188 [==============================] - 17s 91ms/step - loss: 0.0346 - accuracy: 0.9897 - val_loss: 0.0327 - val_accuracy: 0.9897\nEpoch 9/10000\n188/188 [==============================] - ETA: 0s - loss: 0.0313 - accuracy: 0.9904\nEpoch 9: val_loss did not improve from 0.03126\n188/188 [==============================] - 16s 88ms/step - loss: 0.0313 - accuracy: 0.9904 - val_loss: 0.0387 - val_accuracy: 0.9898\nEpoch 10/10000\n188/188 [==============================] - ETA: 0s - loss: 0.0305 - accuracy: 0.9905Restoring model weights from the end of the best epoch: 7.\n\nEpoch 10: val_loss did not improve from 0.03126\n188/188 [==============================] - 16s 87ms/step - loss: 0.0305 - accuracy: 0.9905 - val_loss: 0.0429 - val_accuracy: 0.9890\nEpoch 10: early stopping\n\n\n/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n  saving_api.save_model(\n\n\n\nperformance_test = model1.evaluate(test_x, test_y, batch_size=256)\n\nprint(f'Test Loss: {performance_test[0]:.6f}')\nprint(f'Test Accuracy: {performance_test[1]*100:.3f}%')\n\n40/40 [==============================] - 1s 14ms/step - loss: 0.0222 - accuracy: 0.9929\nTest Loss: 0.022246\nTest Accuracy: 99.290%\n\n\n\nif not isinstance(history, dict):\n    history = history.history\n\nplt.plot(history['accuracy'])\nplt.plot(history['val_accuracy'])\nplt.title('Accuracy : Training vs Validation')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Training', 'Validation'], loc=0)\nplt.show()\n\n\n\n\n\nif not isinstance(history, dict):\n    history = history.history\n\nplt.plot(history['loss'])\nplt.plot(history['val_loss'])\nplt.title('Loss : Training vs Validation')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Training', 'Validation'], loc=0)\nplt.show()"
  },
  {
    "objectID": "posts/image/2021-01-30-02. CNNwithMNIST.html#model-save-load",
    "href": "posts/image/2021-01-30-02. CNNwithMNIST.html#model-save-load",
    "title": "01. MNIST",
    "section": "",
    "text": ".save( )\n.load_model( )\n모델을 새롭게 저장하여 구조와 가중치 일부를 살펴보자\n\n\nmodel1.save('my_first_save.h5')\n\n\nclear_session()\nmodel = keras.models.load_model('my_first_save.h5')\nmodel.summary()\n\nModel: \"sequential\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n conv2d (Conv2D)             (None, 28, 28, 64)        640       \n                                                                 \n conv2d_1 (Conv2D)           (None, 28, 28, 64)        36928     \n                                                                 \n max_pooling2d (MaxPooling2  (None, 14, 14, 64)        0         \n D)                                                              \n                                                                 \n batch_normalization (Batch  (None, 14, 14, 64)        256       \n Normalization)                                                  \n                                                                 \n dropout (Dropout)           (None, 14, 14, 64)        0         \n                                                                 \n conv2d_2 (Conv2D)           (None, 14, 14, 128)       73856     \n                                                                 \n conv2d_3 (Conv2D)           (None, 14, 14, 128)       147584    \n                                                                 \n max_pooling2d_1 (MaxPoolin  (None, 7, 7, 128)         0         \n g2D)                                                            \n                                                                 \n batch_normalization_1 (Bat  (None, 7, 7, 128)         512       \n chNormalization)                                                \n                                                                 \n dropout_1 (Dropout)         (None, 7, 7, 128)         0         \n                                                                 \n flatten (Flatten)           (None, 6272)              0         \n                                                                 \n dense (Dense)               (None, 256)               1605888   \n                                                                 \n dense_1 (Dense)             (None, 10)                2570      \n                                                                 \n=================================================================\nTotal params: 1868234 (7.13 MB)\nTrainable params: 1867850 (7.13 MB)\nNon-trainable params: 384 (1.50 KB)\n_________________________________________________________________\n\n\n\nmodel.get_weights()[0][0][0]\n\narray([[-0.02984254, -0.12516664, -0.09413426,  0.09054146, -0.07211596,\n        -0.01527972,  0.00230363,  0.04401932, -0.01355622,  0.04863958,\n        -0.08964277, -0.04560584,  0.05172559, -0.11350822, -0.03701778,\n        -0.04161173,  0.02648799, -0.05457827, -0.00339586, -0.03861612,\n        -0.02852188,  0.04478017,  0.09058408,  0.0198766 , -0.07154213,\n        -0.14043497,  0.02664175, -0.07911503, -0.02397238,  0.10413881,\n         0.01074672, -0.02098845,  0.05726629,  0.08587891,  0.04663802,\n        -0.07617614,  0.08382248, -0.05756453, -0.00537495,  0.02765768,\n         0.05966743, -0.09275575,  0.09132898, -0.03411004, -0.11128342,\n        -0.01560384, -0.04309869,  0.08575775,  0.02638629, -0.00027417,\n         0.04176026, -0.02452355, -0.09161343, -0.12658899, -0.0884955 ,\n         0.00123525, -0.03394348, -0.03826233, -0.0472492 , -0.03134252,\n         0.09108598, -0.03336433,  0.09566312, -0.04078798]],\n      dtype=float32)\n\n\n\n학습 과정에서 저장된 모델을 불러와 구조와 가중치 일부를 살펴보자\n\n\nclear_session()\nmodel = keras.models.load_model('/content/model1.h5')\nmodel.summary()\n\n\nmodel.get_weights()[0][0][0]\n\narray([[-0.02984254, -0.12516664, -0.09413426,  0.09054146, -0.07211596,\n        -0.01527972,  0.00230363,  0.04401932, -0.01355622,  0.04863958,\n        -0.08964277, -0.04560584,  0.05172559, -0.11350822, -0.03701778,\n        -0.04161173,  0.02648799, -0.05457827, -0.00339586, -0.03861612,\n        -0.02852188,  0.04478017,  0.09058408,  0.0198766 , -0.07154213,\n        -0.14043497,  0.02664175, -0.07911503, -0.02397238,  0.10413881,\n         0.01074672, -0.02098845,  0.05726629,  0.08587891,  0.04663802,\n        -0.07617614,  0.08382248, -0.05756453, -0.00537495,  0.02765768,\n         0.05966743, -0.09275575,  0.09132898, -0.03411004, -0.11128342,\n        -0.01560384, -0.04309869,  0.08575775,  0.02638629, -0.00027417,\n         0.04176026, -0.02452355, -0.09161343, -0.12658899, -0.0884955 ,\n         0.00123525, -0.03394348, -0.03826233, -0.0472492 , -0.03134252,\n         0.09108598, -0.03336433,  0.09566312, -0.04078798]],\n      dtype=float32)\n\n\n\n.predict( )\n\n\npred_train = model.predict(train_x)\npred_test = model.predict(test_x)\n\nsingle_pred_train = pred_train.argmax(axis=1)\nsingle_pred_test = pred_test.argmax(axis=1)\n\nlogi_train_accuracy = accuracy_score(train_y.argmax(axis=1), single_pred_train)\nlogi_test_accuracy = accuracy_score(test_y.argmax(axis=1), single_pred_test)\n\nprint('CNN')\nprint(f'트레이닝 정확도 : {logi_train_accuracy*100:.2f}%')\nprint(f'테스트 정확도 : {logi_test_accuracy*100:.2f}%')\n\n1500/1500 [==============================] - 4s 2ms/step\n313/313 [==============================] - 1s 2ms/step\nCNN\n트레이닝 정확도 : 99.46%\n테스트 정확도 : 99.29%"
  },
  {
    "objectID": "posts/image/2021-01-30-02. CNNwithMNIST.html#visualization",
    "href": "posts/image/2021-01-30-02. CNNwithMNIST.html#visualization",
    "title": "01. MNIST",
    "section": "",
    "text": "실제 데이터 확인\n\n\n'''\n성능 확인을 위해\nCtrl+Enter를 이용하여\n반복 실행 해보자!\n'''\n\nid = np.random.randint(0,10000)\n\nprint(f'id = {id}')\nprint(f'다음 그림은 숫자 {test_y.argmax(axis=1)[id]} 입니다.')\nprint(f'모델의 예측 : {single_pred_test[id]}')\nprint(f'모델의 카테고리별 확률 : {np.floor(pred_test[id]*100)}')\n\nif test_y.argmax(axis=1)[id] == single_pred_test[id] :\n    print('정답입니다')\nelse :\n    print('틀렸어요')\n\nplt.imshow(test_x[id].reshape([28,-1]), cmap='Greys')\nplt.show()\n\nid = 4950\n다음 그림은 숫자 2 입니다.\n모델의 예측 : 2\n모델의 카테고리별 확률 : [ 0.  0. 99.  0.  0.  0.  0.  0.  0.  0.]\n정답입니다\n\n\n\n\n\n\n틀린 이미지만 확인해보기\n\n\ntrue_false = (test_y.argmax(axis=1) == single_pred_test)\nf_id = np.where(true_false == False)[0]\nf_n = len(f_id)\n\nid = f_id[np.random.randint(0,f_n)]\n\nprint(f'id = {id}')\nprint(f'다음 그림은 숫자 {test_y.argmax(axis=1)[id]} 입니다.')\nprint(f'모델의 예측 : {single_pred_test[id]}')\nprint(f'모델의 카테고리별 확률 : {np.floor(pred_test[id]*100)}')\n\nif test_y.argmax(axis=1)[id] == single_pred_test[id] :\n    print('정답입니다')\nelse :\n    print('틀렸어요')\n\nplt.imshow(test_x[id].reshape([28,-1]), cmap='Greys')\nplt.show()\n\nid = 9594\n다음 그림은 숫자 1 입니다.\n모델의 예측 : 6\n모델의 카테고리별 확률 : [ 0. 24.  0.  0.  0.  0. 73.  0.  1.  0.]\n틀렸어요"
  },
  {
    "objectID": "posts/image/2021-02-02-04. ImageAugmentation2.html",
    "href": "posts/image/2021-02-02-04. ImageAugmentation2.html",
    "title": "03. image DA (2)",
    "section": "",
    "text": "Indeed, I once even proposed that the toughest challenge facing AI workers is to answer the question: “What are the letters ‘A’ and ‘I’? - Douglas R. Hofstadter (1995)\n\n\n\nData source: notMNIST (you need to download notMNIST_small.mat file):\n\n\nsome publicly available fonts and extracted glyphs from them to make a dataset similar to MNIST. There are 10 classes, with letters A-J taken from different fonts.\n\n\nApproaching 0.5% error rate on notMNIST_small would be very impressive. If you run your algorithm on this dataset, please let me know your results.\n\n\n\n\nMany introductions to image classification with deep learning start with MNIST, a standard dataset of handwritten digits. This is unfortunate. Not only does it not produce a “Wow!” effect or show where deep learning shines, but it also can be solved with shallow machine learning techniques. In this case, plain k-Nearest Neighbors produces more than 97% accuracy (or even 99.5% with some data preprocessing!). Moreover, MNIST is not a typical image dataset – and mastering it is unlikely to teach you transferable skills that would be useful for other classification problems\n\nMany good ideas will not work well on MNIST (e.g. batch norm). Inversely many bad ideas may work on MNIST and no[t] transfer to real [computer vision]. - François Chollet’s tweet\n\n\n!wget http://yaroslavvb.com/upload/notMNIST/notMNIST_small.mat\n\n--2023-09-15 06:06:26--  http://yaroslavvb.com/upload/notMNIST/notMNIST_small.mat\nResolving yaroslavvb.com (yaroslavvb.com)... 129.121.4.193\nConnecting to yaroslavvb.com (yaroslavvb.com)|129.121.4.193|:80... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 117586976 (112M)\nSaving to: ‘notMNIST_small.mat’\n\nnotMNIST_small.mat  100%[===================&gt;] 112.14M  19.5MB/s    in 6.7s    \n\n2023-09-15 06:06:33 (16.8 MB/s) - ‘notMNIST_small.mat’ saved [117586976/117586976]\n\n\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy import io\n\n\n\n\n\ndata = io.loadmat('notMNIST_small.mat')\n\n# data\n\n\nx = data['images']\ny = data['labels']\n\n\nx.shape, y.shape\n\n((28, 28, 18724), (18724,))\n\n\n\nresolution = 28\nclasses = 10\n\nx = np.transpose(x, (2, 0, 1))\nprint(x.shape)\nx = x.reshape( (-1, resolution, resolution, 1) )\n\n(18724, 28, 28)\n\n\n\n# sample, x, y, channel\nx.shape, y.shape\n\n((18724, 28, 28, 1), (18724,))\n\n\n\n데이터 살펴보기\n\n\nrand_i = np.random.randint(0, x.shape[0])\n\nplt.title( f'idx: {rand_i} , y: {\"ABCDEFGHIJ\"[ int(y[rand_i]) ]}' )\nplt.imshow( x[rand_i, :, :, 0], cmap='Greys' )\nplt.show()\n\n\n\n\n\nrows = 5\nfig, axes = plt.subplots(rows, classes, figsize=(classes,rows))\n\nfor letter_id in range(classes) :\n    letters = x[y==letter_id]      # 0부터 9까지 각 숫자에 맞는 array가 letters에 들어간다.\n    letters_len = len(letters)\n\n    for row_i in range(rows) :\n        axe = axes[row_i, letter_id]\n        axe.imshow( letters[np.random.randint(letters_len)], cmap='Greys', interpolation='none')\n        axe.axis('off')\n\n\n\n\n\n\n\n\nData split\n\ntraining set : test set = 8 : 2\ntraining set : validation set = 8 : 2\n재현을 위한 난수 고정 : 2023\n\n\n\nfrom sklearn.model_selection import train_test_split\n\n\ntrain_x, test_x, train_y, test_y = train_test_split(x, y, test_size=0.2, random_state=2023)\ntrain_x, val_x, train_y, val_y = train_test_split(train_x, train_y, test_size=0.2, random_state=2023)\n\n\ntrain_x.shape, train_y.shape, val_x.shape, val_y.shape\n\n((11983, 28, 28, 1), (11983,), (2996, 28, 28, 1), (2996,))\n\n\n\nScaling\n\nmin-max scaling\n\n\n\nmax_n, min_n = train_x.max(), train_x.min()\nmax_n, min_n\n\n(255.0, 0.0)\n\n\n\ntrain_x = (train_x - min_n) / (max_n - min_n)\nval_x = (val_x - min_n) / (max_n - min_n)\ntest_x = (test_x - min_n) / (max_n - min_n)\n\n\ntrain_x.max(), train_x.min()\n\n(1.0, 0.0)\n\n\n\nOne-hot encoding\n\n\ntrain_y.shape\n\n(11983,)\n\n\n\nclass_n = len(np.unique(train_y))\nclass_n\n\n10\n\n\n\nfrom tensorflow.keras.utils import to_categorical\n\n\ntrain_y = to_categorical(train_y, class_n)\nval_y = to_categorical(val_y, class_n)\ntest_y = to_categorical(test_y, class_n)\n\n\nData shape 재확인\n\n\ntrain_x.shape, train_y.shape\n\n((11983, 28, 28, 1), (11983, 10))\n\n\n\n\n\n\nImageDataGenerator : 전체 옵션 참고\n.flow( )\n\n\n!mkdir output\n\n\n!ls output\n\n\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\n\n# 데이터 제너레이터를 선언함! 제너레이팅 규칙과 함께!\ntrainIDG = ImageDataGenerator(rescale=1./255,         # 사실 이 부분은 전처리 과정에서 했다.\n                              zca_whitening=True,     # apply ZCA whitening\n                              rotation_range=30,      # randomly rotate images in the range (degrees, 0 to 180)\n                              zoom_range = 0.2,       # randomly zoom image\n                              width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n                              height_shift_range=0.1, # randomly shift images vertically (fraction of total height)\n                              horizontal_flip=True,   # randomly flip images\n                              vertical_flip=True)     # randomly flip images\n\n# 옵션에 따라 필요할 수도 있고 그렇지 않을 수 있다.\ntrainIDG.fit(train_x)\n\n# 학습 할 때마다, '실시간'으로 데이터를 생성하여 학습에 활용하고, 버리고를 반복할 준비!\nflow_trainIDG = trainIDG.flow(train_x, train_y,\n                              batch_size=128,\n                            #   save_to_dir='output',\n                            #   save_prefix='train',\n                            #   save_format='png'\n                              )\n\n/usr/local/lib/python3.10/dist-packages/keras/src/preprocessing/image.py:1444: UserWarning: This ImageDataGenerator specifies `zca_whitening`, which overrides setting of `featurewise_center`.\n  warnings.warn(\n\n\n\n!ls output\n\n\nvalIDG = ImageDataGenerator(rescale=1./255)\n\nflow_valIDG = valIDG.flow(val_x, val_y,           # validation set의 변수명!\n                          batch_size=128,\n                        #   save_to_dir='output',\n                        #   save_prefix='val',\n                        #   save_format='png'\n                          )\n\n\n\n\n\n조건\n\nSequential API, Functional API 중 택일.\n이 구조를 미니 버전으로 활용해봐도 좋다.\nDropOut, BatchNormalization 등의 기능도 같이 활용해보자.\nEarly Stopping을 사용할 것.\n\n\n\nimport tensorflow as tf\nfrom tensorflow import keras\n\nfrom tensorflow.keras.backend import clear_session\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input, Dense, Flatten\nfrom tensorflow.keras.layers import Conv2D, MaxPool2D, BatchNormalization, Dropout\n\n\ntrain_x.shape, train_y.shape\n\n((11983, 28, 28, 1), (11983, 10))\n\n\n\n## Functional API\n# 1. 세션 클리어\nclear_session()\n\n# 2. 레이어 엮기\nil = Input(shape=(28,28,1))\n\nhl = Conv2D(filters=64,        # 새롭게 제작하려는 feature map의 수! 서로 다른 filter의 수!\n            kernel_size=(3,3), # Conv 필터의 가로세로\n            strides=(1,1),     # Conv 필터의 이동 보폭\n            padding='same',    # 1. 사이즈 유지 | 2. 외곽 정보 더 반영\n            activation='relu'  # 주의!\n            )(il)\nhl = Conv2D(filters=64,        # 새롭게 제작하려는 feature map의 수! 서로 다른 filter의 수!\n            kernel_size=(3,3), # Conv 필터의 가로세로\n            strides=(1,1),     # Conv 필터의 이동 보폭\n            padding='same',    # 1. 사이즈 유지 | 2. 외곽 정보 더 반영\n            activation='relu'  # 주의!\n            )(hl)\nhl = MaxPool2D(pool_size=(2,2), # 풀링 필터의 가로세로\n               strides=(2,2)    # 풀링 필터의 이동 보폭\n               )(hl)\nhl = BatchNormalization()(hl)\nhl = Dropout(0.5)(hl)\n\nhl = Conv2D(filters=128,        # 새롭게 제작하려는 feature map의 수! 서로 다른 filter의 수!\n            kernel_size=(3,3), # Conv 필터의 가로세로\n            strides=(1,1),     # Conv 필터의 이동 보폭\n            padding='same',    # 1. 사이즈 유지 | 2. 외곽 정보 더 반영\n            activation='relu'  # 주의!\n            )(hl)\nhl = Conv2D(filters=128,        # 새롭게 제작하려는 feature map의 수! 서로 다른 filter의 수!\n            kernel_size=(3,3), # Conv 필터의 가로세로\n            strides=(1,1),     # Conv 필터의 이동 보폭\n            padding='same',    # 1. 사이즈 유지 | 2. 외곽 정보 더 반영\n            activation='relu'  # 주의!\n            )(hl)\nhl = MaxPool2D(pool_size=(2,2), # 풀링 필터의 가로세로\n               strides=(2,2)    # 풀링 필터의 이동 보폭\n               )(hl)\nhl = BatchNormalization()(hl)\nhl = Dropout(0.5)(hl)\n\nhl = Flatten()(hl)\nhl = Dense(1024, activation='relu')(hl)\n\nol = Dense(10, activation='softmax')(hl)\n\n# 3. 모델의 시작과 끝 지정\nmodel = Model(il, ol)\n\n# 4. 컴파일\nmodel.compile(optimizer='adam', loss='categorical_crossentropy',\n              metrics=['accuracy'])\n\n\nmodel.summary()\n\n\nEarly Stopping\n\n\nfrom tensorflow.keras.callbacks import EarlyStopping\n\n\nes = EarlyStopping(monitor='val_loss',       # 얼리스토핑 적용 대상\n                   min_delta=0,              # 임계값.\n                   patience=3,               # 몇 번 더 지켜볼래.\n                   verbose=1,\n                   restore_best_weights=True # 최적의 가중치로 돌려줌.\n                   )\n\n\n.fit( )\n\nImage Data Augmentation 과정에서 생성한 ImageDataGenerator를 사용해야 한다.\n\n\n\nmodel.fit(flow_trainIDG,               # 위에서 설정한 IDG를 사용해야 합니다!\n          epochs=10000, verbose=1,\n          validation_data=flow_valIDG, # validation data 역시 IDG를 사용해야 합니다.\n          callbacks=[es]\n          )\n\nEpoch 1/10000\n94/94 [==============================] - 29s 172ms/step - loss: 1.7398 - accuracy: 0.5190 - val_loss: 5.2281 - val_accuracy: 0.0988\nEpoch 2/10000\n94/94 [==============================] - 15s 158ms/step - loss: 0.8966 - accuracy: 0.7057 - val_loss: 4.6273 - val_accuracy: 0.0988\nEpoch 3/10000\n94/94 [==============================] - 15s 159ms/step - loss: 0.7712 - accuracy: 0.7480 - val_loss: 4.4361 - val_accuracy: 0.0895\nEpoch 4/10000\n94/94 [==============================] - 15s 158ms/step - loss: 0.6798 - accuracy: 0.7821 - val_loss: 6.2650 - val_accuracy: 0.0895\nEpoch 5/10000\n94/94 [==============================] - 15s 162ms/step - loss: 0.6313 - accuracy: 0.7995 - val_loss: 7.2511 - val_accuracy: 0.0895\nEpoch 6/10000\n94/94 [==============================] - ETA: 0s - loss: 0.5947 - accuracy: 0.8146Restoring model weights from the end of the best epoch: 3.\n94/94 [==============================] - 15s 161ms/step - loss: 0.5947 - accuracy: 0.8146 - val_loss: 9.2555 - val_accuracy: 0.0895\nEpoch 6: early stopping\n\n\n&lt;keras.src.callbacks.History at 0x7fae7c08d750&gt;\n\n\n\n!ls output\n\n\n.evaluate( )\n\n\nmodel.evaluate(test_x, test_y)\n\n118/118 [==============================] - 1s 5ms/step - loss: 3.2877 - accuracy: 0.3356\n\n\n[3.2877118587493896, 0.3356475234031677]\n\n\n\n.predict( )\n\n\ny_pred = model.predict(test_x)\n\n118/118 [==============================] - 0s 3ms/step\n\n\n\n# 원핫 인코딩 한 것을 다시 묶어주는 코드\n# 평가 지표 및 실제 데이터 확인을 위해 필요\n\ny_pred_arg = np.argmax(y_pred, axis=1)\ntest_y_arg = np.argmax(test_y, axis=1)\n\n\n평가 지표\n\n\nfrom sklearn.metrics import accuracy_score, classification_report\n\n\naccuracy_score(test_y_arg, y_pred_arg)\n\n0.33564753004005343\n\n\n\nprint( classification_report(test_y_arg, y_pred_arg) )\n\n              precision    recall  f1-score   support\n\n           0       0.20      0.94      0.33       357\n           1       0.41      0.65      0.50       365\n           2       0.00      0.00      0.00       374\n           3       0.33      0.90      0.48       392\n           4       1.00      0.00      0.00       406\n           5       0.00      0.00      0.00       377\n           6       0.81      0.60      0.69       372\n           7       1.00      0.09      0.17       374\n           8       0.57      0.19      0.28       385\n           9       0.00      0.00      0.00       343\n\n    accuracy                           0.34      3745\n   macro avg       0.43      0.34      0.25      3745\nweighted avg       0.44      0.34      0.25      3745\n\n\n\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n\n\n\n\n\n\n실제 데이터 확인\n\n\nletters_str = \"ABCDEFGHIJ\"\n\nrand_idx = np.random.randint(0, len(y_pred_arg))\ntest_idx = test_y_arg[rand_idx]\npred_idx = y_pred_arg[rand_idx]\nclass_prob = np.floor( y_pred[rand_idx]*100 )\n\nprint(f'idx = {rand_idx}')\nprint(f'해당 인덱스의 이미지는 {letters_str[test_idx]}')\nprint(f'모델의 예측 : {letters_str[pred_idx]}')\nprint(f'모델의 클래스별 확률 : ')\nprint('-------------------')\nfor idx, val in enumerate(letters_str) :\n    print(val, class_prob[idx])\nprint('=================================================')\n\nif test_y_arg[rand_idx] == y_pred_arg[rand_idx] :\n    print('정답')\nelse :\n    print('땡')\n\nplt.imshow(test_x[rand_idx], cmap='Greys')\nplt.show()\n\nidx = 1312\n해당 인덱스의 이미지는 E\n모델의 예측 : B\n모델의 클래스별 확률 : \n-------------------\nA 5.0\nB 40.0\nC 0.0\nD 1.0\nE 16.0\nF 0.0\nG 14.0\nH 0.0\nI 21.0\nJ 0.0\n=================================================\n땡\n\n\n\n\n\n\n틀린 이미지만 확인해보기\n\n\ntemp = (test_y_arg == y_pred_arg)\nfalse_idx = np.where(temp==False)[0]\nfalse_len = len(false_idx)\nfalse_len\n\n2488\n\n\n\nletters_str = \"ABCDEFGHIJ\"\n\nrand_idx = false_idx[np.random.randint(0, false_len)]\ntest_idx = test_y_arg[rand_idx]\npred_idx = y_pred_arg[rand_idx]\nclass_prob = np.floor( y_pred[rand_idx]*100 )\n\nprint(f'idx = {rand_idx}')\nprint(f'해당 인덱스의 이미지는 {letters_str[test_idx]}')\nprint(f'모델의 예측 : {letters_str[pred_idx]}')\nprint(f'모델의 클래스별 확률 : ')\nprint('-------------------')\nfor idx, val in enumerate(letters_str) :\n    print(val, class_prob[idx])\nprint('=================================================')\n\nif test_y_arg[rand_idx] == y_pred_arg[rand_idx] :\n    print('정답')\nelse :\n    print('땡')\n\nplt.imshow(test_x[rand_idx], cmap='Greys')\nplt.show()\n\nidx = 2086\n해당 인덱스의 이미지는 J\n모델의 예측 : D\n모델의 클래스별 확률 : \n-------------------\nA 11.0\nB 0.0\nC 0.0\nD 75.0\nE 0.0\nF 0.0\nG 9.0\nH 0.0\nI 2.0\nJ 0.0\n=================================================\n땡"
  },
  {
    "objectID": "posts/image/2021-02-02-04. ImageAugmentation2.html#notmnist",
    "href": "posts/image/2021-02-02-04. ImageAugmentation2.html#notmnist",
    "title": "03. image DA (2)",
    "section": "",
    "text": "Data source: notMNIST (you need to download notMNIST_small.mat file):\n\n\nsome publicly available fonts and extracted glyphs from them to make a dataset similar to MNIST. There are 10 classes, with letters A-J taken from different fonts.\n\n\nApproaching 0.5% error rate on notMNIST_small would be very impressive. If you run your algorithm on this dataset, please let me know your results."
  },
  {
    "objectID": "posts/image/2021-02-02-04. ImageAugmentation2.html#so-why-not-mnist",
    "href": "posts/image/2021-02-02-04. ImageAugmentation2.html#so-why-not-mnist",
    "title": "03. image DA (2)",
    "section": "",
    "text": "Many introductions to image classification with deep learning start with MNIST, a standard dataset of handwritten digits. This is unfortunate. Not only does it not produce a “Wow!” effect or show where deep learning shines, but it also can be solved with shallow machine learning techniques. In this case, plain k-Nearest Neighbors produces more than 97% accuracy (or even 99.5% with some data preprocessing!). Moreover, MNIST is not a typical image dataset – and mastering it is unlikely to teach you transferable skills that would be useful for other classification problems\n\nMany good ideas will not work well on MNIST (e.g. batch norm). Inversely many bad ideas may work on MNIST and no[t] transfer to real [computer vision]. - François Chollet’s tweet\n\n\n!wget http://yaroslavvb.com/upload/notMNIST/notMNIST_small.mat\n\n--2023-09-15 06:06:26--  http://yaroslavvb.com/upload/notMNIST/notMNIST_small.mat\nResolving yaroslavvb.com (yaroslavvb.com)... 129.121.4.193\nConnecting to yaroslavvb.com (yaroslavvb.com)|129.121.4.193|:80... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 117586976 (112M)\nSaving to: ‘notMNIST_small.mat’\n\nnotMNIST_small.mat  100%[===================&gt;] 112.14M  19.5MB/s    in 6.7s    \n\n2023-09-15 06:06:33 (16.8 MB/s) - ‘notMNIST_small.mat’ saved [117586976/117586976]\n\n\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy import io"
  },
  {
    "objectID": "posts/image/2021-02-02-04. ImageAugmentation2.html#data-loading",
    "href": "posts/image/2021-02-02-04. ImageAugmentation2.html#data-loading",
    "title": "03. image DA (2)",
    "section": "",
    "text": "data = io.loadmat('notMNIST_small.mat')\n\n# data\n\n\nx = data['images']\ny = data['labels']\n\n\nx.shape, y.shape\n\n((28, 28, 18724), (18724,))\n\n\n\nresolution = 28\nclasses = 10\n\nx = np.transpose(x, (2, 0, 1))\nprint(x.shape)\nx = x.reshape( (-1, resolution, resolution, 1) )\n\n(18724, 28, 28)\n\n\n\n# sample, x, y, channel\nx.shape, y.shape\n\n((18724, 28, 28, 1), (18724,))\n\n\n\n데이터 살펴보기\n\n\nrand_i = np.random.randint(0, x.shape[0])\n\nplt.title( f'idx: {rand_i} , y: {\"ABCDEFGHIJ\"[ int(y[rand_i]) ]}' )\nplt.imshow( x[rand_i, :, :, 0], cmap='Greys' )\nplt.show()\n\n\n\n\n\nrows = 5\nfig, axes = plt.subplots(rows, classes, figsize=(classes,rows))\n\nfor letter_id in range(classes) :\n    letters = x[y==letter_id]      # 0부터 9까지 각 숫자에 맞는 array가 letters에 들어간다.\n    letters_len = len(letters)\n\n    for row_i in range(rows) :\n        axe = axes[row_i, letter_id]\n        axe.imshow( letters[np.random.randint(letters_len)], cmap='Greys', interpolation='none')\n        axe.axis('off')"
  },
  {
    "objectID": "posts/image/2021-02-02-04. ImageAugmentation2.html#data-preprocessing",
    "href": "posts/image/2021-02-02-04. ImageAugmentation2.html#data-preprocessing",
    "title": "03. image DA (2)",
    "section": "",
    "text": "Data split\n\ntraining set : test set = 8 : 2\ntraining set : validation set = 8 : 2\n재현을 위한 난수 고정 : 2023\n\n\n\nfrom sklearn.model_selection import train_test_split\n\n\ntrain_x, test_x, train_y, test_y = train_test_split(x, y, test_size=0.2, random_state=2023)\ntrain_x, val_x, train_y, val_y = train_test_split(train_x, train_y, test_size=0.2, random_state=2023)\n\n\ntrain_x.shape, train_y.shape, val_x.shape, val_y.shape\n\n((11983, 28, 28, 1), (11983,), (2996, 28, 28, 1), (2996,))\n\n\n\nScaling\n\nmin-max scaling\n\n\n\nmax_n, min_n = train_x.max(), train_x.min()\nmax_n, min_n\n\n(255.0, 0.0)\n\n\n\ntrain_x = (train_x - min_n) / (max_n - min_n)\nval_x = (val_x - min_n) / (max_n - min_n)\ntest_x = (test_x - min_n) / (max_n - min_n)\n\n\ntrain_x.max(), train_x.min()\n\n(1.0, 0.0)\n\n\n\nOne-hot encoding\n\n\ntrain_y.shape\n\n(11983,)\n\n\n\nclass_n = len(np.unique(train_y))\nclass_n\n\n10\n\n\n\nfrom tensorflow.keras.utils import to_categorical\n\n\ntrain_y = to_categorical(train_y, class_n)\nval_y = to_categorical(val_y, class_n)\ntest_y = to_categorical(test_y, class_n)\n\n\nData shape 재확인\n\n\ntrain_x.shape, train_y.shape\n\n((11983, 28, 28, 1), (11983, 10))"
  },
  {
    "objectID": "posts/image/2021-02-02-04. ImageAugmentation2.html#image-data-augmentation",
    "href": "posts/image/2021-02-02-04. ImageAugmentation2.html#image-data-augmentation",
    "title": "03. image DA (2)",
    "section": "",
    "text": "ImageDataGenerator : 전체 옵션 참고\n.flow( )\n\n\n!mkdir output\n\n\n!ls output\n\n\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\n\n# 데이터 제너레이터를 선언함! 제너레이팅 규칙과 함께!\ntrainIDG = ImageDataGenerator(rescale=1./255,         # 사실 이 부분은 전처리 과정에서 했다.\n                              zca_whitening=True,     # apply ZCA whitening\n                              rotation_range=30,      # randomly rotate images in the range (degrees, 0 to 180)\n                              zoom_range = 0.2,       # randomly zoom image\n                              width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n                              height_shift_range=0.1, # randomly shift images vertically (fraction of total height)\n                              horizontal_flip=True,   # randomly flip images\n                              vertical_flip=True)     # randomly flip images\n\n# 옵션에 따라 필요할 수도 있고 그렇지 않을 수 있다.\ntrainIDG.fit(train_x)\n\n# 학습 할 때마다, '실시간'으로 데이터를 생성하여 학습에 활용하고, 버리고를 반복할 준비!\nflow_trainIDG = trainIDG.flow(train_x, train_y,\n                              batch_size=128,\n                            #   save_to_dir='output',\n                            #   save_prefix='train',\n                            #   save_format='png'\n                              )\n\n/usr/local/lib/python3.10/dist-packages/keras/src/preprocessing/image.py:1444: UserWarning: This ImageDataGenerator specifies `zca_whitening`, which overrides setting of `featurewise_center`.\n  warnings.warn(\n\n\n\n!ls output\n\n\nvalIDG = ImageDataGenerator(rescale=1./255)\n\nflow_valIDG = valIDG.flow(val_x, val_y,           # validation set의 변수명!\n                          batch_size=128,\n                        #   save_to_dir='output',\n                        #   save_prefix='val',\n                        #   save_format='png'\n                          )"
  },
  {
    "objectID": "posts/image/2021-02-02-04. ImageAugmentation2.html#modeling-cnn",
    "href": "posts/image/2021-02-02-04. ImageAugmentation2.html#modeling-cnn",
    "title": "03. image DA (2)",
    "section": "",
    "text": "조건\n\nSequential API, Functional API 중 택일.\n이 구조를 미니 버전으로 활용해봐도 좋다.\nDropOut, BatchNormalization 등의 기능도 같이 활용해보자.\nEarly Stopping을 사용할 것.\n\n\n\nimport tensorflow as tf\nfrom tensorflow import keras\n\nfrom tensorflow.keras.backend import clear_session\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input, Dense, Flatten\nfrom tensorflow.keras.layers import Conv2D, MaxPool2D, BatchNormalization, Dropout\n\n\ntrain_x.shape, train_y.shape\n\n((11983, 28, 28, 1), (11983, 10))\n\n\n\n## Functional API\n# 1. 세션 클리어\nclear_session()\n\n# 2. 레이어 엮기\nil = Input(shape=(28,28,1))\n\nhl = Conv2D(filters=64,        # 새롭게 제작하려는 feature map의 수! 서로 다른 filter의 수!\n            kernel_size=(3,3), # Conv 필터의 가로세로\n            strides=(1,1),     # Conv 필터의 이동 보폭\n            padding='same',    # 1. 사이즈 유지 | 2. 외곽 정보 더 반영\n            activation='relu'  # 주의!\n            )(il)\nhl = Conv2D(filters=64,        # 새롭게 제작하려는 feature map의 수! 서로 다른 filter의 수!\n            kernel_size=(3,3), # Conv 필터의 가로세로\n            strides=(1,1),     # Conv 필터의 이동 보폭\n            padding='same',    # 1. 사이즈 유지 | 2. 외곽 정보 더 반영\n            activation='relu'  # 주의!\n            )(hl)\nhl = MaxPool2D(pool_size=(2,2), # 풀링 필터의 가로세로\n               strides=(2,2)    # 풀링 필터의 이동 보폭\n               )(hl)\nhl = BatchNormalization()(hl)\nhl = Dropout(0.5)(hl)\n\nhl = Conv2D(filters=128,        # 새롭게 제작하려는 feature map의 수! 서로 다른 filter의 수!\n            kernel_size=(3,3), # Conv 필터의 가로세로\n            strides=(1,1),     # Conv 필터의 이동 보폭\n            padding='same',    # 1. 사이즈 유지 | 2. 외곽 정보 더 반영\n            activation='relu'  # 주의!\n            )(hl)\nhl = Conv2D(filters=128,        # 새롭게 제작하려는 feature map의 수! 서로 다른 filter의 수!\n            kernel_size=(3,3), # Conv 필터의 가로세로\n            strides=(1,1),     # Conv 필터의 이동 보폭\n            padding='same',    # 1. 사이즈 유지 | 2. 외곽 정보 더 반영\n            activation='relu'  # 주의!\n            )(hl)\nhl = MaxPool2D(pool_size=(2,2), # 풀링 필터의 가로세로\n               strides=(2,2)    # 풀링 필터의 이동 보폭\n               )(hl)\nhl = BatchNormalization()(hl)\nhl = Dropout(0.5)(hl)\n\nhl = Flatten()(hl)\nhl = Dense(1024, activation='relu')(hl)\n\nol = Dense(10, activation='softmax')(hl)\n\n# 3. 모델의 시작과 끝 지정\nmodel = Model(il, ol)\n\n# 4. 컴파일\nmodel.compile(optimizer='adam', loss='categorical_crossentropy',\n              metrics=['accuracy'])\n\n\nmodel.summary()\n\n\nEarly Stopping\n\n\nfrom tensorflow.keras.callbacks import EarlyStopping\n\n\nes = EarlyStopping(monitor='val_loss',       # 얼리스토핑 적용 대상\n                   min_delta=0,              # 임계값.\n                   patience=3,               # 몇 번 더 지켜볼래.\n                   verbose=1,\n                   restore_best_weights=True # 최적의 가중치로 돌려줌.\n                   )\n\n\n.fit( )\n\nImage Data Augmentation 과정에서 생성한 ImageDataGenerator를 사용해야 한다.\n\n\n\nmodel.fit(flow_trainIDG,               # 위에서 설정한 IDG를 사용해야 합니다!\n          epochs=10000, verbose=1,\n          validation_data=flow_valIDG, # validation data 역시 IDG를 사용해야 합니다.\n          callbacks=[es]\n          )\n\nEpoch 1/10000\n94/94 [==============================] - 29s 172ms/step - loss: 1.7398 - accuracy: 0.5190 - val_loss: 5.2281 - val_accuracy: 0.0988\nEpoch 2/10000\n94/94 [==============================] - 15s 158ms/step - loss: 0.8966 - accuracy: 0.7057 - val_loss: 4.6273 - val_accuracy: 0.0988\nEpoch 3/10000\n94/94 [==============================] - 15s 159ms/step - loss: 0.7712 - accuracy: 0.7480 - val_loss: 4.4361 - val_accuracy: 0.0895\nEpoch 4/10000\n94/94 [==============================] - 15s 158ms/step - loss: 0.6798 - accuracy: 0.7821 - val_loss: 6.2650 - val_accuracy: 0.0895\nEpoch 5/10000\n94/94 [==============================] - 15s 162ms/step - loss: 0.6313 - accuracy: 0.7995 - val_loss: 7.2511 - val_accuracy: 0.0895\nEpoch 6/10000\n94/94 [==============================] - ETA: 0s - loss: 0.5947 - accuracy: 0.8146Restoring model weights from the end of the best epoch: 3.\n94/94 [==============================] - 15s 161ms/step - loss: 0.5947 - accuracy: 0.8146 - val_loss: 9.2555 - val_accuracy: 0.0895\nEpoch 6: early stopping\n\n\n&lt;keras.src.callbacks.History at 0x7fae7c08d750&gt;\n\n\n\n!ls output\n\n\n.evaluate( )\n\n\nmodel.evaluate(test_x, test_y)\n\n118/118 [==============================] - 1s 5ms/step - loss: 3.2877 - accuracy: 0.3356\n\n\n[3.2877118587493896, 0.3356475234031677]\n\n\n\n.predict( )\n\n\ny_pred = model.predict(test_x)\n\n118/118 [==============================] - 0s 3ms/step\n\n\n\n# 원핫 인코딩 한 것을 다시 묶어주는 코드\n# 평가 지표 및 실제 데이터 확인을 위해 필요\n\ny_pred_arg = np.argmax(y_pred, axis=1)\ntest_y_arg = np.argmax(test_y, axis=1)\n\n\n평가 지표\n\n\nfrom sklearn.metrics import accuracy_score, classification_report\n\n\naccuracy_score(test_y_arg, y_pred_arg)\n\n0.33564753004005343\n\n\n\nprint( classification_report(test_y_arg, y_pred_arg) )\n\n              precision    recall  f1-score   support\n\n           0       0.20      0.94      0.33       357\n           1       0.41      0.65      0.50       365\n           2       0.00      0.00      0.00       374\n           3       0.33      0.90      0.48       392\n           4       1.00      0.00      0.00       406\n           5       0.00      0.00      0.00       377\n           6       0.81      0.60      0.69       372\n           7       1.00      0.09      0.17       374\n           8       0.57      0.19      0.28       385\n           9       0.00      0.00      0.00       343\n\n    accuracy                           0.34      3745\n   macro avg       0.43      0.34      0.25      3745\nweighted avg       0.44      0.34      0.25      3745\n\n\n\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))"
  },
  {
    "objectID": "posts/image/2021-02-02-04. ImageAugmentation2.html#visualization",
    "href": "posts/image/2021-02-02-04. ImageAugmentation2.html#visualization",
    "title": "03. image DA (2)",
    "section": "",
    "text": "실제 데이터 확인\n\n\nletters_str = \"ABCDEFGHIJ\"\n\nrand_idx = np.random.randint(0, len(y_pred_arg))\ntest_idx = test_y_arg[rand_idx]\npred_idx = y_pred_arg[rand_idx]\nclass_prob = np.floor( y_pred[rand_idx]*100 )\n\nprint(f'idx = {rand_idx}')\nprint(f'해당 인덱스의 이미지는 {letters_str[test_idx]}')\nprint(f'모델의 예측 : {letters_str[pred_idx]}')\nprint(f'모델의 클래스별 확률 : ')\nprint('-------------------')\nfor idx, val in enumerate(letters_str) :\n    print(val, class_prob[idx])\nprint('=================================================')\n\nif test_y_arg[rand_idx] == y_pred_arg[rand_idx] :\n    print('정답')\nelse :\n    print('땡')\n\nplt.imshow(test_x[rand_idx], cmap='Greys')\nplt.show()\n\nidx = 1312\n해당 인덱스의 이미지는 E\n모델의 예측 : B\n모델의 클래스별 확률 : \n-------------------\nA 5.0\nB 40.0\nC 0.0\nD 1.0\nE 16.0\nF 0.0\nG 14.0\nH 0.0\nI 21.0\nJ 0.0\n=================================================\n땡\n\n\n\n\n\n\n틀린 이미지만 확인해보기\n\n\ntemp = (test_y_arg == y_pred_arg)\nfalse_idx = np.where(temp==False)[0]\nfalse_len = len(false_idx)\nfalse_len\n\n2488\n\n\n\nletters_str = \"ABCDEFGHIJ\"\n\nrand_idx = false_idx[np.random.randint(0, false_len)]\ntest_idx = test_y_arg[rand_idx]\npred_idx = y_pred_arg[rand_idx]\nclass_prob = np.floor( y_pred[rand_idx]*100 )\n\nprint(f'idx = {rand_idx}')\nprint(f'해당 인덱스의 이미지는 {letters_str[test_idx]}')\nprint(f'모델의 예측 : {letters_str[pred_idx]}')\nprint(f'모델의 클래스별 확률 : ')\nprint('-------------------')\nfor idx, val in enumerate(letters_str) :\n    print(val, class_prob[idx])\nprint('=================================================')\n\nif test_y_arg[rand_idx] == y_pred_arg[rand_idx] :\n    print('정답')\nelse :\n    print('땡')\n\nplt.imshow(test_x[rand_idx], cmap='Greys')\nplt.show()\n\nidx = 2086\n해당 인덱스의 이미지는 J\n모델의 예측 : D\n모델의 클래스별 확률 : \n-------------------\nA 11.0\nB 0.0\nC 0.0\nD 75.0\nE 0.0\nF 0.0\nG 9.0\nH 0.0\nI 2.0\nJ 0.0\n=================================================\n땡"
  },
  {
    "objectID": "posts/image/2021-02-05-06. DeepLearningwithMNIST.html",
    "href": "posts/image/2021-02-05-06. DeepLearningwithMNIST.html",
    "title": "05. MNIST",
    "section": "",
    "text": "import tensorflow as tf\nfrom tensorflow import keras\n\n\nfrom tensorflow.keras.datasets import fashion_mnist\n\n\n(train_x, train_y), (test_x, test_y) = fashion_mnist.load_data()\n\nDownloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n29515/29515 [==============================] - 0s 0us/step\nDownloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n26421880/26421880 [==============================] - 0s 0us/step\nDownloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n5148/5148 [==============================] - 0s 0us/step\nDownloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n4422102/4422102 [==============================] - 0s 0us/step\n\n\n\ntrain_x.shape, train_y.shape, test_x.shape, test_y.shape\n\n((60000, 28, 28), (60000,), (10000, 28, 28), (10000,))\n\n\n\nlabels = ['T-shirt',\n          'Trouser',\n          'Pullover',\n          'Dress',\n          'Coat',\n          'Sandal',\n          'Shirt',\n          'Sneaker',\n          'Bag',\n          'Ankle boot'\n          ]\n\nprint(labels)\n\n['T-shirt', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n\nidx = np.random.randint(0, 60000)\n\nprint(f'idx = {idx}')\nprint(f'다음 이미지는 {labels[train_y[idx]]}')\n\nplt.imshow(train_x[idx], cmap='Greys')\nplt.show()\n\nidx = 8042\n다음 이미지는 Dress\n\n\n\n\n\n\n\n\nX : Min-Max Scaling\n\n\n## MinMaxScaler 금지!\n\n\nmax_n, min_n = train_x.max(), train_x.min()\nmax_n, min_n\n\n(255, 0)\n\n\n\ntrain_x = (train_x - min_n) / (max_n - min_n)\ntest_x = (test_x - min_n) / (max_n - min_n)\n\n\ntrain_x.max(), train_x.min()\n\n(1.0, 0.0)\n\n\n\nX : Data Reshape (흑백 채널 추가)\n\n\ntrain_x.shape\n\n(60000, 28, 28)\n\n\n\ntrain_x_re = train_x.reshape(train_x.shape[0], 28, 28, -1)\ntest_x_re = test_x.reshape(test_x.shape[0], 28, 28, -1)\n\n\ntrain_x_re.shape\n\n(60000, 28, 28, 1)\n\n\n\n# np.expand_dims(train_x, axis=3)\n\n\nY : One-hot Encoding\n\n\nfrom tensorflow.keras.utils import to_categorical\n\n\ntrain_y.shape\n\n(60000,)\n\n\n\nclass_n = len(np.unique(train_y))\n\n\ntrain_y_hot = to_categorical(train_y, class_n)\ntest_y_hot = to_categorical(test_y, class_n)\n\n\ntrain_y_hot.shape\n\n(60000, 10)\n\n\n\ntrain_x_re.shape, train_y_hot.shape\n\n((60000, 28, 28, 1), (60000, 10))\n\n\n\n\n\n\nSequential API : 레이어를 순차적으로 차곡차곡!\nFunctional API : 레이어를 사슬처럼 엮기!\n\n\nimport tensorflow as tf\nfrom tensorflow import keras\n\nfrom tensorflow.keras.backend import clear_session\nfrom tensorflow.keras.models import Sequential, Model\nfrom tensorflow.keras.layers import Input, Dense, Flatten, BatchNormalization, Dropout\n\n\n## Sequential API\n# 1. 세션 클리어 : 메모리에 기존의 모델 구조가 남아있다면 지워줘!\nclear_session()\n\n# 2. 모델 발판 선언 : 레이어 블록을 차곡차곡 쌓을 발판!\nmodel1 = Sequential()\n\n# 3. 레이어 조립 : 순차적으로 쌓음!\nmodel1.add( Input(shape=(28,28,1)) )\nmodel1.add( Flatten() )\nmodel1.add( Dense(1024, activation='relu') )\nmodel1.add( Dense(1024, activation='relu') )\nmodel1.add( BatchNormalization() )\nmodel1.add( Dropout(0.25) )\nmodel1.add( Dense(512, activation='relu') )\nmodel1.add( Dense(512, activation='relu') )\nmodel1.add( BatchNormalization() )\nmodel1.add( Dropout(0.25) )\nmodel1.add( Dense(256, activation='relu') )\nmodel1.add( Dense(128, activation='relu') )\nmodel1.add( BatchNormalization() )\nmodel1.add( Dropout(0.25) )\nmodel1.add( Dense(10, activation='softmax') )\n\n# 4. 컴파일\nmodel1.compile(optimizer='adam',\n               loss=keras.losses.categorical_crossentropy,\n               metrics=['accuracy']\n               )\n\n\nmodel1.summary()\n\nModel: \"sequential\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n flatten (Flatten)           (None, 784)               0         \n                                                                 \n dense (Dense)               (None, 1024)              803840    \n                                                                 \n dense_1 (Dense)             (None, 1024)              1049600   \n                                                                 \n batch_normalization (Batch  (None, 1024)              4096      \n Normalization)                                                  \n                                                                 \n dropout (Dropout)           (None, 1024)              0         \n                                                                 \n dense_2 (Dense)             (None, 512)               524800    \n                                                                 \n dense_3 (Dense)             (None, 512)               262656    \n                                                                 \n batch_normalization_1 (Bat  (None, 512)               2048      \n chNormalization)                                                \n                                                                 \n dropout_1 (Dropout)         (None, 512)               0         \n                                                                 \n dense_4 (Dense)             (None, 256)               131328    \n                                                                 \n dense_5 (Dense)             (None, 128)               32896     \n                                                                 \n batch_normalization_2 (Bat  (None, 128)               512       \n chNormalization)                                                \n                                                                 \n dropout_2 (Dropout)         (None, 128)               0         \n                                                                 \n dense_6 (Dense)             (None, 10)                1290      \n                                                                 \n=================================================================\nTotal params: 2813066 (10.73 MB)\nTrainable params: 2809738 (10.72 MB)\nNon-trainable params: 3328 (13.00 KB)\n_________________________________________________________________\n\n\n\n## Functional API\n# 1. 세션 클리어 : 청소\nclear_session()\n\n# 2. 레이어를 사슬처럼 엮기\nil = Input(shape=(28,28,1))\nhl = Flatten()(il)\n\nhl = Dense(1024, activation='relu')(hl)\nhl = Dense(1024, activation='relu')(hl)\nhl = BatchNormalization()(hl)\nhl = Dropout(0.25)(hl)\n\nhl = Dense(512, activation='relu')(hl)\nhl = Dense(512, activation='relu')(hl)\nhl = BatchNormalization()(hl)\nhl = Dropout(0.25)(hl)\n\nhl = Dense(256, activation='relu')(hl)\nhl = Dense(128, activation='relu')(hl)\nhl = BatchNormalization()(hl)\nhl = Dropout(0.25)(hl)\n\nol = Dense(10, activation='softmax')(hl)\n\n# 3. 모델의 시작과 끝 지정/알려줌\nmodel2 = Model(il, ol)\n\n# 4. 컴파일\nmodel2.compile(optimizer='adam',\n               loss=keras.losses.categorical_crossentropy,\n               metrics=['accuracy']\n               )\n\n\nmodel2.summary()\n\nModel: \"model\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n input_1 (InputLayer)        [(None, 28, 28, 1)]       0         \n                                                                 \n flatten (Flatten)           (None, 784)               0         \n                                                                 \n dense (Dense)               (None, 1024)              803840    \n                                                                 \n dense_1 (Dense)             (None, 1024)              1049600   \n                                                                 \n batch_normalization (Batch  (None, 1024)              4096      \n Normalization)                                                  \n                                                                 \n dropout (Dropout)           (None, 1024)              0         \n                                                                 \n dense_2 (Dense)             (None, 512)               524800    \n                                                                 \n dense_3 (Dense)             (None, 512)               262656    \n                                                                 \n batch_normalization_1 (Bat  (None, 512)               2048      \n chNormalization)                                                \n                                                                 \n dropout_1 (Dropout)         (None, 512)               0         \n                                                                 \n dense_4 (Dense)             (None, 256)               131328    \n                                                                 \n dense_5 (Dense)             (None, 128)               32896     \n                                                                 \n batch_normalization_2 (Bat  (None, 128)               512       \n chNormalization)                                                \n                                                                 \n dropout_2 (Dropout)         (None, 128)               0         \n                                                                 \n dense_6 (Dense)             (None, 10)                1290      \n                                                                 \n=================================================================\nTotal params: 2813066 (10.73 MB)\nTrainable params: 2809738 (10.72 MB)\nNon-trainable params: 3328 (13.00 KB)\n_________________________________________________________________\n\n\n\n\n\n과적합 방지!\n\n\nfrom tensorflow.keras.callbacks import EarlyStopping\n\n\nes = EarlyStopping(monitor='val_loss',        # 얼리스토핑을 적용할 관측 대상!\n                   min_delta=0,               # 설정한 값 이상으로 변화해야 성능 개선으로 간주! Threshold!\n                   patience=3,                # 성능 개선이 발생하지 않을 때, 몇 에포크 더 지켜볼 것인지!\n                   verbose=1,\n                   restore_best_weights=True  # 얼리스토핑 적용 후, 최적의 가중치를 모델에 전달!\n                   )\n\n\nmodel1.fit(train_x_re, train_y_hot, epochs=10000, verbose=1,\n           validation_split=0.2,  # 매 epoch마다 랜덤하게 20%를 validation set화 함!\n           callbacks=[es]         # 얼리스토핑을 수행하기 위한!\n           )\n\nEpoch 1/10000\n1500/1500 [==============================] - 18s 6ms/step - loss: 0.6154 - accuracy: 0.7851 - val_loss: 0.4515 - val_accuracy: 0.8411\nEpoch 2/10000\n1500/1500 [==============================] - 9s 6ms/step - loss: 0.4572 - accuracy: 0.8391 - val_loss: 0.4001 - val_accuracy: 0.8579\nEpoch 3/10000\n1500/1500 [==============================] - 9s 6ms/step - loss: 0.4071 - accuracy: 0.8533 - val_loss: 0.4077 - val_accuracy: 0.8608\nEpoch 4/10000\n1500/1500 [==============================] - 9s 6ms/step - loss: 0.3741 - accuracy: 0.8663 - val_loss: 0.3727 - val_accuracy: 0.8623\nEpoch 5/10000\n1500/1500 [==============================] - 9s 6ms/step - loss: 0.3504 - accuracy: 0.8731 - val_loss: 0.3894 - val_accuracy: 0.8633\nEpoch 6/10000\n1500/1500 [==============================] - 9s 6ms/step - loss: 0.3348 - accuracy: 0.8796 - val_loss: 0.3518 - val_accuracy: 0.8801\nEpoch 7/10000\n1500/1500 [==============================] - 9s 6ms/step - loss: 0.3171 - accuracy: 0.8851 - val_loss: 0.3653 - val_accuracy: 0.8746\nEpoch 8/10000\n1500/1500 [==============================] - 8s 6ms/step - loss: 0.3042 - accuracy: 0.8918 - val_loss: 0.3222 - val_accuracy: 0.8810\nEpoch 9/10000\n1500/1500 [==============================] - 9s 6ms/step - loss: 0.2883 - accuracy: 0.8956 - val_loss: 0.3259 - val_accuracy: 0.8851\nEpoch 10/10000\n1500/1500 [==============================] - 9s 6ms/step - loss: 0.2768 - accuracy: 0.9002 - val_loss: 0.3664 - val_accuracy: 0.8731\nEpoch 11/10000\n1495/1500 [============================&gt;.] - ETA: 0s - loss: 0.2700 - accuracy: 0.9005Restoring model weights from the end of the best epoch: 8.\n1500/1500 [==============================] - 10s 6ms/step - loss: 0.2699 - accuracy: 0.9006 - val_loss: 0.3233 - val_accuracy: 0.8848\nEpoch 11: early stopping\n\n\n&lt;keras.src.callbacks.History at 0x7e4182652740&gt;\n\n\n\n모델 성능 평가\n\n\nmodel1.evaluate(test_x_re, test_y_hot)\n\n313/313 [==============================] - 1s 3ms/step - loss: 0.3533 - accuracy: 0.8698\n\n\n[0.35334810614585876, 0.8697999715805054]\n\n\n\n예측값 생성\n\n\ny_pred = model1.predict(test_x_re)\n\n313/313 [==============================] - 1s 2ms/step\n\n\n\ny_pred\n\narray([[9.4809511e-06, 8.8048737e-06, 8.0290629e-06, ..., 2.8839773e-03,\n        5.8179953e-06, 9.9661839e-01],\n       [3.5026006e-04, 5.1599517e-07, 9.6235543e-01, ..., 1.8944108e-06,\n        7.8653347e-06, 1.1505227e-06],\n       [1.1024580e-06, 9.9998915e-01, 1.7111474e-06, ..., 3.0977384e-07,\n        1.2295349e-06, 1.2656298e-07],\n       ...,\n       [1.5850060e-03, 2.6797961e-06, 1.4185406e-04, ..., 2.2506862e-05,\n        9.9727172e-01, 3.9122397e-06],\n       [3.2278253e-06, 9.9987662e-01, 3.0650394e-06, ..., 2.9644505e-07,\n        1.0506158e-05, 6.6061748e-06],\n       [4.4416233e-06, 1.6793224e-06, 6.1789865e-06, ..., 1.8420644e-02,\n        1.8467043e-05, 8.0895763e-05]], dtype=float32)\n\n\n\ny_pred.shape\n\n(10000, 10)\n\n\n\ny_pred[0]\n\narray([9.4809511e-06, 8.8048737e-06, 8.0290629e-06, 1.2099741e-05,\n       4.9804830e-06, 4.3006203e-04, 1.8331393e-05, 2.8839773e-03,\n       5.8179953e-06, 9.9661839e-01], dtype=float32)\n\n\n\ny_pred_arg = np.argmax(y_pred, axis=1)\n\n\ny_pred_arg.shape\n\n(10000,)\n\n\n\ny_pred_arg[0]\n\n9\n\n\n\n성능 지표\n\n\nfrom sklearn.metrics import classification_report\n\n\nprint(classification_report(test_y, y_pred_arg, target_names=labels))\n\n              precision    recall  f1-score   support\n\n     T-shirt       0.81      0.86      0.83      1000\n     Trouser       0.99      0.97      0.98      1000\n    Pullover       0.84      0.65      0.73      1000\n       Dress       0.89      0.87      0.88      1000\n        Coat       0.72      0.88      0.79      1000\n      Sandal       0.99      0.93      0.96      1000\n       Shirt       0.66      0.65      0.65      1000\n     Sneaker       0.93      0.95      0.94      1000\n         Bag       0.97      0.97      0.97      1000\n  Ankle boot       0.94      0.96      0.95      1000\n\n    accuracy                           0.87     10000\n   macro avg       0.87      0.87      0.87     10000\nweighted avg       0.87      0.87      0.87     10000\n\n\n\n\n\n\n\n\nid = np.random.randint(0, 10000)\n\nprint(f'idx = {id}')\nprint(f'실제 그림 = {labels[test_y[id]]}')\nprint(f'모델 예측 = {labels[y_pred_arg[id]]}')\n\nprob = np.floor(y_pred[0]*100).tolist()\nprob_dict = {}\n\nfor idx, prob in enumerate(prob) :\n    prob_dict[ labels[idx] ] = prob\n\nprint(f'모델의 클래스별 확률')\nprint(prob_dict)\n\nif y_pred_arg[id] == test_y[id] :\n    print('정답!')\nelse :\n    print('땡!!!')\n\nplt.imshow(test_x_re[id].reshape([28, 28]), cmap='Greys')\nplt.show()\n\nidx = 5587\n실제 그림 = Pullover\n모델 예측 = Coat\n모델의 클래스별 확률\n{'T-shirt': 0.0, 'Trouser': 0.0, 'Pullover': 0.0, 'Dress': 0.0, 'Coat': 0.0, 'Sandal': 0.0, 'Shirt': 0.0, 'Sneaker': 0.0, 'Bag': 0.0, 'Ankle boot': 99.0}\n땡!!!\n\n\n\n\n\n\n틀린 것만 살펴봅시다.\n\n틀릴만한 이미지가 맞는지?!\n\n\n\ntrue_false = (test_y==y_pred_arg)\nf_id = np.where(true_false==False)[0]\nf_n = len(f_id)\n\nid = f_id[np.random.randint(0, f_n)]\n\nprint(f'idx = {id}')\nprint(f'실제 그림 = {labels[test_y[id]]}')\nprint(f'모델 예측 = {labels[y_pred_arg[id]]}')\n\nprob = np.floor(y_pred[0]*100).tolist()\nprob_dict = {}\n\nfor idx, prob in enumerate(prob) :\n    prob_dict[ labels[idx] ] = prob\n\nprint(f'모델의 클래스별 확률')\nprint(prob_dict)\n\nif y_pred_arg[id] == test_y[id] :\n    print('정답!')\nelse :\n    print('땡!!!')\n\nplt.imshow(test_x_re[id].reshape([28, 28]), cmap='Greys')\nplt.show()\n\nidx = 8997\n실제 그림 = Shirt\n모델 예측 = T-shirt\n모델의 클래스별 확률\n{'T-shirt': 0.0, 'Trouser': 0.0, 'Pullover': 0.0, 'Dress': 0.0, 'Coat': 0.0, 'Sandal': 0.0, 'Shirt': 0.0, 'Sneaker': 0.0, 'Bag': 0.0, 'Ankle boot': 99.0}\n땡!!!"
  },
  {
    "objectID": "posts/image/2021-02-05-06. DeepLearningwithMNIST.html#preprocessing",
    "href": "posts/image/2021-02-05-06. DeepLearningwithMNIST.html#preprocessing",
    "title": "05. MNIST",
    "section": "",
    "text": "X : Min-Max Scaling\n\n\n## MinMaxScaler 금지!\n\n\nmax_n, min_n = train_x.max(), train_x.min()\nmax_n, min_n\n\n(255, 0)\n\n\n\ntrain_x = (train_x - min_n) / (max_n - min_n)\ntest_x = (test_x - min_n) / (max_n - min_n)\n\n\ntrain_x.max(), train_x.min()\n\n(1.0, 0.0)\n\n\n\nX : Data Reshape (흑백 채널 추가)\n\n\ntrain_x.shape\n\n(60000, 28, 28)\n\n\n\ntrain_x_re = train_x.reshape(train_x.shape[0], 28, 28, -1)\ntest_x_re = test_x.reshape(test_x.shape[0], 28, 28, -1)\n\n\ntrain_x_re.shape\n\n(60000, 28, 28, 1)\n\n\n\n# np.expand_dims(train_x, axis=3)\n\n\nY : One-hot Encoding\n\n\nfrom tensorflow.keras.utils import to_categorical\n\n\ntrain_y.shape\n\n(60000,)\n\n\n\nclass_n = len(np.unique(train_y))\n\n\ntrain_y_hot = to_categorical(train_y, class_n)\ntest_y_hot = to_categorical(test_y, class_n)\n\n\ntrain_y_hot.shape\n\n(60000, 10)\n\n\n\ntrain_x_re.shape, train_y_hot.shape\n\n((60000, 28, 28, 1), (60000, 10))"
  },
  {
    "objectID": "posts/image/2021-02-05-06. DeepLearningwithMNIST.html#modeling",
    "href": "posts/image/2021-02-05-06. DeepLearningwithMNIST.html#modeling",
    "title": "05. MNIST",
    "section": "",
    "text": "Sequential API : 레이어를 순차적으로 차곡차곡!\nFunctional API : 레이어를 사슬처럼 엮기!\n\n\nimport tensorflow as tf\nfrom tensorflow import keras\n\nfrom tensorflow.keras.backend import clear_session\nfrom tensorflow.keras.models import Sequential, Model\nfrom tensorflow.keras.layers import Input, Dense, Flatten, BatchNormalization, Dropout\n\n\n## Sequential API\n# 1. 세션 클리어 : 메모리에 기존의 모델 구조가 남아있다면 지워줘!\nclear_session()\n\n# 2. 모델 발판 선언 : 레이어 블록을 차곡차곡 쌓을 발판!\nmodel1 = Sequential()\n\n# 3. 레이어 조립 : 순차적으로 쌓음!\nmodel1.add( Input(shape=(28,28,1)) )\nmodel1.add( Flatten() )\nmodel1.add( Dense(1024, activation='relu') )\nmodel1.add( Dense(1024, activation='relu') )\nmodel1.add( BatchNormalization() )\nmodel1.add( Dropout(0.25) )\nmodel1.add( Dense(512, activation='relu') )\nmodel1.add( Dense(512, activation='relu') )\nmodel1.add( BatchNormalization() )\nmodel1.add( Dropout(0.25) )\nmodel1.add( Dense(256, activation='relu') )\nmodel1.add( Dense(128, activation='relu') )\nmodel1.add( BatchNormalization() )\nmodel1.add( Dropout(0.25) )\nmodel1.add( Dense(10, activation='softmax') )\n\n# 4. 컴파일\nmodel1.compile(optimizer='adam',\n               loss=keras.losses.categorical_crossentropy,\n               metrics=['accuracy']\n               )\n\n\nmodel1.summary()\n\nModel: \"sequential\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n flatten (Flatten)           (None, 784)               0         \n                                                                 \n dense (Dense)               (None, 1024)              803840    \n                                                                 \n dense_1 (Dense)             (None, 1024)              1049600   \n                                                                 \n batch_normalization (Batch  (None, 1024)              4096      \n Normalization)                                                  \n                                                                 \n dropout (Dropout)           (None, 1024)              0         \n                                                                 \n dense_2 (Dense)             (None, 512)               524800    \n                                                                 \n dense_3 (Dense)             (None, 512)               262656    \n                                                                 \n batch_normalization_1 (Bat  (None, 512)               2048      \n chNormalization)                                                \n                                                                 \n dropout_1 (Dropout)         (None, 512)               0         \n                                                                 \n dense_4 (Dense)             (None, 256)               131328    \n                                                                 \n dense_5 (Dense)             (None, 128)               32896     \n                                                                 \n batch_normalization_2 (Bat  (None, 128)               512       \n chNormalization)                                                \n                                                                 \n dropout_2 (Dropout)         (None, 128)               0         \n                                                                 \n dense_6 (Dense)             (None, 10)                1290      \n                                                                 \n=================================================================\nTotal params: 2813066 (10.73 MB)\nTrainable params: 2809738 (10.72 MB)\nNon-trainable params: 3328 (13.00 KB)\n_________________________________________________________________\n\n\n\n## Functional API\n# 1. 세션 클리어 : 청소\nclear_session()\n\n# 2. 레이어를 사슬처럼 엮기\nil = Input(shape=(28,28,1))\nhl = Flatten()(il)\n\nhl = Dense(1024, activation='relu')(hl)\nhl = Dense(1024, activation='relu')(hl)\nhl = BatchNormalization()(hl)\nhl = Dropout(0.25)(hl)\n\nhl = Dense(512, activation='relu')(hl)\nhl = Dense(512, activation='relu')(hl)\nhl = BatchNormalization()(hl)\nhl = Dropout(0.25)(hl)\n\nhl = Dense(256, activation='relu')(hl)\nhl = Dense(128, activation='relu')(hl)\nhl = BatchNormalization()(hl)\nhl = Dropout(0.25)(hl)\n\nol = Dense(10, activation='softmax')(hl)\n\n# 3. 모델의 시작과 끝 지정/알려줌\nmodel2 = Model(il, ol)\n\n# 4. 컴파일\nmodel2.compile(optimizer='adam',\n               loss=keras.losses.categorical_crossentropy,\n               metrics=['accuracy']\n               )\n\n\nmodel2.summary()\n\nModel: \"model\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n input_1 (InputLayer)        [(None, 28, 28, 1)]       0         \n                                                                 \n flatten (Flatten)           (None, 784)               0         \n                                                                 \n dense (Dense)               (None, 1024)              803840    \n                                                                 \n dense_1 (Dense)             (None, 1024)              1049600   \n                                                                 \n batch_normalization (Batch  (None, 1024)              4096      \n Normalization)                                                  \n                                                                 \n dropout (Dropout)           (None, 1024)              0         \n                                                                 \n dense_2 (Dense)             (None, 512)               524800    \n                                                                 \n dense_3 (Dense)             (None, 512)               262656    \n                                                                 \n batch_normalization_1 (Bat  (None, 512)               2048      \n chNormalization)                                                \n                                                                 \n dropout_1 (Dropout)         (None, 512)               0         \n                                                                 \n dense_4 (Dense)             (None, 256)               131328    \n                                                                 \n dense_5 (Dense)             (None, 128)               32896     \n                                                                 \n batch_normalization_2 (Bat  (None, 128)               512       \n chNormalization)                                                \n                                                                 \n dropout_2 (Dropout)         (None, 128)               0         \n                                                                 \n dense_6 (Dense)             (None, 10)                1290      \n                                                                 \n=================================================================\nTotal params: 2813066 (10.73 MB)\nTrainable params: 2809738 (10.72 MB)\nNon-trainable params: 3328 (13.00 KB)\n_________________________________________________________________\n\n\n\n\n\n과적합 방지!\n\n\nfrom tensorflow.keras.callbacks import EarlyStopping\n\n\nes = EarlyStopping(monitor='val_loss',        # 얼리스토핑을 적용할 관측 대상!\n                   min_delta=0,               # 설정한 값 이상으로 변화해야 성능 개선으로 간주! Threshold!\n                   patience=3,                # 성능 개선이 발생하지 않을 때, 몇 에포크 더 지켜볼 것인지!\n                   verbose=1,\n                   restore_best_weights=True  # 얼리스토핑 적용 후, 최적의 가중치를 모델에 전달!\n                   )\n\n\nmodel1.fit(train_x_re, train_y_hot, epochs=10000, verbose=1,\n           validation_split=0.2,  # 매 epoch마다 랜덤하게 20%를 validation set화 함!\n           callbacks=[es]         # 얼리스토핑을 수행하기 위한!\n           )\n\nEpoch 1/10000\n1500/1500 [==============================] - 18s 6ms/step - loss: 0.6154 - accuracy: 0.7851 - val_loss: 0.4515 - val_accuracy: 0.8411\nEpoch 2/10000\n1500/1500 [==============================] - 9s 6ms/step - loss: 0.4572 - accuracy: 0.8391 - val_loss: 0.4001 - val_accuracy: 0.8579\nEpoch 3/10000\n1500/1500 [==============================] - 9s 6ms/step - loss: 0.4071 - accuracy: 0.8533 - val_loss: 0.4077 - val_accuracy: 0.8608\nEpoch 4/10000\n1500/1500 [==============================] - 9s 6ms/step - loss: 0.3741 - accuracy: 0.8663 - val_loss: 0.3727 - val_accuracy: 0.8623\nEpoch 5/10000\n1500/1500 [==============================] - 9s 6ms/step - loss: 0.3504 - accuracy: 0.8731 - val_loss: 0.3894 - val_accuracy: 0.8633\nEpoch 6/10000\n1500/1500 [==============================] - 9s 6ms/step - loss: 0.3348 - accuracy: 0.8796 - val_loss: 0.3518 - val_accuracy: 0.8801\nEpoch 7/10000\n1500/1500 [==============================] - 9s 6ms/step - loss: 0.3171 - accuracy: 0.8851 - val_loss: 0.3653 - val_accuracy: 0.8746\nEpoch 8/10000\n1500/1500 [==============================] - 8s 6ms/step - loss: 0.3042 - accuracy: 0.8918 - val_loss: 0.3222 - val_accuracy: 0.8810\nEpoch 9/10000\n1500/1500 [==============================] - 9s 6ms/step - loss: 0.2883 - accuracy: 0.8956 - val_loss: 0.3259 - val_accuracy: 0.8851\nEpoch 10/10000\n1500/1500 [==============================] - 9s 6ms/step - loss: 0.2768 - accuracy: 0.9002 - val_loss: 0.3664 - val_accuracy: 0.8731\nEpoch 11/10000\n1495/1500 [============================&gt;.] - ETA: 0s - loss: 0.2700 - accuracy: 0.9005Restoring model weights from the end of the best epoch: 8.\n1500/1500 [==============================] - 10s 6ms/step - loss: 0.2699 - accuracy: 0.9006 - val_loss: 0.3233 - val_accuracy: 0.8848\nEpoch 11: early stopping\n\n\n&lt;keras.src.callbacks.History at 0x7e4182652740&gt;\n\n\n\n모델 성능 평가\n\n\nmodel1.evaluate(test_x_re, test_y_hot)\n\n313/313 [==============================] - 1s 3ms/step - loss: 0.3533 - accuracy: 0.8698\n\n\n[0.35334810614585876, 0.8697999715805054]\n\n\n\n예측값 생성\n\n\ny_pred = model1.predict(test_x_re)\n\n313/313 [==============================] - 1s 2ms/step\n\n\n\ny_pred\n\narray([[9.4809511e-06, 8.8048737e-06, 8.0290629e-06, ..., 2.8839773e-03,\n        5.8179953e-06, 9.9661839e-01],\n       [3.5026006e-04, 5.1599517e-07, 9.6235543e-01, ..., 1.8944108e-06,\n        7.8653347e-06, 1.1505227e-06],\n       [1.1024580e-06, 9.9998915e-01, 1.7111474e-06, ..., 3.0977384e-07,\n        1.2295349e-06, 1.2656298e-07],\n       ...,\n       [1.5850060e-03, 2.6797961e-06, 1.4185406e-04, ..., 2.2506862e-05,\n        9.9727172e-01, 3.9122397e-06],\n       [3.2278253e-06, 9.9987662e-01, 3.0650394e-06, ..., 2.9644505e-07,\n        1.0506158e-05, 6.6061748e-06],\n       [4.4416233e-06, 1.6793224e-06, 6.1789865e-06, ..., 1.8420644e-02,\n        1.8467043e-05, 8.0895763e-05]], dtype=float32)\n\n\n\ny_pred.shape\n\n(10000, 10)\n\n\n\ny_pred[0]\n\narray([9.4809511e-06, 8.8048737e-06, 8.0290629e-06, 1.2099741e-05,\n       4.9804830e-06, 4.3006203e-04, 1.8331393e-05, 2.8839773e-03,\n       5.8179953e-06, 9.9661839e-01], dtype=float32)\n\n\n\ny_pred_arg = np.argmax(y_pred, axis=1)\n\n\ny_pred_arg.shape\n\n(10000,)\n\n\n\ny_pred_arg[0]\n\n9\n\n\n\n성능 지표\n\n\nfrom sklearn.metrics import classification_report\n\n\nprint(classification_report(test_y, y_pred_arg, target_names=labels))\n\n              precision    recall  f1-score   support\n\n     T-shirt       0.81      0.86      0.83      1000\n     Trouser       0.99      0.97      0.98      1000\n    Pullover       0.84      0.65      0.73      1000\n       Dress       0.89      0.87      0.88      1000\n        Coat       0.72      0.88      0.79      1000\n      Sandal       0.99      0.93      0.96      1000\n       Shirt       0.66      0.65      0.65      1000\n     Sneaker       0.93      0.95      0.94      1000\n         Bag       0.97      0.97      0.97      1000\n  Ankle boot       0.94      0.96      0.95      1000\n\n    accuracy                           0.87     10000\n   macro avg       0.87      0.87      0.87     10000\nweighted avg       0.87      0.87      0.87     10000"
  },
  {
    "objectID": "posts/image/2021-02-05-06. DeepLearningwithMNIST.html#visualization",
    "href": "posts/image/2021-02-05-06. DeepLearningwithMNIST.html#visualization",
    "title": "05. MNIST",
    "section": "",
    "text": "id = np.random.randint(0, 10000)\n\nprint(f'idx = {id}')\nprint(f'실제 그림 = {labels[test_y[id]]}')\nprint(f'모델 예측 = {labels[y_pred_arg[id]]}')\n\nprob = np.floor(y_pred[0]*100).tolist()\nprob_dict = {}\n\nfor idx, prob in enumerate(prob) :\n    prob_dict[ labels[idx] ] = prob\n\nprint(f'모델의 클래스별 확률')\nprint(prob_dict)\n\nif y_pred_arg[id] == test_y[id] :\n    print('정답!')\nelse :\n    print('땡!!!')\n\nplt.imshow(test_x_re[id].reshape([28, 28]), cmap='Greys')\nplt.show()\n\nidx = 5587\n실제 그림 = Pullover\n모델 예측 = Coat\n모델의 클래스별 확률\n{'T-shirt': 0.0, 'Trouser': 0.0, 'Pullover': 0.0, 'Dress': 0.0, 'Coat': 0.0, 'Sandal': 0.0, 'Shirt': 0.0, 'Sneaker': 0.0, 'Bag': 0.0, 'Ankle boot': 99.0}\n땡!!!\n\n\n\n\n\n\n틀린 것만 살펴봅시다.\n\n틀릴만한 이미지가 맞는지?!\n\n\n\ntrue_false = (test_y==y_pred_arg)\nf_id = np.where(true_false==False)[0]\nf_n = len(f_id)\n\nid = f_id[np.random.randint(0, f_n)]\n\nprint(f'idx = {id}')\nprint(f'실제 그림 = {labels[test_y[id]]}')\nprint(f'모델 예측 = {labels[y_pred_arg[id]]}')\n\nprob = np.floor(y_pred[0]*100).tolist()\nprob_dict = {}\n\nfor idx, prob in enumerate(prob) :\n    prob_dict[ labels[idx] ] = prob\n\nprint(f'모델의 클래스별 확률')\nprint(prob_dict)\n\nif y_pred_arg[id] == test_y[id] :\n    print('정답!')\nelse :\n    print('땡!!!')\n\nplt.imshow(test_x_re[id].reshape([28, 28]), cmap='Greys')\nplt.show()\n\nidx = 8997\n실제 그림 = Shirt\n모델 예측 = T-shirt\n모델의 클래스별 확률\n{'T-shirt': 0.0, 'Trouser': 0.0, 'Pullover': 0.0, 'Dress': 0.0, 'Coat': 0.0, 'Sandal': 0.0, 'Shirt': 0.0, 'Sneaker': 0.0, 'Bag': 0.0, 'Ankle boot': 99.0}\n땡!!!"
  },
  {
    "objectID": "posts/image/2021-02-08-08. PretrainedModel_and_Tuning.html",
    "href": "posts/image/2021-02-08-08. PretrainedModel_and_Tuning.html",
    "title": "07. pretrained Model (2)",
    "section": "",
    "text": "모델 종류 참고 링크\n트랜스퍼 러닝이란\n\n\n\n\nimport tensorflow as tf\nfrom tensorflow import keras\n\nfrom tensorflow.keras.applications.inception_v3 import InceptionV3\nfrom tensorflow.keras.applications.inception_v3 import preprocess_input\nfrom tensorflow.keras.applications.inception_v3 import decode_predictions\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.layers import GlobalAveragePooling2D, Dense\n\nfrom sklearn.model_selection import train_test_split\n\nimport random\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport glob\n\n\n\n\n\nfrom google.colab import drive\ndrive.mount('/content/drive')\n\nMounted at /content/drive\n\n\n\n!cd /content/drive/MyDrive/my_data/; ls\n\ndatasets  img1  model.png     my_mnist   MyPjt  transfer\nhandmade  img2  my_first_save.h5  my_mnist2  temp\n\n\n\n!cd /content/drive/MyDrive/my_data/transfer; ls\n\narmstrong  bleach  opm\n\n\n\nfiles = glob.glob('/content/drive/MyDrive/my_data/transfer/*/*')\nfiles\n\n['/content/drive/MyDrive/my_data/transfer/opm/3ba41ec9dad7c14601a4bd80bbb09940.jpg',\n '/content/drive/MyDrive/my_data/transfer/opm/images.png',\n '/content/drive/MyDrive/my_data/transfer/opm/saitama-of-one-punch-man-season-2.png',\n '/content/drive/MyDrive/my_data/transfer/opm/one-punch-man-saitama-punch-canvas-art-wrap-28064182532_1024x1024.jpg',\n '/content/drive/MyDrive/my_data/transfer/opm/One-Punch-Man-trama-e-recensione-696x385.jpg',\n '/content/drive/MyDrive/my_data/transfer/opm/kisspng-one-punch-man-youtube-saitama-desktop-wallpaper-one-punch-man-5ac57d8f9cb076.9914570015228921756418.jpg',\n '/content/drive/MyDrive/my_data/transfer/opm/User_184486_Profile_Picture_20180331-093841_44ab7971-cb01-41cd-aa91-6232dceea126.jpg',\n '/content/drive/MyDrive/my_data/transfer/opm/maxresdefault.jpg',\n '/content/drive/MyDrive/my_data/transfer/opm/images.jpg',\n '/content/drive/MyDrive/my_data/transfer/opm/다운로드 (1).jpg',\n '/content/drive/MyDrive/my_data/transfer/opm/one-punch-man_1545897445533.webp',\n '/content/drive/MyDrive/my_data/transfer/opm/https___blogs-images.forbes.com_olliebarder_files_2016_09_onepunchman_second-1200x675.jpg',\n '/content/drive/MyDrive/my_data/transfer/opm/images (1).jpg',\n '/content/drive/MyDrive/my_data/transfer/opm/다운로드.jpg',\n '/content/drive/MyDrive/my_data/transfer/opm/images (2).jpg',\n '/content/drive/MyDrive/my_data/transfer/opm/maxresdefault (1).jpg',\n '/content/drive/MyDrive/my_data/transfer/opm/images (3).jpg',\n '/content/drive/MyDrive/my_data/transfer/opm/images (4).jpg',\n '/content/drive/MyDrive/my_data/transfer/opm/unnamed.png',\n '/content/drive/MyDrive/my_data/transfer/opm/다sdfsdf운로드.jpg',\n '/content/drive/MyDrive/my_data/transfer/armstrong/1019499_1336092939744_full.jpg',\n '/content/drive/MyDrive/my_data/transfer/armstrong/2hfkwf8.jpg',\n '/content/drive/MyDrive/my_data/transfer/armstrong/15. 10. 30. - 1.jpg',\n '/content/drive/MyDrive/my_data/transfer/armstrong/Alex_Louis_Armstrong_28FMA29.jpg',\n '/content/drive/MyDrive/my_data/transfer/armstrong/Bc0tX7sCEAARqk9.jpg',\n '/content/drive/MyDrive/my_data/transfer/armstrong/b0005412_49d8ba1c6c1ca.jpg',\n '/content/drive/MyDrive/my_data/transfer/armstrong/G-Mgc5su_400x400.png',\n '/content/drive/MyDrive/my_data/transfer/armstrong/다운로드 (1).jpg',\n '/content/drive/MyDrive/my_data/transfer/armstrong/다운로드.jpg',\n '/content/drive/MyDrive/my_data/transfer/armstrong/Alex_Louis_Armstrong_(2009).jpg',\n '/content/drive/MyDrive/my_data/transfer/armstrong/full-metal-alchemist-character-recreated-in-dark-souls-3-and-its-not-alphonse-social.jpg',\n '/content/drive/MyDrive/my_data/transfer/armstrong/maxresdefault (1).jpg',\n '/content/drive/MyDrive/my_data/transfer/armstrong/maxresdefault.jpg',\n '/content/drive/MyDrive/my_data/transfer/armstrong/big_1471769576_image.jpg',\n '/content/drive/MyDrive/my_data/transfer/armstrong/4892072-4384090584-fma54.jpg',\n '/content/drive/MyDrive/my_data/transfer/armstrong/unnamed (1).jpg',\n '/content/drive/MyDrive/my_data/transfer/armstrong/images.jpg',\n '/content/drive/MyDrive/my_data/transfer/armstrong/다운로드 (2).jpg',\n '/content/drive/MyDrive/my_data/transfer/armstrong/OCq90KN8_400x400.jpg',\n '/content/drive/MyDrive/my_data/transfer/bleach/4607d2e7d52c8.jpg',\n '/content/drive/MyDrive/my_data/transfer/bleach/465bceabc9368.jpg',\n '/content/drive/MyDrive/my_data/transfer/bleach/31.jpg',\n '/content/drive/MyDrive/my_data/transfer/bleach/maxresdefault.jpg',\n '/content/drive/MyDrive/my_data/transfer/bleach/4I08cmY7_400x400.jpg',\n '/content/drive/MyDrive/my_data/transfer/bleach/img.chuing.jpg',\n '/content/drive/MyDrive/my_data/transfer/bleach/c2790d5985eae82cd1199a4cba2101c114662c2a02339b9a3d1b154712fe5e8d212ac61ad47c8d04c7ea0fba559817ff.png',\n '/content/drive/MyDrive/my_data/transfer/bleach/9285513a71e117418e70c5fa86a50126.jpeg',\n '/content/drive/MyDrive/my_data/transfer/bleach/BCKT_33CUAEurqj.jpg',\n '/content/drive/MyDrive/my_data/transfer/bleach/images.jpg',\n '/content/drive/MyDrive/my_data/transfer/bleach/Ikkaku-bleach-anime-20603578-1280-720.jpg',\n '/content/drive/MyDrive/my_data/transfer/bleach/720c5ff4df799c3cb6150a13cf8e0561.jpg',\n '/content/drive/MyDrive/my_data/transfer/bleach/Ikkaku_Madarame.png',\n '/content/drive/MyDrive/my_data/transfer/bleach/maxresdefault (1).jpg',\n '/content/drive/MyDrive/my_data/transfer/bleach/maxresdefault (2).jpg',\n '/content/drive/MyDrive/my_data/transfer/bleach/maxresdefault (3).jpg',\n '/content/drive/MyDrive/my_data/transfer/bleach/다운로드.jpg',\n '/content/drive/MyDrive/my_data/transfer/bleach/340717-ikkaku_madarame.jpg',\n '/content/drive/MyDrive/my_data/transfer/bleach/b8e72a67c122b896dea8e20c9c829dd8.jpg']\n\n\n\nname_cnt = {}\n\nfor x in files :\n    name_cnt[x.split('/')[-2]] = name_cnt.get(x.split('/')[-2], 0) + 1\n\nname_cnt\n\n{'opm': 20, 'armstrong': 19, 'bleach': 19}\n\n\n\ni = 0\nnames = {}\n\nfor key in name_cnt :\n    names[key] = i     # names_cnt의 key값에 새로운 값 부여\n    i += 1             # 클래스 수만큼 i값 증가\n\nnames\n\n{'opm': 0, 'armstrong': 1, 'bleach': 2}\n\n\n\nimages = []\nlabels = []\n\nfor path in files:\n    img = image.load_img(path, target_size=(299,299) )\n    img = image.img_to_array(img)\n\n    images.append(img)\n    labels.append(names[path.split('/')[-2]])\n\n    plt.imshow(image.load_img(path))\n    plt.show()\n\nimages_arr = np.array(images)\nlabels_arr = np.array(labels)\n\nprint(images_arr.shape)\nprint(labels_arr.shape)\n\nOutput hidden; open in https://colab.research.google.com to view.\n\n\n\nprint(labels_arr)\nlabel_v = len(np.unique(labels_arr))\nlabel_v\n\n[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n\n\n3\n\n\n\n### 라벨링\ny = to_categorical(labels, label_v)\n\n\nprint(y[:3])\ny.shape\n\n[[1. 0. 0.]\n [1. 0. 0.]\n [1. 0. 0.]]\n\n\n(58, 3)\n\n\n\n\n\n\ntraining set, validation set, test set 생성\n각 이미지 그룹별로 균등한 분할을 위하여. 아래 코드가 조금 복잡합니다.\n\n\ntemp = []\ninit_v = 0\n\nfor v in name_cnt.values() :\n    temp.append( (images[init_v:init_v+v], y[init_v:init_v+v]) )\n    init_v += v\n\n\nfor i in range(len(temp)) :\n    x_to_array = np.array(temp[i][0])\n    y_to_array = np.array(temp[i][1])\n\n    train_x, test_x, train_y, test_y =\\\n        train_test_split(x_to_array, y_to_array, test_size=0.2, random_state=2023)\n\n    train_x, valid_x, train_y, valid_y =\\\n        train_test_split(train_x, train_y, test_size=0.2, random_state=2023)\n\n    if i==0 :\n        first_tr_x, first_va_x, first_te_x = train_x.copy(), valid_x.copy(), test_x.copy()\n        first_tr_y, first_va_y, first_te_y = train_y.copy(), valid_y.copy(), test_y.copy()\n\n    elif i==1 :\n        new_tr_x, new_tr_y = np.vstack((first_tr_x, train_x)), np.vstack((first_tr_y, train_y))\n        new_va_x, new_va_y = np.vstack((first_va_x, valid_x)), np.vstack((first_va_y, valid_y))\n        new_te_x, new_te_y = np.vstack((first_te_x, test_x)), np.vstack((first_te_y, test_y))\n\n    else :\n        new_tr_x, new_tr_y = np.vstack((new_tr_x, train_x)), np.vstack((new_tr_y, train_y))\n        new_va_x, new_va_y = np.vstack((new_va_x, valid_x)), np.vstack((new_va_y, valid_y))\n        new_te_x, new_te_y = np.vstack((new_te_x, test_x)), np.vstack((new_te_y, test_y))\n\n\nnew_tr_x.shape, new_tr_y.shape, new_va_x.shape, new_va_y.shape, new_te_x.shape, new_te_y.shape\n\n((36, 299, 299, 3),\n (36, 3),\n (10, 299, 299, 3),\n (10, 3),\n (12, 299, 299, 3),\n (12, 3))\n\n\n\n# 전처리 하지 않은 파일 따로 시각화 해두기\ntrain_xv, valid_xv, test_xv = train_x.copy(), valid_x.copy(), test_x.copy()\n\n\n\n\n\n잘 만들어진 모델에서 제공하는 전처리 과정을 사용합니다.\n\n\nnew_tr_x.max(), new_tr_x.min()\n\n(255.0, 0.0)\n\n\n\nnew_tr_x = preprocess_input(new_tr_x)\nnew_va_x = preprocess_input(new_va_x)\nnew_te_x = preprocess_input(new_te_x)\n\n\nnew_tr_x.max(), new_tr_x.min()\n\n(1.0, -1.0)\n\n\n\n\n\n\nkeras.backend.clear_session()\n\nbase_model = InceptionV3(weights='imagenet',       # ImageNet 데이터를 기반으로 미리 학습된 가중치 불러오기\n                         include_top=False,        # InceptionV3 모델의 아웃풋 레이어는 제외하고 불러오기\n                         input_shape= (299,299,3)) # 입력 데이터의 형태\n\nnew_output = GlobalAveragePooling2D()(base_model.output)\nnew_output = Dense(3, # class 3개   클래스 개수만큼 진행한다.\n                  activation = 'softmax')(new_output)\n\nmodel = keras.models.Model(base_model.inputs, new_output)\n\nmodel.summary()\n\nDownloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n87910968/87910968 [==============================] - 0s 0us/step\nModel: \"model\"\n__________________________________________________________________________________________________\n Layer (type)                Output Shape                 Param #   Connected to                  \n==================================================================================================\n input_1 (InputLayer)        [(None, 299, 299, 3)]        0         []                            \n                                                                                                  \n conv2d (Conv2D)             (None, 149, 149, 32)         864       ['input_1[0][0]']             \n                                                                                                  \n batch_normalization (Batch  (None, 149, 149, 32)         96        ['conv2d[0][0]']              \n Normalization)                                                                                   \n                                                                                                  \n activation (Activation)     (None, 149, 149, 32)         0         ['batch_normalization[0][0]'] \n                                                                                                  \n conv2d_1 (Conv2D)           (None, 147, 147, 32)         9216      ['activation[0][0]']          \n                                                                                                  \n batch_normalization_1 (Bat  (None, 147, 147, 32)         96        ['conv2d_1[0][0]']            \n chNormalization)                                                                                 \n                                                                                                  \n activation_1 (Activation)   (None, 147, 147, 32)         0         ['batch_normalization_1[0][0]'\n                                                                    ]                             \n                                                                                                  \n conv2d_2 (Conv2D)           (None, 147, 147, 64)         18432     ['activation_1[0][0]']        \n                                                                                                  \n batch_normalization_2 (Bat  (None, 147, 147, 64)         192       ['conv2d_2[0][0]']            \n chNormalization)                                                                                 \n                                                                                                  \n activation_2 (Activation)   (None, 147, 147, 64)         0         ['batch_normalization_2[0][0]'\n                                                                    ]                             \n                                                                                                  \n max_pooling2d (MaxPooling2  (None, 73, 73, 64)           0         ['activation_2[0][0]']        \n D)                                                                                               \n                                                                                                  \n conv2d_3 (Conv2D)           (None, 73, 73, 80)           5120      ['max_pooling2d[0][0]']       \n                                                                                                  \n batch_normalization_3 (Bat  (None, 73, 73, 80)           240       ['conv2d_3[0][0]']            \n chNormalization)                                                                                 \n                                                                                                  \n activation_3 (Activation)   (None, 73, 73, 80)           0         ['batch_normalization_3[0][0]'\n                                                                    ]                             \n                                                                                                  \n conv2d_4 (Conv2D)           (None, 71, 71, 192)          138240    ['activation_3[0][0]']        \n                                                                                                  \n batch_normalization_4 (Bat  (None, 71, 71, 192)          576       ['conv2d_4[0][0]']            \n chNormalization)                                                                                 \n                                                                                                  \n activation_4 (Activation)   (None, 71, 71, 192)          0         ['batch_normalization_4[0][0]'\n                                                                    ]                             \n                                                                                                  \n max_pooling2d_1 (MaxPoolin  (None, 35, 35, 192)          0         ['activation_4[0][0]']        \n g2D)                                                                                             \n                                                                                                  \n conv2d_8 (Conv2D)           (None, 35, 35, 64)           12288     ['max_pooling2d_1[0][0]']     \n                                                                                                  \n batch_normalization_8 (Bat  (None, 35, 35, 64)           192       ['conv2d_8[0][0]']            \n chNormalization)                                                                                 \n                                                                                                  \n activation_8 (Activation)   (None, 35, 35, 64)           0         ['batch_normalization_8[0][0]'\n                                                                    ]                             \n                                                                                                  \n conv2d_6 (Conv2D)           (None, 35, 35, 48)           9216      ['max_pooling2d_1[0][0]']     \n                                                                                                  \n conv2d_9 (Conv2D)           (None, 35, 35, 96)           55296     ['activation_8[0][0]']        \n                                                                                                  \n batch_normalization_6 (Bat  (None, 35, 35, 48)           144       ['conv2d_6[0][0]']            \n chNormalization)                                                                                 \n                                                                                                  \n batch_normalization_9 (Bat  (None, 35, 35, 96)           288       ['conv2d_9[0][0]']            \n chNormalization)                                                                                 \n                                                                                                  \n activation_6 (Activation)   (None, 35, 35, 48)           0         ['batch_normalization_6[0][0]'\n                                                                    ]                             \n                                                                                                  \n activation_9 (Activation)   (None, 35, 35, 96)           0         ['batch_normalization_9[0][0]'\n                                                                    ]                             \n                                                                                                  \n average_pooling2d (Average  (None, 35, 35, 192)          0         ['max_pooling2d_1[0][0]']     \n Pooling2D)                                                                                       \n                                                                                                  \n conv2d_5 (Conv2D)           (None, 35, 35, 64)           12288     ['max_pooling2d_1[0][0]']     \n                                                                                                  \n conv2d_7 (Conv2D)           (None, 35, 35, 64)           76800     ['activation_6[0][0]']        \n                                                                                                  \n conv2d_10 (Conv2D)          (None, 35, 35, 96)           82944     ['activation_9[0][0]']        \n                                                                                                  \n conv2d_11 (Conv2D)          (None, 35, 35, 32)           6144      ['average_pooling2d[0][0]']   \n                                                                                                  \n batch_normalization_5 (Bat  (None, 35, 35, 64)           192       ['conv2d_5[0][0]']            \n chNormalization)                                                                                 \n                                                                                                  \n batch_normalization_7 (Bat  (None, 35, 35, 64)           192       ['conv2d_7[0][0]']            \n chNormalization)                                                                                 \n                                                                                                  \n batch_normalization_10 (Ba  (None, 35, 35, 96)           288       ['conv2d_10[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n batch_normalization_11 (Ba  (None, 35, 35, 32)           96        ['conv2d_11[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n activation_5 (Activation)   (None, 35, 35, 64)           0         ['batch_normalization_5[0][0]'\n                                                                    ]                             \n                                                                                                  \n activation_7 (Activation)   (None, 35, 35, 64)           0         ['batch_normalization_7[0][0]'\n                                                                    ]                             \n                                                                                                  \n activation_10 (Activation)  (None, 35, 35, 96)           0         ['batch_normalization_10[0][0]\n                                                                    ']                            \n                                                                                                  \n activation_11 (Activation)  (None, 35, 35, 32)           0         ['batch_normalization_11[0][0]\n                                                                    ']                            \n                                                                                                  \n mixed0 (Concatenate)        (None, 35, 35, 256)          0         ['activation_5[0][0]',        \n                                                                     'activation_7[0][0]',        \n                                                                     'activation_10[0][0]',       \n                                                                     'activation_11[0][0]']       \n                                                                                                  \n conv2d_15 (Conv2D)          (None, 35, 35, 64)           16384     ['mixed0[0][0]']              \n                                                                                                  \n batch_normalization_15 (Ba  (None, 35, 35, 64)           192       ['conv2d_15[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n activation_15 (Activation)  (None, 35, 35, 64)           0         ['batch_normalization_15[0][0]\n                                                                    ']                            \n                                                                                                  \n conv2d_13 (Conv2D)          (None, 35, 35, 48)           12288     ['mixed0[0][0]']              \n                                                                                                  \n conv2d_16 (Conv2D)          (None, 35, 35, 96)           55296     ['activation_15[0][0]']       \n                                                                                                  \n batch_normalization_13 (Ba  (None, 35, 35, 48)           144       ['conv2d_13[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n batch_normalization_16 (Ba  (None, 35, 35, 96)           288       ['conv2d_16[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n activation_13 (Activation)  (None, 35, 35, 48)           0         ['batch_normalization_13[0][0]\n                                                                    ']                            \n                                                                                                  \n activation_16 (Activation)  (None, 35, 35, 96)           0         ['batch_normalization_16[0][0]\n                                                                    ']                            \n                                                                                                  \n average_pooling2d_1 (Avera  (None, 35, 35, 256)          0         ['mixed0[0][0]']              \n gePooling2D)                                                                                     \n                                                                                                  \n conv2d_12 (Conv2D)          (None, 35, 35, 64)           16384     ['mixed0[0][0]']              \n                                                                                                  \n conv2d_14 (Conv2D)          (None, 35, 35, 64)           76800     ['activation_13[0][0]']       \n                                                                                                  \n conv2d_17 (Conv2D)          (None, 35, 35, 96)           82944     ['activation_16[0][0]']       \n                                                                                                  \n conv2d_18 (Conv2D)          (None, 35, 35, 64)           16384     ['average_pooling2d_1[0][0]'] \n                                                                                                  \n batch_normalization_12 (Ba  (None, 35, 35, 64)           192       ['conv2d_12[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n batch_normalization_14 (Ba  (None, 35, 35, 64)           192       ['conv2d_14[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n batch_normalization_17 (Ba  (None, 35, 35, 96)           288       ['conv2d_17[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n batch_normalization_18 (Ba  (None, 35, 35, 64)           192       ['conv2d_18[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n activation_12 (Activation)  (None, 35, 35, 64)           0         ['batch_normalization_12[0][0]\n                                                                    ']                            \n                                                                                                  \n activation_14 (Activation)  (None, 35, 35, 64)           0         ['batch_normalization_14[0][0]\n                                                                    ']                            \n                                                                                                  \n activation_17 (Activation)  (None, 35, 35, 96)           0         ['batch_normalization_17[0][0]\n                                                                    ']                            \n                                                                                                  \n activation_18 (Activation)  (None, 35, 35, 64)           0         ['batch_normalization_18[0][0]\n                                                                    ']                            \n                                                                                                  \n mixed1 (Concatenate)        (None, 35, 35, 288)          0         ['activation_12[0][0]',       \n                                                                     'activation_14[0][0]',       \n                                                                     'activation_17[0][0]',       \n                                                                     'activation_18[0][0]']       \n                                                                                                  \n conv2d_22 (Conv2D)          (None, 35, 35, 64)           18432     ['mixed1[0][0]']              \n                                                                                                  \n batch_normalization_22 (Ba  (None, 35, 35, 64)           192       ['conv2d_22[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n activation_22 (Activation)  (None, 35, 35, 64)           0         ['batch_normalization_22[0][0]\n                                                                    ']                            \n                                                                                                  \n conv2d_20 (Conv2D)          (None, 35, 35, 48)           13824     ['mixed1[0][0]']              \n                                                                                                  \n conv2d_23 (Conv2D)          (None, 35, 35, 96)           55296     ['activation_22[0][0]']       \n                                                                                                  \n batch_normalization_20 (Ba  (None, 35, 35, 48)           144       ['conv2d_20[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n batch_normalization_23 (Ba  (None, 35, 35, 96)           288       ['conv2d_23[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n activation_20 (Activation)  (None, 35, 35, 48)           0         ['batch_normalization_20[0][0]\n                                                                    ']                            \n                                                                                                  \n activation_23 (Activation)  (None, 35, 35, 96)           0         ['batch_normalization_23[0][0]\n                                                                    ']                            \n                                                                                                  \n average_pooling2d_2 (Avera  (None, 35, 35, 288)          0         ['mixed1[0][0]']              \n gePooling2D)                                                                                     \n                                                                                                  \n conv2d_19 (Conv2D)          (None, 35, 35, 64)           18432     ['mixed1[0][0]']              \n                                                                                                  \n conv2d_21 (Conv2D)          (None, 35, 35, 64)           76800     ['activation_20[0][0]']       \n                                                                                                  \n conv2d_24 (Conv2D)          (None, 35, 35, 96)           82944     ['activation_23[0][0]']       \n                                                                                                  \n conv2d_25 (Conv2D)          (None, 35, 35, 64)           18432     ['average_pooling2d_2[0][0]'] \n                                                                                                  \n batch_normalization_19 (Ba  (None, 35, 35, 64)           192       ['conv2d_19[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n batch_normalization_21 (Ba  (None, 35, 35, 64)           192       ['conv2d_21[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n batch_normalization_24 (Ba  (None, 35, 35, 96)           288       ['conv2d_24[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n batch_normalization_25 (Ba  (None, 35, 35, 64)           192       ['conv2d_25[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n activation_19 (Activation)  (None, 35, 35, 64)           0         ['batch_normalization_19[0][0]\n                                                                    ']                            \n                                                                                                  \n activation_21 (Activation)  (None, 35, 35, 64)           0         ['batch_normalization_21[0][0]\n                                                                    ']                            \n                                                                                                  \n activation_24 (Activation)  (None, 35, 35, 96)           0         ['batch_normalization_24[0][0]\n                                                                    ']                            \n                                                                                                  \n activation_25 (Activation)  (None, 35, 35, 64)           0         ['batch_normalization_25[0][0]\n                                                                    ']                            \n                                                                                                  \n mixed2 (Concatenate)        (None, 35, 35, 288)          0         ['activation_19[0][0]',       \n                                                                     'activation_21[0][0]',       \n                                                                     'activation_24[0][0]',       \n                                                                     'activation_25[0][0]']       \n                                                                                                  \n conv2d_27 (Conv2D)          (None, 35, 35, 64)           18432     ['mixed2[0][0]']              \n                                                                                                  \n batch_normalization_27 (Ba  (None, 35, 35, 64)           192       ['conv2d_27[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n activation_27 (Activation)  (None, 35, 35, 64)           0         ['batch_normalization_27[0][0]\n                                                                    ']                            \n                                                                                                  \n conv2d_28 (Conv2D)          (None, 35, 35, 96)           55296     ['activation_27[0][0]']       \n                                                                                                  \n batch_normalization_28 (Ba  (None, 35, 35, 96)           288       ['conv2d_28[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n activation_28 (Activation)  (None, 35, 35, 96)           0         ['batch_normalization_28[0][0]\n                                                                    ']                            \n                                                                                                  \n conv2d_26 (Conv2D)          (None, 17, 17, 384)          995328    ['mixed2[0][0]']              \n                                                                                                  \n conv2d_29 (Conv2D)          (None, 17, 17, 96)           82944     ['activation_28[0][0]']       \n                                                                                                  \n batch_normalization_26 (Ba  (None, 17, 17, 384)          1152      ['conv2d_26[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n batch_normalization_29 (Ba  (None, 17, 17, 96)           288       ['conv2d_29[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n activation_26 (Activation)  (None, 17, 17, 384)          0         ['batch_normalization_26[0][0]\n                                                                    ']                            \n                                                                                                  \n activation_29 (Activation)  (None, 17, 17, 96)           0         ['batch_normalization_29[0][0]\n                                                                    ']                            \n                                                                                                  \n max_pooling2d_2 (MaxPoolin  (None, 17, 17, 288)          0         ['mixed2[0][0]']              \n g2D)                                                                                             \n                                                                                                  \n mixed3 (Concatenate)        (None, 17, 17, 768)          0         ['activation_26[0][0]',       \n                                                                     'activation_29[0][0]',       \n                                                                     'max_pooling2d_2[0][0]']     \n                                                                                                  \n conv2d_34 (Conv2D)          (None, 17, 17, 128)          98304     ['mixed3[0][0]']              \n                                                                                                  \n batch_normalization_34 (Ba  (None, 17, 17, 128)          384       ['conv2d_34[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n activation_34 (Activation)  (None, 17, 17, 128)          0         ['batch_normalization_34[0][0]\n                                                                    ']                            \n                                                                                                  \n conv2d_35 (Conv2D)          (None, 17, 17, 128)          114688    ['activation_34[0][0]']       \n                                                                                                  \n batch_normalization_35 (Ba  (None, 17, 17, 128)          384       ['conv2d_35[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n activation_35 (Activation)  (None, 17, 17, 128)          0         ['batch_normalization_35[0][0]\n                                                                    ']                            \n                                                                                                  \n conv2d_31 (Conv2D)          (None, 17, 17, 128)          98304     ['mixed3[0][0]']              \n                                                                                                  \n conv2d_36 (Conv2D)          (None, 17, 17, 128)          114688    ['activation_35[0][0]']       \n                                                                                                  \n batch_normalization_31 (Ba  (None, 17, 17, 128)          384       ['conv2d_31[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n batch_normalization_36 (Ba  (None, 17, 17, 128)          384       ['conv2d_36[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n activation_31 (Activation)  (None, 17, 17, 128)          0         ['batch_normalization_31[0][0]\n                                                                    ']                            \n                                                                                                  \n activation_36 (Activation)  (None, 17, 17, 128)          0         ['batch_normalization_36[0][0]\n                                                                    ']                            \n                                                                                                  \n conv2d_32 (Conv2D)          (None, 17, 17, 128)          114688    ['activation_31[0][0]']       \n                                                                                                  \n conv2d_37 (Conv2D)          (None, 17, 17, 128)          114688    ['activation_36[0][0]']       \n                                                                                                  \n batch_normalization_32 (Ba  (None, 17, 17, 128)          384       ['conv2d_32[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n batch_normalization_37 (Ba  (None, 17, 17, 128)          384       ['conv2d_37[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n activation_32 (Activation)  (None, 17, 17, 128)          0         ['batch_normalization_32[0][0]\n                                                                    ']                            \n                                                                                                  \n activation_37 (Activation)  (None, 17, 17, 128)          0         ['batch_normalization_37[0][0]\n                                                                    ']                            \n                                                                                                  \n average_pooling2d_3 (Avera  (None, 17, 17, 768)          0         ['mixed3[0][0]']              \n gePooling2D)                                                                                     \n                                                                                                  \n conv2d_30 (Conv2D)          (None, 17, 17, 192)          147456    ['mixed3[0][0]']              \n                                                                                                  \n conv2d_33 (Conv2D)          (None, 17, 17, 192)          172032    ['activation_32[0][0]']       \n                                                                                                  \n conv2d_38 (Conv2D)          (None, 17, 17, 192)          172032    ['activation_37[0][0]']       \n                                                                                                  \n conv2d_39 (Conv2D)          (None, 17, 17, 192)          147456    ['average_pooling2d_3[0][0]'] \n                                                                                                  \n batch_normalization_30 (Ba  (None, 17, 17, 192)          576       ['conv2d_30[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n batch_normalization_33 (Ba  (None, 17, 17, 192)          576       ['conv2d_33[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n batch_normalization_38 (Ba  (None, 17, 17, 192)          576       ['conv2d_38[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n batch_normalization_39 (Ba  (None, 17, 17, 192)          576       ['conv2d_39[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n activation_30 (Activation)  (None, 17, 17, 192)          0         ['batch_normalization_30[0][0]\n                                                                    ']                            \n                                                                                                  \n activation_33 (Activation)  (None, 17, 17, 192)          0         ['batch_normalization_33[0][0]\n                                                                    ']                            \n                                                                                                  \n activation_38 (Activation)  (None, 17, 17, 192)          0         ['batch_normalization_38[0][0]\n                                                                    ']                            \n                                                                                                  \n activation_39 (Activation)  (None, 17, 17, 192)          0         ['batch_normalization_39[0][0]\n                                                                    ']                            \n                                                                                                  \n mixed4 (Concatenate)        (None, 17, 17, 768)          0         ['activation_30[0][0]',       \n                                                                     'activation_33[0][0]',       \n                                                                     'activation_38[0][0]',       \n                                                                     'activation_39[0][0]']       \n                                                                                                  \n conv2d_44 (Conv2D)          (None, 17, 17, 160)          122880    ['mixed4[0][0]']              \n                                                                                                  \n batch_normalization_44 (Ba  (None, 17, 17, 160)          480       ['conv2d_44[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n activation_44 (Activation)  (None, 17, 17, 160)          0         ['batch_normalization_44[0][0]\n                                                                    ']                            \n                                                                                                  \n conv2d_45 (Conv2D)          (None, 17, 17, 160)          179200    ['activation_44[0][0]']       \n                                                                                                  \n batch_normalization_45 (Ba  (None, 17, 17, 160)          480       ['conv2d_45[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n activation_45 (Activation)  (None, 17, 17, 160)          0         ['batch_normalization_45[0][0]\n                                                                    ']                            \n                                                                                                  \n conv2d_41 (Conv2D)          (None, 17, 17, 160)          122880    ['mixed4[0][0]']              \n                                                                                                  \n conv2d_46 (Conv2D)          (None, 17, 17, 160)          179200    ['activation_45[0][0]']       \n                                                                                                  \n batch_normalization_41 (Ba  (None, 17, 17, 160)          480       ['conv2d_41[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n batch_normalization_46 (Ba  (None, 17, 17, 160)          480       ['conv2d_46[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n activation_41 (Activation)  (None, 17, 17, 160)          0         ['batch_normalization_41[0][0]\n                                                                    ']                            \n                                                                                                  \n activation_46 (Activation)  (None, 17, 17, 160)          0         ['batch_normalization_46[0][0]\n                                                                    ']                            \n                                                                                                  \n conv2d_42 (Conv2D)          (None, 17, 17, 160)          179200    ['activation_41[0][0]']       \n                                                                                                  \n conv2d_47 (Conv2D)          (None, 17, 17, 160)          179200    ['activation_46[0][0]']       \n                                                                                                  \n batch_normalization_42 (Ba  (None, 17, 17, 160)          480       ['conv2d_42[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n batch_normalization_47 (Ba  (None, 17, 17, 160)          480       ['conv2d_47[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n activation_42 (Activation)  (None, 17, 17, 160)          0         ['batch_normalization_42[0][0]\n                                                                    ']                            \n                                                                                                  \n activation_47 (Activation)  (None, 17, 17, 160)          0         ['batch_normalization_47[0][0]\n                                                                    ']                            \n                                                                                                  \n average_pooling2d_4 (Avera  (None, 17, 17, 768)          0         ['mixed4[0][0]']              \n gePooling2D)                                                                                     \n                                                                                                  \n conv2d_40 (Conv2D)          (None, 17, 17, 192)          147456    ['mixed4[0][0]']              \n                                                                                                  \n conv2d_43 (Conv2D)          (None, 17, 17, 192)          215040    ['activation_42[0][0]']       \n                                                                                                  \n conv2d_48 (Conv2D)          (None, 17, 17, 192)          215040    ['activation_47[0][0]']       \n                                                                                                  \n conv2d_49 (Conv2D)          (None, 17, 17, 192)          147456    ['average_pooling2d_4[0][0]'] \n                                                                                                  \n batch_normalization_40 (Ba  (None, 17, 17, 192)          576       ['conv2d_40[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n batch_normalization_43 (Ba  (None, 17, 17, 192)          576       ['conv2d_43[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n batch_normalization_48 (Ba  (None, 17, 17, 192)          576       ['conv2d_48[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n batch_normalization_49 (Ba  (None, 17, 17, 192)          576       ['conv2d_49[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n activation_40 (Activation)  (None, 17, 17, 192)          0         ['batch_normalization_40[0][0]\n                                                                    ']                            \n                                                                                                  \n activation_43 (Activation)  (None, 17, 17, 192)          0         ['batch_normalization_43[0][0]\n                                                                    ']                            \n                                                                                                  \n activation_48 (Activation)  (None, 17, 17, 192)          0         ['batch_normalization_48[0][0]\n                                                                    ']                            \n                                                                                                  \n activation_49 (Activation)  (None, 17, 17, 192)          0         ['batch_normalization_49[0][0]\n                                                                    ']                            \n                                                                                                  \n mixed5 (Concatenate)        (None, 17, 17, 768)          0         ['activation_40[0][0]',       \n                                                                     'activation_43[0][0]',       \n                                                                     'activation_48[0][0]',       \n                                                                     'activation_49[0][0]']       \n                                                                                                  \n conv2d_54 (Conv2D)          (None, 17, 17, 160)          122880    ['mixed5[0][0]']              \n                                                                                                  \n batch_normalization_54 (Ba  (None, 17, 17, 160)          480       ['conv2d_54[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n activation_54 (Activation)  (None, 17, 17, 160)          0         ['batch_normalization_54[0][0]\n                                                                    ']                            \n                                                                                                  \n conv2d_55 (Conv2D)          (None, 17, 17, 160)          179200    ['activation_54[0][0]']       \n                                                                                                  \n batch_normalization_55 (Ba  (None, 17, 17, 160)          480       ['conv2d_55[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n activation_55 (Activation)  (None, 17, 17, 160)          0         ['batch_normalization_55[0][0]\n                                                                    ']                            \n                                                                                                  \n conv2d_51 (Conv2D)          (None, 17, 17, 160)          122880    ['mixed5[0][0]']              \n                                                                                                  \n conv2d_56 (Conv2D)          (None, 17, 17, 160)          179200    ['activation_55[0][0]']       \n                                                                                                  \n batch_normalization_51 (Ba  (None, 17, 17, 160)          480       ['conv2d_51[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n batch_normalization_56 (Ba  (None, 17, 17, 160)          480       ['conv2d_56[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n activation_51 (Activation)  (None, 17, 17, 160)          0         ['batch_normalization_51[0][0]\n                                                                    ']                            \n                                                                                                  \n activation_56 (Activation)  (None, 17, 17, 160)          0         ['batch_normalization_56[0][0]\n                                                                    ']                            \n                                                                                                  \n conv2d_52 (Conv2D)          (None, 17, 17, 160)          179200    ['activation_51[0][0]']       \n                                                                                                  \n conv2d_57 (Conv2D)          (None, 17, 17, 160)          179200    ['activation_56[0][0]']       \n                                                                                                  \n batch_normalization_52 (Ba  (None, 17, 17, 160)          480       ['conv2d_52[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n batch_normalization_57 (Ba  (None, 17, 17, 160)          480       ['conv2d_57[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n activation_52 (Activation)  (None, 17, 17, 160)          0         ['batch_normalization_52[0][0]\n                                                                    ']                            \n                                                                                                  \n activation_57 (Activation)  (None, 17, 17, 160)          0         ['batch_normalization_57[0][0]\n                                                                    ']                            \n                                                                                                  \n average_pooling2d_5 (Avera  (None, 17, 17, 768)          0         ['mixed5[0][0]']              \n gePooling2D)                                                                                     \n                                                                                                  \n conv2d_50 (Conv2D)          (None, 17, 17, 192)          147456    ['mixed5[0][0]']              \n                                                                                                  \n conv2d_53 (Conv2D)          (None, 17, 17, 192)          215040    ['activation_52[0][0]']       \n                                                                                                  \n conv2d_58 (Conv2D)          (None, 17, 17, 192)          215040    ['activation_57[0][0]']       \n                                                                                                  \n conv2d_59 (Conv2D)          (None, 17, 17, 192)          147456    ['average_pooling2d_5[0][0]'] \n                                                                                                  \n batch_normalization_50 (Ba  (None, 17, 17, 192)          576       ['conv2d_50[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n batch_normalization_53 (Ba  (None, 17, 17, 192)          576       ['conv2d_53[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n batch_normalization_58 (Ba  (None, 17, 17, 192)          576       ['conv2d_58[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n batch_normalization_59 (Ba  (None, 17, 17, 192)          576       ['conv2d_59[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n activation_50 (Activation)  (None, 17, 17, 192)          0         ['batch_normalization_50[0][0]\n                                                                    ']                            \n                                                                                                  \n activation_53 (Activation)  (None, 17, 17, 192)          0         ['batch_normalization_53[0][0]\n                                                                    ']                            \n                                                                                                  \n activation_58 (Activation)  (None, 17, 17, 192)          0         ['batch_normalization_58[0][0]\n                                                                    ']                            \n                                                                                                  \n activation_59 (Activation)  (None, 17, 17, 192)          0         ['batch_normalization_59[0][0]\n                                                                    ']                            \n                                                                                                  \n mixed6 (Concatenate)        (None, 17, 17, 768)          0         ['activation_50[0][0]',       \n                                                                     'activation_53[0][0]',       \n                                                                     'activation_58[0][0]',       \n                                                                     'activation_59[0][0]']       \n                                                                                                  \n conv2d_64 (Conv2D)          (None, 17, 17, 192)          147456    ['mixed6[0][0]']              \n                                                                                                  \n batch_normalization_64 (Ba  (None, 17, 17, 192)          576       ['conv2d_64[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n activation_64 (Activation)  (None, 17, 17, 192)          0         ['batch_normalization_64[0][0]\n                                                                    ']                            \n                                                                                                  \n conv2d_65 (Conv2D)          (None, 17, 17, 192)          258048    ['activation_64[0][0]']       \n                                                                                                  \n batch_normalization_65 (Ba  (None, 17, 17, 192)          576       ['conv2d_65[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n activation_65 (Activation)  (None, 17, 17, 192)          0         ['batch_normalization_65[0][0]\n                                                                    ']                            \n                                                                                                  \n conv2d_61 (Conv2D)          (None, 17, 17, 192)          147456    ['mixed6[0][0]']              \n                                                                                                  \n conv2d_66 (Conv2D)          (None, 17, 17, 192)          258048    ['activation_65[0][0]']       \n                                                                                                  \n batch_normalization_61 (Ba  (None, 17, 17, 192)          576       ['conv2d_61[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n batch_normalization_66 (Ba  (None, 17, 17, 192)          576       ['conv2d_66[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n activation_61 (Activation)  (None, 17, 17, 192)          0         ['batch_normalization_61[0][0]\n                                                                    ']                            \n                                                                                                  \n activation_66 (Activation)  (None, 17, 17, 192)          0         ['batch_normalization_66[0][0]\n                                                                    ']                            \n                                                                                                  \n conv2d_62 (Conv2D)          (None, 17, 17, 192)          258048    ['activation_61[0][0]']       \n                                                                                                  \n conv2d_67 (Conv2D)          (None, 17, 17, 192)          258048    ['activation_66[0][0]']       \n                                                                                                  \n batch_normalization_62 (Ba  (None, 17, 17, 192)          576       ['conv2d_62[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n batch_normalization_67 (Ba  (None, 17, 17, 192)          576       ['conv2d_67[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n activation_62 (Activation)  (None, 17, 17, 192)          0         ['batch_normalization_62[0][0]\n                                                                    ']                            \n                                                                                                  \n activation_67 (Activation)  (None, 17, 17, 192)          0         ['batch_normalization_67[0][0]\n                                                                    ']                            \n                                                                                                  \n average_pooling2d_6 (Avera  (None, 17, 17, 768)          0         ['mixed6[0][0]']              \n gePooling2D)                                                                                     \n                                                                                                  \n conv2d_60 (Conv2D)          (None, 17, 17, 192)          147456    ['mixed6[0][0]']              \n                                                                                                  \n conv2d_63 (Conv2D)          (None, 17, 17, 192)          258048    ['activation_62[0][0]']       \n                                                                                                  \n conv2d_68 (Conv2D)          (None, 17, 17, 192)          258048    ['activation_67[0][0]']       \n                                                                                                  \n conv2d_69 (Conv2D)          (None, 17, 17, 192)          147456    ['average_pooling2d_6[0][0]'] \n                                                                                                  \n batch_normalization_60 (Ba  (None, 17, 17, 192)          576       ['conv2d_60[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n batch_normalization_63 (Ba  (None, 17, 17, 192)          576       ['conv2d_63[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n batch_normalization_68 (Ba  (None, 17, 17, 192)          576       ['conv2d_68[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n batch_normalization_69 (Ba  (None, 17, 17, 192)          576       ['conv2d_69[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n activation_60 (Activation)  (None, 17, 17, 192)          0         ['batch_normalization_60[0][0]\n                                                                    ']                            \n                                                                                                  \n activation_63 (Activation)  (None, 17, 17, 192)          0         ['batch_normalization_63[0][0]\n                                                                    ']                            \n                                                                                                  \n activation_68 (Activation)  (None, 17, 17, 192)          0         ['batch_normalization_68[0][0]\n                                                                    ']                            \n                                                                                                  \n activation_69 (Activation)  (None, 17, 17, 192)          0         ['batch_normalization_69[0][0]\n                                                                    ']                            \n                                                                                                  \n mixed7 (Concatenate)        (None, 17, 17, 768)          0         ['activation_60[0][0]',       \n                                                                     'activation_63[0][0]',       \n                                                                     'activation_68[0][0]',       \n                                                                     'activation_69[0][0]']       \n                                                                                                  \n conv2d_72 (Conv2D)          (None, 17, 17, 192)          147456    ['mixed7[0][0]']              \n                                                                                                  \n batch_normalization_72 (Ba  (None, 17, 17, 192)          576       ['conv2d_72[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n activation_72 (Activation)  (None, 17, 17, 192)          0         ['batch_normalization_72[0][0]\n                                                                    ']                            \n                                                                                                  \n conv2d_73 (Conv2D)          (None, 17, 17, 192)          258048    ['activation_72[0][0]']       \n                                                                                                  \n batch_normalization_73 (Ba  (None, 17, 17, 192)          576       ['conv2d_73[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n activation_73 (Activation)  (None, 17, 17, 192)          0         ['batch_normalization_73[0][0]\n                                                                    ']                            \n                                                                                                  \n conv2d_70 (Conv2D)          (None, 17, 17, 192)          147456    ['mixed7[0][0]']              \n                                                                                                  \n conv2d_74 (Conv2D)          (None, 17, 17, 192)          258048    ['activation_73[0][0]']       \n                                                                                                  \n batch_normalization_70 (Ba  (None, 17, 17, 192)          576       ['conv2d_70[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n batch_normalization_74 (Ba  (None, 17, 17, 192)          576       ['conv2d_74[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n activation_70 (Activation)  (None, 17, 17, 192)          0         ['batch_normalization_70[0][0]\n                                                                    ']                            \n                                                                                                  \n activation_74 (Activation)  (None, 17, 17, 192)          0         ['batch_normalization_74[0][0]\n                                                                    ']                            \n                                                                                                  \n conv2d_71 (Conv2D)          (None, 8, 8, 320)            552960    ['activation_70[0][0]']       \n                                                                                                  \n conv2d_75 (Conv2D)          (None, 8, 8, 192)            331776    ['activation_74[0][0]']       \n                                                                                                  \n batch_normalization_71 (Ba  (None, 8, 8, 320)            960       ['conv2d_71[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n batch_normalization_75 (Ba  (None, 8, 8, 192)            576       ['conv2d_75[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n activation_71 (Activation)  (None, 8, 8, 320)            0         ['batch_normalization_71[0][0]\n                                                                    ']                            \n                                                                                                  \n activation_75 (Activation)  (None, 8, 8, 192)            0         ['batch_normalization_75[0][0]\n                                                                    ']                            \n                                                                                                  \n max_pooling2d_3 (MaxPoolin  (None, 8, 8, 768)            0         ['mixed7[0][0]']              \n g2D)                                                                                             \n                                                                                                  \n mixed8 (Concatenate)        (None, 8, 8, 1280)           0         ['activation_71[0][0]',       \n                                                                     'activation_75[0][0]',       \n                                                                     'max_pooling2d_3[0][0]']     \n                                                                                                  \n conv2d_80 (Conv2D)          (None, 8, 8, 448)            573440    ['mixed8[0][0]']              \n                                                                                                  \n batch_normalization_80 (Ba  (None, 8, 8, 448)            1344      ['conv2d_80[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n activation_80 (Activation)  (None, 8, 8, 448)            0         ['batch_normalization_80[0][0]\n                                                                    ']                            \n                                                                                                  \n conv2d_77 (Conv2D)          (None, 8, 8, 384)            491520    ['mixed8[0][0]']              \n                                                                                                  \n conv2d_81 (Conv2D)          (None, 8, 8, 384)            1548288   ['activation_80[0][0]']       \n                                                                                                  \n batch_normalization_77 (Ba  (None, 8, 8, 384)            1152      ['conv2d_77[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n batch_normalization_81 (Ba  (None, 8, 8, 384)            1152      ['conv2d_81[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n activation_77 (Activation)  (None, 8, 8, 384)            0         ['batch_normalization_77[0][0]\n                                                                    ']                            \n                                                                                                  \n activation_81 (Activation)  (None, 8, 8, 384)            0         ['batch_normalization_81[0][0]\n                                                                    ']                            \n                                                                                                  \n conv2d_78 (Conv2D)          (None, 8, 8, 384)            442368    ['activation_77[0][0]']       \n                                                                                                  \n conv2d_79 (Conv2D)          (None, 8, 8, 384)            442368    ['activation_77[0][0]']       \n                                                                                                  \n conv2d_82 (Conv2D)          (None, 8, 8, 384)            442368    ['activation_81[0][0]']       \n                                                                                                  \n conv2d_83 (Conv2D)          (None, 8, 8, 384)            442368    ['activation_81[0][0]']       \n                                                                                                  \n average_pooling2d_7 (Avera  (None, 8, 8, 1280)           0         ['mixed8[0][0]']              \n gePooling2D)                                                                                     \n                                                                                                  \n conv2d_76 (Conv2D)          (None, 8, 8, 320)            409600    ['mixed8[0][0]']              \n                                                                                                  \n batch_normalization_78 (Ba  (None, 8, 8, 384)            1152      ['conv2d_78[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n batch_normalization_79 (Ba  (None, 8, 8, 384)            1152      ['conv2d_79[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n batch_normalization_82 (Ba  (None, 8, 8, 384)            1152      ['conv2d_82[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n batch_normalization_83 (Ba  (None, 8, 8, 384)            1152      ['conv2d_83[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n conv2d_84 (Conv2D)          (None, 8, 8, 192)            245760    ['average_pooling2d_7[0][0]'] \n                                                                                                  \n batch_normalization_76 (Ba  (None, 8, 8, 320)            960       ['conv2d_76[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n activation_78 (Activation)  (None, 8, 8, 384)            0         ['batch_normalization_78[0][0]\n                                                                    ']                            \n                                                                                                  \n activation_79 (Activation)  (None, 8, 8, 384)            0         ['batch_normalization_79[0][0]\n                                                                    ']                            \n                                                                                                  \n activation_82 (Activation)  (None, 8, 8, 384)            0         ['batch_normalization_82[0][0]\n                                                                    ']                            \n                                                                                                  \n activation_83 (Activation)  (None, 8, 8, 384)            0         ['batch_normalization_83[0][0]\n                                                                    ']                            \n                                                                                                  \n batch_normalization_84 (Ba  (None, 8, 8, 192)            576       ['conv2d_84[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n activation_76 (Activation)  (None, 8, 8, 320)            0         ['batch_normalization_76[0][0]\n                                                                    ']                            \n                                                                                                  \n mixed9_0 (Concatenate)      (None, 8, 8, 768)            0         ['activation_78[0][0]',       \n                                                                     'activation_79[0][0]']       \n                                                                                                  \n concatenate (Concatenate)   (None, 8, 8, 768)            0         ['activation_82[0][0]',       \n                                                                     'activation_83[0][0]']       \n                                                                                                  \n activation_84 (Activation)  (None, 8, 8, 192)            0         ['batch_normalization_84[0][0]\n                                                                    ']                            \n                                                                                                  \n mixed9 (Concatenate)        (None, 8, 8, 2048)           0         ['activation_76[0][0]',       \n                                                                     'mixed9_0[0][0]',            \n                                                                     'concatenate[0][0]',         \n                                                                     'activation_84[0][0]']       \n                                                                                                  \n conv2d_89 (Conv2D)          (None, 8, 8, 448)            917504    ['mixed9[0][0]']              \n                                                                                                  \n batch_normalization_89 (Ba  (None, 8, 8, 448)            1344      ['conv2d_89[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n activation_89 (Activation)  (None, 8, 8, 448)            0         ['batch_normalization_89[0][0]\n                                                                    ']                            \n                                                                                                  \n conv2d_86 (Conv2D)          (None, 8, 8, 384)            786432    ['mixed9[0][0]']              \n                                                                                                  \n conv2d_90 (Conv2D)          (None, 8, 8, 384)            1548288   ['activation_89[0][0]']       \n                                                                                                  \n batch_normalization_86 (Ba  (None, 8, 8, 384)            1152      ['conv2d_86[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n batch_normalization_90 (Ba  (None, 8, 8, 384)            1152      ['conv2d_90[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n activation_86 (Activation)  (None, 8, 8, 384)            0         ['batch_normalization_86[0][0]\n                                                                    ']                            \n                                                                                                  \n activation_90 (Activation)  (None, 8, 8, 384)            0         ['batch_normalization_90[0][0]\n                                                                    ']                            \n                                                                                                  \n conv2d_87 (Conv2D)          (None, 8, 8, 384)            442368    ['activation_86[0][0]']       \n                                                                                                  \n conv2d_88 (Conv2D)          (None, 8, 8, 384)            442368    ['activation_86[0][0]']       \n                                                                                                  \n conv2d_91 (Conv2D)          (None, 8, 8, 384)            442368    ['activation_90[0][0]']       \n                                                                                                  \n conv2d_92 (Conv2D)          (None, 8, 8, 384)            442368    ['activation_90[0][0]']       \n                                                                                                  \n average_pooling2d_8 (Avera  (None, 8, 8, 2048)           0         ['mixed9[0][0]']              \n gePooling2D)                                                                                     \n                                                                                                  \n conv2d_85 (Conv2D)          (None, 8, 8, 320)            655360    ['mixed9[0][0]']              \n                                                                                                  \n batch_normalization_87 (Ba  (None, 8, 8, 384)            1152      ['conv2d_87[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n batch_normalization_88 (Ba  (None, 8, 8, 384)            1152      ['conv2d_88[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n batch_normalization_91 (Ba  (None, 8, 8, 384)            1152      ['conv2d_91[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n batch_normalization_92 (Ba  (None, 8, 8, 384)            1152      ['conv2d_92[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n conv2d_93 (Conv2D)          (None, 8, 8, 192)            393216    ['average_pooling2d_8[0][0]'] \n                                                                                                  \n batch_normalization_85 (Ba  (None, 8, 8, 320)            960       ['conv2d_85[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n activation_87 (Activation)  (None, 8, 8, 384)            0         ['batch_normalization_87[0][0]\n                                                                    ']                            \n                                                                                                  \n activation_88 (Activation)  (None, 8, 8, 384)            0         ['batch_normalization_88[0][0]\n                                                                    ']                            \n                                                                                                  \n activation_91 (Activation)  (None, 8, 8, 384)            0         ['batch_normalization_91[0][0]\n                                                                    ']                            \n                                                                                                  \n activation_92 (Activation)  (None, 8, 8, 384)            0         ['batch_normalization_92[0][0]\n                                                                    ']                            \n                                                                                                  \n batch_normalization_93 (Ba  (None, 8, 8, 192)            576       ['conv2d_93[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n activation_85 (Activation)  (None, 8, 8, 320)            0         ['batch_normalization_85[0][0]\n                                                                    ']                            \n                                                                                                  \n mixed9_1 (Concatenate)      (None, 8, 8, 768)            0         ['activation_87[0][0]',       \n                                                                     'activation_88[0][0]']       \n                                                                                                  \n concatenate_1 (Concatenate  (None, 8, 8, 768)            0         ['activation_91[0][0]',       \n )                                                                   'activation_92[0][0]']       \n                                                                                                  \n activation_93 (Activation)  (None, 8, 8, 192)            0         ['batch_normalization_93[0][0]\n                                                                    ']                            \n                                                                                                  \n mixed10 (Concatenate)       (None, 8, 8, 2048)           0         ['activation_85[0][0]',       \n                                                                     'mixed9_1[0][0]',            \n                                                                     'concatenate_1[0][0]',       \n                                                                     'activation_93[0][0]']       \n                                                                                                  \n global_average_pooling2d (  (None, 2048)                 0         ['mixed10[0][0]']             \n GlobalAveragePooling2D)                                                                          \n                                                                                                  \n dense (Dense)               (None, 3)                    6147      ['global_average_pooling2d[0][\n                                                                    0]']                          \n                                                                                                  \n==================================================================================================\nTotal params: 21808931 (83.19 MB)\nTrainable params: 21774499 (83.06 MB)\nNon-trainable params: 34432 (134.50 KB)\n__________________________________________________________________________________________________\n\n\n\nfrom tensorflow.keras.utils import plot_model\n\n\nplot_model(model, show_shapes=True, show_layer_names=True)\n\nOutput hidden; open in https://colab.research.google.com to view.\n\n\n\nprint(f'모델의 레이어 수 : {len(model.layers)}')\n\n모델의 레이어 수 : 313\n\n\n\n\n\n\n모델의 가중치를 그대로 사용할 레이어와 추가 학습할 레이어를 결정합니다.\n\n\nmodel.layers\n\n\nfor idx, layer in enumerate(model.layers) :\n    if idx &lt; 213 :\n        layer.trainable = False\n    else :\n        layer.trainable = True\n\n\n# 처음부터 학습시키는 것도 아니고,\n# 마지막 100개의 레이어만 튜닝 할 것이므로 learning rate를 조금 크게 잡아본다.\n\nmodel.compile(loss='categorical_crossentropy', metrics=['accuracy'],\n             optimizer=keras.optimizers.Adam(learning_rate=0.001) )\n\n\n\n\n\nlr_reduction = ReduceLROnPlateau(monitor='val_loss',\n                                 patience=4,\n                                 verbose=1,\n                                 factor=0.5,\n                                 min_lr=0.000001)\n\nes = EarlyStopping(monitor='val_loss',\n                   min_delta=0, # 개선되고 있다고 판단하기 위한 최소 변화량\n                   patience=8,  # 개선 없는 epoch 얼마나 기달려 줄거야\n                   verbose=1,\n                   restore_best_weights=True)\n\n\ntrainIDG = ImageDataGenerator(\n    featurewise_center=False,  # set input mean to 0 over the dataset\n    samplewise_center=False,  # set each sample mean to 0\n    featurewise_std_normalization=False,  # divide inputs by std of the dataset\n    samplewise_std_normalization=False,  # divide each input by its std\n    zca_whitening=False,  # apply ZCA whitening\n    rotation_range=180, # randomly rotate images in the range (degrees, 0 to 180)\n    zoom_range = 0.3, # Randomly zoom image\n    width_shift_range=0.3,  # randomly shift images horizontally (fraction of total width)\n    height_shift_range=0.3,  # randomly shift images vertically (fraction of total height)\n    horizontal_flip=True,  # randomly flip images\n    vertical_flip=True)  # randomly flip images\n\nvalidIDG = ImageDataGenerator()\n\n\ntrainIDG.fit(train_x)\nvalidIDG.fit(valid_x)\n\n\nflow_trainIDG = trainIDG.flow(train_x, train_y)\nflow_validIDG = validIDG.flow(valid_x, valid_y)\n\n\n\n\n\n# 데이터를 넣어서 학습시키자!\nhist = model.fit(flow_trainIDG, validation_data=flow_validIDG,\n                 epochs=1000, verbose=1,\n                 callbacks=[es, lr_reduction]\n                 )\n\nEpoch 1/1000\n1/1 [==============================] - 31s 31s/step - loss: 0.9249 - accuracy: 0.7500 - val_loss: 14.0317 - val_accuracy: 0.0000e+00 - lr: 0.0010\nEpoch 2/1000\n1/1 [==============================] - 1s 602ms/step - loss: 0.5820 - accuracy: 0.7500 - val_loss: 0.0033 - val_accuracy: 1.0000 - lr: 0.0010\nEpoch 3/1000\n1/1 [==============================] - 1s 523ms/step - loss: 0.1278 - accuracy: 1.0000 - val_loss: 0.0026 - val_accuracy: 1.0000 - lr: 0.0010\nEpoch 4/1000\n1/1 [==============================] - 0s 422ms/step - loss: 0.0316 - accuracy: 1.0000 - val_loss: 0.0032 - val_accuracy: 1.0000 - lr: 0.0010\nEpoch 5/1000\n1/1 [==============================] - 1s 517ms/step - loss: 0.0355 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - lr: 0.0010\nEpoch 6/1000\n1/1 [==============================] - 0s 371ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - lr: 0.0010\nEpoch 7/1000\n1/1 [==============================] - 0s 353ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - lr: 0.0010\nEpoch 8/1000\n1/1 [==============================] - 0s 351ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - lr: 0.0010\nEpoch 9/1000\n1/1 [==============================] - ETA: 0s - loss: 0.0031 - accuracy: 1.0000\nEpoch 9: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n1/1 [==============================] - 0s 362ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - lr: 0.0010\nEpoch 10/1000\n1/1 [==============================] - 0s 355ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - lr: 5.0000e-04\nEpoch 11/1000\n1/1 [==============================] - 0s 395ms/step - loss: 6.8561e-04 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - lr: 5.0000e-04\nEpoch 12/1000\n1/1 [==============================] - 0s 381ms/step - loss: 7.2360e-04 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - lr: 5.0000e-04\nEpoch 13/1000\n1/1 [==============================] - ETA: 0s - loss: 4.2742e-04 - accuracy: 1.0000Restoring model weights from the end of the best epoch: 5.\n\nEpoch 13: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n1/1 [==============================] - 1s 620ms/step - loss: 4.2742e-04 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - lr: 5.0000e-04\nEpoch 13: early stopping\n\n\n\n\n\n\nmodel.evaluate(test_x, test_y) ## [loss, accuracy]\n\n1/1 [==============================] - 1s 1s/step - loss: 0.0000e+00 - accuracy: 1.0000\n\n\n[0.0, 1.0]\n\n\n\ny_pred = model.predict(test_x)\ny_pred\n\n1/1 [==============================] - 1s 1s/step\n\n\narray([[2.1487143e-30, 4.1730422e-24, 1.0000000e+00],\n       [5.7259425e-10, 8.6654088e-09, 1.0000000e+00],\n       [8.9091756e-35, 1.0757881e-26, 1.0000000e+00],\n       [4.2603377e-15, 1.1493484e-10, 1.0000000e+00]], dtype=float32)\n\n\n\nto_names = { v:k for k,v in names.items() }\n\n\nfor i in range(len(test_x)) :\n    print('------------------------------------------------------')\n    print(f'실제 정답 : {to_names[test_y[i].argmax()]} vs 모델의 예측 : {to_names[y_pred[i].argmax()]} ')\n    prob = ''\n\n    for j in to_names :\n        string = f'{to_names[j]} : {y_pred[i][j]*100:.2f}%  '\n        prob = prob + string\n    print(prob)\n    plt.imshow(test_xv[i].reshape([299,299,3])/255)\n    plt.show()\n\n------------------------------------------------------\n실제 정답 : bleach vs 모델의 예측 : bleach \nopm : 0.00%  armstrong : 0.00%  bleach : 100.00%  \n------------------------------------------------------\n실제 정답 : bleach vs 모델의 예측 : bleach \nopm : 0.00%  armstrong : 0.00%  bleach : 100.00%  \n------------------------------------------------------\n실제 정답 : bleach vs 모델의 예측 : bleach \nopm : 0.00%  armstrong : 0.00%  bleach : 100.00%  \n------------------------------------------------------\n실제 정답 : bleach vs 모델의 예측 : bleach \nopm : 0.00%  armstrong : 0.00%  bleach : 100.00%"
  },
  {
    "objectID": "posts/image/2021-02-08-08. PretrainedModel_and_Tuning.html#library-loading",
    "href": "posts/image/2021-02-08-08. PretrainedModel_and_Tuning.html#library-loading",
    "title": "07. pretrained Model (2)",
    "section": "",
    "text": "import tensorflow as tf\nfrom tensorflow import keras\n\nfrom tensorflow.keras.applications.inception_v3 import InceptionV3\nfrom tensorflow.keras.applications.inception_v3 import preprocess_input\nfrom tensorflow.keras.applications.inception_v3 import decode_predictions\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.layers import GlobalAveragePooling2D, Dense\n\nfrom sklearn.model_selection import train_test_split\n\nimport random\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport glob"
  },
  {
    "objectID": "posts/image/2021-02-08-08. PretrainedModel_and_Tuning.html#connect-colaboratory-with-my-google-drive",
    "href": "posts/image/2021-02-08-08. PretrainedModel_and_Tuning.html#connect-colaboratory-with-my-google-drive",
    "title": "07. pretrained Model (2)",
    "section": "",
    "text": "from google.colab import drive\ndrive.mount('/content/drive')\n\nMounted at /content/drive\n\n\n\n!cd /content/drive/MyDrive/my_data/; ls\n\ndatasets  img1  model.png     my_mnist   MyPjt  transfer\nhandmade  img2  my_first_save.h5  my_mnist2  temp\n\n\n\n!cd /content/drive/MyDrive/my_data/transfer; ls\n\narmstrong  bleach  opm\n\n\n\nfiles = glob.glob('/content/drive/MyDrive/my_data/transfer/*/*')\nfiles\n\n['/content/drive/MyDrive/my_data/transfer/opm/3ba41ec9dad7c14601a4bd80bbb09940.jpg',\n '/content/drive/MyDrive/my_data/transfer/opm/images.png',\n '/content/drive/MyDrive/my_data/transfer/opm/saitama-of-one-punch-man-season-2.png',\n '/content/drive/MyDrive/my_data/transfer/opm/one-punch-man-saitama-punch-canvas-art-wrap-28064182532_1024x1024.jpg',\n '/content/drive/MyDrive/my_data/transfer/opm/One-Punch-Man-trama-e-recensione-696x385.jpg',\n '/content/drive/MyDrive/my_data/transfer/opm/kisspng-one-punch-man-youtube-saitama-desktop-wallpaper-one-punch-man-5ac57d8f9cb076.9914570015228921756418.jpg',\n '/content/drive/MyDrive/my_data/transfer/opm/User_184486_Profile_Picture_20180331-093841_44ab7971-cb01-41cd-aa91-6232dceea126.jpg',\n '/content/drive/MyDrive/my_data/transfer/opm/maxresdefault.jpg',\n '/content/drive/MyDrive/my_data/transfer/opm/images.jpg',\n '/content/drive/MyDrive/my_data/transfer/opm/다운로드 (1).jpg',\n '/content/drive/MyDrive/my_data/transfer/opm/one-punch-man_1545897445533.webp',\n '/content/drive/MyDrive/my_data/transfer/opm/https___blogs-images.forbes.com_olliebarder_files_2016_09_onepunchman_second-1200x675.jpg',\n '/content/drive/MyDrive/my_data/transfer/opm/images (1).jpg',\n '/content/drive/MyDrive/my_data/transfer/opm/다운로드.jpg',\n '/content/drive/MyDrive/my_data/transfer/opm/images (2).jpg',\n '/content/drive/MyDrive/my_data/transfer/opm/maxresdefault (1).jpg',\n '/content/drive/MyDrive/my_data/transfer/opm/images (3).jpg',\n '/content/drive/MyDrive/my_data/transfer/opm/images (4).jpg',\n '/content/drive/MyDrive/my_data/transfer/opm/unnamed.png',\n '/content/drive/MyDrive/my_data/transfer/opm/다sdfsdf운로드.jpg',\n '/content/drive/MyDrive/my_data/transfer/armstrong/1019499_1336092939744_full.jpg',\n '/content/drive/MyDrive/my_data/transfer/armstrong/2hfkwf8.jpg',\n '/content/drive/MyDrive/my_data/transfer/armstrong/15. 10. 30. - 1.jpg',\n '/content/drive/MyDrive/my_data/transfer/armstrong/Alex_Louis_Armstrong_28FMA29.jpg',\n '/content/drive/MyDrive/my_data/transfer/armstrong/Bc0tX7sCEAARqk9.jpg',\n '/content/drive/MyDrive/my_data/transfer/armstrong/b0005412_49d8ba1c6c1ca.jpg',\n '/content/drive/MyDrive/my_data/transfer/armstrong/G-Mgc5su_400x400.png',\n '/content/drive/MyDrive/my_data/transfer/armstrong/다운로드 (1).jpg',\n '/content/drive/MyDrive/my_data/transfer/armstrong/다운로드.jpg',\n '/content/drive/MyDrive/my_data/transfer/armstrong/Alex_Louis_Armstrong_(2009).jpg',\n '/content/drive/MyDrive/my_data/transfer/armstrong/full-metal-alchemist-character-recreated-in-dark-souls-3-and-its-not-alphonse-social.jpg',\n '/content/drive/MyDrive/my_data/transfer/armstrong/maxresdefault (1).jpg',\n '/content/drive/MyDrive/my_data/transfer/armstrong/maxresdefault.jpg',\n '/content/drive/MyDrive/my_data/transfer/armstrong/big_1471769576_image.jpg',\n '/content/drive/MyDrive/my_data/transfer/armstrong/4892072-4384090584-fma54.jpg',\n '/content/drive/MyDrive/my_data/transfer/armstrong/unnamed (1).jpg',\n '/content/drive/MyDrive/my_data/transfer/armstrong/images.jpg',\n '/content/drive/MyDrive/my_data/transfer/armstrong/다운로드 (2).jpg',\n '/content/drive/MyDrive/my_data/transfer/armstrong/OCq90KN8_400x400.jpg',\n '/content/drive/MyDrive/my_data/transfer/bleach/4607d2e7d52c8.jpg',\n '/content/drive/MyDrive/my_data/transfer/bleach/465bceabc9368.jpg',\n '/content/drive/MyDrive/my_data/transfer/bleach/31.jpg',\n '/content/drive/MyDrive/my_data/transfer/bleach/maxresdefault.jpg',\n '/content/drive/MyDrive/my_data/transfer/bleach/4I08cmY7_400x400.jpg',\n '/content/drive/MyDrive/my_data/transfer/bleach/img.chuing.jpg',\n '/content/drive/MyDrive/my_data/transfer/bleach/c2790d5985eae82cd1199a4cba2101c114662c2a02339b9a3d1b154712fe5e8d212ac61ad47c8d04c7ea0fba559817ff.png',\n '/content/drive/MyDrive/my_data/transfer/bleach/9285513a71e117418e70c5fa86a50126.jpeg',\n '/content/drive/MyDrive/my_data/transfer/bleach/BCKT_33CUAEurqj.jpg',\n '/content/drive/MyDrive/my_data/transfer/bleach/images.jpg',\n '/content/drive/MyDrive/my_data/transfer/bleach/Ikkaku-bleach-anime-20603578-1280-720.jpg',\n '/content/drive/MyDrive/my_data/transfer/bleach/720c5ff4df799c3cb6150a13cf8e0561.jpg',\n '/content/drive/MyDrive/my_data/transfer/bleach/Ikkaku_Madarame.png',\n '/content/drive/MyDrive/my_data/transfer/bleach/maxresdefault (1).jpg',\n '/content/drive/MyDrive/my_data/transfer/bleach/maxresdefault (2).jpg',\n '/content/drive/MyDrive/my_data/transfer/bleach/maxresdefault (3).jpg',\n '/content/drive/MyDrive/my_data/transfer/bleach/다운로드.jpg',\n '/content/drive/MyDrive/my_data/transfer/bleach/340717-ikkaku_madarame.jpg',\n '/content/drive/MyDrive/my_data/transfer/bleach/b8e72a67c122b896dea8e20c9c829dd8.jpg']\n\n\n\nname_cnt = {}\n\nfor x in files :\n    name_cnt[x.split('/')[-2]] = name_cnt.get(x.split('/')[-2], 0) + 1\n\nname_cnt\n\n{'opm': 20, 'armstrong': 19, 'bleach': 19}\n\n\n\ni = 0\nnames = {}\n\nfor key in name_cnt :\n    names[key] = i     # names_cnt의 key값에 새로운 값 부여\n    i += 1             # 클래스 수만큼 i값 증가\n\nnames\n\n{'opm': 0, 'armstrong': 1, 'bleach': 2}\n\n\n\nimages = []\nlabels = []\n\nfor path in files:\n    img = image.load_img(path, target_size=(299,299) )\n    img = image.img_to_array(img)\n\n    images.append(img)\n    labels.append(names[path.split('/')[-2]])\n\n    plt.imshow(image.load_img(path))\n    plt.show()\n\nimages_arr = np.array(images)\nlabels_arr = np.array(labels)\n\nprint(images_arr.shape)\nprint(labels_arr.shape)\n\nOutput hidden; open in https://colab.research.google.com to view.\n\n\n\nprint(labels_arr)\nlabel_v = len(np.unique(labels_arr))\nlabel_v\n\n[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n\n\n3\n\n\n\n### 라벨링\ny = to_categorical(labels, label_v)\n\n\nprint(y[:3])\ny.shape\n\n[[1. 0. 0.]\n [1. 0. 0.]\n [1. 0. 0.]]\n\n\n(58, 3)"
  },
  {
    "objectID": "posts/image/2021-02-08-08. PretrainedModel_and_Tuning.html#dataset-split",
    "href": "posts/image/2021-02-08-08. PretrainedModel_and_Tuning.html#dataset-split",
    "title": "07. pretrained Model (2)",
    "section": "",
    "text": "training set, validation set, test set 생성\n각 이미지 그룹별로 균등한 분할을 위하여. 아래 코드가 조금 복잡합니다.\n\n\ntemp = []\ninit_v = 0\n\nfor v in name_cnt.values() :\n    temp.append( (images[init_v:init_v+v], y[init_v:init_v+v]) )\n    init_v += v\n\n\nfor i in range(len(temp)) :\n    x_to_array = np.array(temp[i][0])\n    y_to_array = np.array(temp[i][1])\n\n    train_x, test_x, train_y, test_y =\\\n        train_test_split(x_to_array, y_to_array, test_size=0.2, random_state=2023)\n\n    train_x, valid_x, train_y, valid_y =\\\n        train_test_split(train_x, train_y, test_size=0.2, random_state=2023)\n\n    if i==0 :\n        first_tr_x, first_va_x, first_te_x = train_x.copy(), valid_x.copy(), test_x.copy()\n        first_tr_y, first_va_y, first_te_y = train_y.copy(), valid_y.copy(), test_y.copy()\n\n    elif i==1 :\n        new_tr_x, new_tr_y = np.vstack((first_tr_x, train_x)), np.vstack((first_tr_y, train_y))\n        new_va_x, new_va_y = np.vstack((first_va_x, valid_x)), np.vstack((first_va_y, valid_y))\n        new_te_x, new_te_y = np.vstack((first_te_x, test_x)), np.vstack((first_te_y, test_y))\n\n    else :\n        new_tr_x, new_tr_y = np.vstack((new_tr_x, train_x)), np.vstack((new_tr_y, train_y))\n        new_va_x, new_va_y = np.vstack((new_va_x, valid_x)), np.vstack((new_va_y, valid_y))\n        new_te_x, new_te_y = np.vstack((new_te_x, test_x)), np.vstack((new_te_y, test_y))\n\n\nnew_tr_x.shape, new_tr_y.shape, new_va_x.shape, new_va_y.shape, new_te_x.shape, new_te_y.shape\n\n((36, 299, 299, 3),\n (36, 3),\n (10, 299, 299, 3),\n (10, 3),\n (12, 299, 299, 3),\n (12, 3))\n\n\n\n# 전처리 하지 않은 파일 따로 시각화 해두기\ntrain_xv, valid_xv, test_xv = train_x.copy(), valid_x.copy(), test_x.copy()"
  },
  {
    "objectID": "posts/image/2021-02-08-08. PretrainedModel_and_Tuning.html#data-preprocessing",
    "href": "posts/image/2021-02-08-08. PretrainedModel_and_Tuning.html#data-preprocessing",
    "title": "07. pretrained Model (2)",
    "section": "",
    "text": "잘 만들어진 모델에서 제공하는 전처리 과정을 사용합니다.\n\n\nnew_tr_x.max(), new_tr_x.min()\n\n(255.0, 0.0)\n\n\n\nnew_tr_x = preprocess_input(new_tr_x)\nnew_va_x = preprocess_input(new_va_x)\nnew_te_x = preprocess_input(new_te_x)\n\n\nnew_tr_x.max(), new_tr_x.min()\n\n(1.0, -1.0)"
  },
  {
    "objectID": "posts/image/2021-02-08-08. PretrainedModel_and_Tuning.html#load-pretrained-model",
    "href": "posts/image/2021-02-08-08. PretrainedModel_and_Tuning.html#load-pretrained-model",
    "title": "07. pretrained Model (2)",
    "section": "",
    "text": "keras.backend.clear_session()\n\nbase_model = InceptionV3(weights='imagenet',       # ImageNet 데이터를 기반으로 미리 학습된 가중치 불러오기\n                         include_top=False,        # InceptionV3 모델의 아웃풋 레이어는 제외하고 불러오기\n                         input_shape= (299,299,3)) # 입력 데이터의 형태\n\nnew_output = GlobalAveragePooling2D()(base_model.output)\nnew_output = Dense(3, # class 3개   클래스 개수만큼 진행한다.\n                  activation = 'softmax')(new_output)\n\nmodel = keras.models.Model(base_model.inputs, new_output)\n\nmodel.summary()\n\nDownloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n87910968/87910968 [==============================] - 0s 0us/step\nModel: \"model\"\n__________________________________________________________________________________________________\n Layer (type)                Output Shape                 Param #   Connected to                  \n==================================================================================================\n input_1 (InputLayer)        [(None, 299, 299, 3)]        0         []                            \n                                                                                                  \n conv2d (Conv2D)             (None, 149, 149, 32)         864       ['input_1[0][0]']             \n                                                                                                  \n batch_normalization (Batch  (None, 149, 149, 32)         96        ['conv2d[0][0]']              \n Normalization)                                                                                   \n                                                                                                  \n activation (Activation)     (None, 149, 149, 32)         0         ['batch_normalization[0][0]'] \n                                                                                                  \n conv2d_1 (Conv2D)           (None, 147, 147, 32)         9216      ['activation[0][0]']          \n                                                                                                  \n batch_normalization_1 (Bat  (None, 147, 147, 32)         96        ['conv2d_1[0][0]']            \n chNormalization)                                                                                 \n                                                                                                  \n activation_1 (Activation)   (None, 147, 147, 32)         0         ['batch_normalization_1[0][0]'\n                                                                    ]                             \n                                                                                                  \n conv2d_2 (Conv2D)           (None, 147, 147, 64)         18432     ['activation_1[0][0]']        \n                                                                                                  \n batch_normalization_2 (Bat  (None, 147, 147, 64)         192       ['conv2d_2[0][0]']            \n chNormalization)                                                                                 \n                                                                                                  \n activation_2 (Activation)   (None, 147, 147, 64)         0         ['batch_normalization_2[0][0]'\n                                                                    ]                             \n                                                                                                  \n max_pooling2d (MaxPooling2  (None, 73, 73, 64)           0         ['activation_2[0][0]']        \n D)                                                                                               \n                                                                                                  \n conv2d_3 (Conv2D)           (None, 73, 73, 80)           5120      ['max_pooling2d[0][0]']       \n                                                                                                  \n batch_normalization_3 (Bat  (None, 73, 73, 80)           240       ['conv2d_3[0][0]']            \n chNormalization)                                                                                 \n                                                                                                  \n activation_3 (Activation)   (None, 73, 73, 80)           0         ['batch_normalization_3[0][0]'\n                                                                    ]                             \n                                                                                                  \n conv2d_4 (Conv2D)           (None, 71, 71, 192)          138240    ['activation_3[0][0]']        \n                                                                                                  \n batch_normalization_4 (Bat  (None, 71, 71, 192)          576       ['conv2d_4[0][0]']            \n chNormalization)                                                                                 \n                                                                                                  \n activation_4 (Activation)   (None, 71, 71, 192)          0         ['batch_normalization_4[0][0]'\n                                                                    ]                             \n                                                                                                  \n max_pooling2d_1 (MaxPoolin  (None, 35, 35, 192)          0         ['activation_4[0][0]']        \n g2D)                                                                                             \n                                                                                                  \n conv2d_8 (Conv2D)           (None, 35, 35, 64)           12288     ['max_pooling2d_1[0][0]']     \n                                                                                                  \n batch_normalization_8 (Bat  (None, 35, 35, 64)           192       ['conv2d_8[0][0]']            \n chNormalization)                                                                                 \n                                                                                                  \n activation_8 (Activation)   (None, 35, 35, 64)           0         ['batch_normalization_8[0][0]'\n                                                                    ]                             \n                                                                                                  \n conv2d_6 (Conv2D)           (None, 35, 35, 48)           9216      ['max_pooling2d_1[0][0]']     \n                                                                                                  \n conv2d_9 (Conv2D)           (None, 35, 35, 96)           55296     ['activation_8[0][0]']        \n                                                                                                  \n batch_normalization_6 (Bat  (None, 35, 35, 48)           144       ['conv2d_6[0][0]']            \n chNormalization)                                                                                 \n                                                                                                  \n batch_normalization_9 (Bat  (None, 35, 35, 96)           288       ['conv2d_9[0][0]']            \n chNormalization)                                                                                 \n                                                                                                  \n activation_6 (Activation)   (None, 35, 35, 48)           0         ['batch_normalization_6[0][0]'\n                                                                    ]                             \n                                                                                                  \n activation_9 (Activation)   (None, 35, 35, 96)           0         ['batch_normalization_9[0][0]'\n                                                                    ]                             \n                                                                                                  \n average_pooling2d (Average  (None, 35, 35, 192)          0         ['max_pooling2d_1[0][0]']     \n Pooling2D)                                                                                       \n                                                                                                  \n conv2d_5 (Conv2D)           (None, 35, 35, 64)           12288     ['max_pooling2d_1[0][0]']     \n                                                                                                  \n conv2d_7 (Conv2D)           (None, 35, 35, 64)           76800     ['activation_6[0][0]']        \n                                                                                                  \n conv2d_10 (Conv2D)          (None, 35, 35, 96)           82944     ['activation_9[0][0]']        \n                                                                                                  \n conv2d_11 (Conv2D)          (None, 35, 35, 32)           6144      ['average_pooling2d[0][0]']   \n                                                                                                  \n batch_normalization_5 (Bat  (None, 35, 35, 64)           192       ['conv2d_5[0][0]']            \n chNormalization)                                                                                 \n                                                                                                  \n batch_normalization_7 (Bat  (None, 35, 35, 64)           192       ['conv2d_7[0][0]']            \n chNormalization)                                                                                 \n                                                                                                  \n batch_normalization_10 (Ba  (None, 35, 35, 96)           288       ['conv2d_10[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n batch_normalization_11 (Ba  (None, 35, 35, 32)           96        ['conv2d_11[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n activation_5 (Activation)   (None, 35, 35, 64)           0         ['batch_normalization_5[0][0]'\n                                                                    ]                             \n                                                                                                  \n activation_7 (Activation)   (None, 35, 35, 64)           0         ['batch_normalization_7[0][0]'\n                                                                    ]                             \n                                                                                                  \n activation_10 (Activation)  (None, 35, 35, 96)           0         ['batch_normalization_10[0][0]\n                                                                    ']                            \n                                                                                                  \n activation_11 (Activation)  (None, 35, 35, 32)           0         ['batch_normalization_11[0][0]\n                                                                    ']                            \n                                                                                                  \n mixed0 (Concatenate)        (None, 35, 35, 256)          0         ['activation_5[0][0]',        \n                                                                     'activation_7[0][0]',        \n                                                                     'activation_10[0][0]',       \n                                                                     'activation_11[0][0]']       \n                                                                                                  \n conv2d_15 (Conv2D)          (None, 35, 35, 64)           16384     ['mixed0[0][0]']              \n                                                                                                  \n batch_normalization_15 (Ba  (None, 35, 35, 64)           192       ['conv2d_15[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n activation_15 (Activation)  (None, 35, 35, 64)           0         ['batch_normalization_15[0][0]\n                                                                    ']                            \n                                                                                                  \n conv2d_13 (Conv2D)          (None, 35, 35, 48)           12288     ['mixed0[0][0]']              \n                                                                                                  \n conv2d_16 (Conv2D)          (None, 35, 35, 96)           55296     ['activation_15[0][0]']       \n                                                                                                  \n batch_normalization_13 (Ba  (None, 35, 35, 48)           144       ['conv2d_13[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n batch_normalization_16 (Ba  (None, 35, 35, 96)           288       ['conv2d_16[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n activation_13 (Activation)  (None, 35, 35, 48)           0         ['batch_normalization_13[0][0]\n                                                                    ']                            \n                                                                                                  \n activation_16 (Activation)  (None, 35, 35, 96)           0         ['batch_normalization_16[0][0]\n                                                                    ']                            \n                                                                                                  \n average_pooling2d_1 (Avera  (None, 35, 35, 256)          0         ['mixed0[0][0]']              \n gePooling2D)                                                                                     \n                                                                                                  \n conv2d_12 (Conv2D)          (None, 35, 35, 64)           16384     ['mixed0[0][0]']              \n                                                                                                  \n conv2d_14 (Conv2D)          (None, 35, 35, 64)           76800     ['activation_13[0][0]']       \n                                                                                                  \n conv2d_17 (Conv2D)          (None, 35, 35, 96)           82944     ['activation_16[0][0]']       \n                                                                                                  \n conv2d_18 (Conv2D)          (None, 35, 35, 64)           16384     ['average_pooling2d_1[0][0]'] \n                                                                                                  \n batch_normalization_12 (Ba  (None, 35, 35, 64)           192       ['conv2d_12[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n batch_normalization_14 (Ba  (None, 35, 35, 64)           192       ['conv2d_14[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n batch_normalization_17 (Ba  (None, 35, 35, 96)           288       ['conv2d_17[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n batch_normalization_18 (Ba  (None, 35, 35, 64)           192       ['conv2d_18[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n activation_12 (Activation)  (None, 35, 35, 64)           0         ['batch_normalization_12[0][0]\n                                                                    ']                            \n                                                                                                  \n activation_14 (Activation)  (None, 35, 35, 64)           0         ['batch_normalization_14[0][0]\n                                                                    ']                            \n                                                                                                  \n activation_17 (Activation)  (None, 35, 35, 96)           0         ['batch_normalization_17[0][0]\n                                                                    ']                            \n                                                                                                  \n activation_18 (Activation)  (None, 35, 35, 64)           0         ['batch_normalization_18[0][0]\n                                                                    ']                            \n                                                                                                  \n mixed1 (Concatenate)        (None, 35, 35, 288)          0         ['activation_12[0][0]',       \n                                                                     'activation_14[0][0]',       \n                                                                     'activation_17[0][0]',       \n                                                                     'activation_18[0][0]']       \n                                                                                                  \n conv2d_22 (Conv2D)          (None, 35, 35, 64)           18432     ['mixed1[0][0]']              \n                                                                                                  \n batch_normalization_22 (Ba  (None, 35, 35, 64)           192       ['conv2d_22[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n activation_22 (Activation)  (None, 35, 35, 64)           0         ['batch_normalization_22[0][0]\n                                                                    ']                            \n                                                                                                  \n conv2d_20 (Conv2D)          (None, 35, 35, 48)           13824     ['mixed1[0][0]']              \n                                                                                                  \n conv2d_23 (Conv2D)          (None, 35, 35, 96)           55296     ['activation_22[0][0]']       \n                                                                                                  \n batch_normalization_20 (Ba  (None, 35, 35, 48)           144       ['conv2d_20[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n batch_normalization_23 (Ba  (None, 35, 35, 96)           288       ['conv2d_23[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n activation_20 (Activation)  (None, 35, 35, 48)           0         ['batch_normalization_20[0][0]\n                                                                    ']                            \n                                                                                                  \n activation_23 (Activation)  (None, 35, 35, 96)           0         ['batch_normalization_23[0][0]\n                                                                    ']                            \n                                                                                                  \n average_pooling2d_2 (Avera  (None, 35, 35, 288)          0         ['mixed1[0][0]']              \n gePooling2D)                                                                                     \n                                                                                                  \n conv2d_19 (Conv2D)          (None, 35, 35, 64)           18432     ['mixed1[0][0]']              \n                                                                                                  \n conv2d_21 (Conv2D)          (None, 35, 35, 64)           76800     ['activation_20[0][0]']       \n                                                                                                  \n conv2d_24 (Conv2D)          (None, 35, 35, 96)           82944     ['activation_23[0][0]']       \n                                                                                                  \n conv2d_25 (Conv2D)          (None, 35, 35, 64)           18432     ['average_pooling2d_2[0][0]'] \n                                                                                                  \n batch_normalization_19 (Ba  (None, 35, 35, 64)           192       ['conv2d_19[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n batch_normalization_21 (Ba  (None, 35, 35, 64)           192       ['conv2d_21[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n batch_normalization_24 (Ba  (None, 35, 35, 96)           288       ['conv2d_24[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n batch_normalization_25 (Ba  (None, 35, 35, 64)           192       ['conv2d_25[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n activation_19 (Activation)  (None, 35, 35, 64)           0         ['batch_normalization_19[0][0]\n                                                                    ']                            \n                                                                                                  \n activation_21 (Activation)  (None, 35, 35, 64)           0         ['batch_normalization_21[0][0]\n                                                                    ']                            \n                                                                                                  \n activation_24 (Activation)  (None, 35, 35, 96)           0         ['batch_normalization_24[0][0]\n                                                                    ']                            \n                                                                                                  \n activation_25 (Activation)  (None, 35, 35, 64)           0         ['batch_normalization_25[0][0]\n                                                                    ']                            \n                                                                                                  \n mixed2 (Concatenate)        (None, 35, 35, 288)          0         ['activation_19[0][0]',       \n                                                                     'activation_21[0][0]',       \n                                                                     'activation_24[0][0]',       \n                                                                     'activation_25[0][0]']       \n                                                                                                  \n conv2d_27 (Conv2D)          (None, 35, 35, 64)           18432     ['mixed2[0][0]']              \n                                                                                                  \n batch_normalization_27 (Ba  (None, 35, 35, 64)           192       ['conv2d_27[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n activation_27 (Activation)  (None, 35, 35, 64)           0         ['batch_normalization_27[0][0]\n                                                                    ']                            \n                                                                                                  \n conv2d_28 (Conv2D)          (None, 35, 35, 96)           55296     ['activation_27[0][0]']       \n                                                                                                  \n batch_normalization_28 (Ba  (None, 35, 35, 96)           288       ['conv2d_28[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n activation_28 (Activation)  (None, 35, 35, 96)           0         ['batch_normalization_28[0][0]\n                                                                    ']                            \n                                                                                                  \n conv2d_26 (Conv2D)          (None, 17, 17, 384)          995328    ['mixed2[0][0]']              \n                                                                                                  \n conv2d_29 (Conv2D)          (None, 17, 17, 96)           82944     ['activation_28[0][0]']       \n                                                                                                  \n batch_normalization_26 (Ba  (None, 17, 17, 384)          1152      ['conv2d_26[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n batch_normalization_29 (Ba  (None, 17, 17, 96)           288       ['conv2d_29[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n activation_26 (Activation)  (None, 17, 17, 384)          0         ['batch_normalization_26[0][0]\n                                                                    ']                            \n                                                                                                  \n activation_29 (Activation)  (None, 17, 17, 96)           0         ['batch_normalization_29[0][0]\n                                                                    ']                            \n                                                                                                  \n max_pooling2d_2 (MaxPoolin  (None, 17, 17, 288)          0         ['mixed2[0][0]']              \n g2D)                                                                                             \n                                                                                                  \n mixed3 (Concatenate)        (None, 17, 17, 768)          0         ['activation_26[0][0]',       \n                                                                     'activation_29[0][0]',       \n                                                                     'max_pooling2d_2[0][0]']     \n                                                                                                  \n conv2d_34 (Conv2D)          (None, 17, 17, 128)          98304     ['mixed3[0][0]']              \n                                                                                                  \n batch_normalization_34 (Ba  (None, 17, 17, 128)          384       ['conv2d_34[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n activation_34 (Activation)  (None, 17, 17, 128)          0         ['batch_normalization_34[0][0]\n                                                                    ']                            \n                                                                                                  \n conv2d_35 (Conv2D)          (None, 17, 17, 128)          114688    ['activation_34[0][0]']       \n                                                                                                  \n batch_normalization_35 (Ba  (None, 17, 17, 128)          384       ['conv2d_35[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n activation_35 (Activation)  (None, 17, 17, 128)          0         ['batch_normalization_35[0][0]\n                                                                    ']                            \n                                                                                                  \n conv2d_31 (Conv2D)          (None, 17, 17, 128)          98304     ['mixed3[0][0]']              \n                                                                                                  \n conv2d_36 (Conv2D)          (None, 17, 17, 128)          114688    ['activation_35[0][0]']       \n                                                                                                  \n batch_normalization_31 (Ba  (None, 17, 17, 128)          384       ['conv2d_31[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n batch_normalization_36 (Ba  (None, 17, 17, 128)          384       ['conv2d_36[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n activation_31 (Activation)  (None, 17, 17, 128)          0         ['batch_normalization_31[0][0]\n                                                                    ']                            \n                                                                                                  \n activation_36 (Activation)  (None, 17, 17, 128)          0         ['batch_normalization_36[0][0]\n                                                                    ']                            \n                                                                                                  \n conv2d_32 (Conv2D)          (None, 17, 17, 128)          114688    ['activation_31[0][0]']       \n                                                                                                  \n conv2d_37 (Conv2D)          (None, 17, 17, 128)          114688    ['activation_36[0][0]']       \n                                                                                                  \n batch_normalization_32 (Ba  (None, 17, 17, 128)          384       ['conv2d_32[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n batch_normalization_37 (Ba  (None, 17, 17, 128)          384       ['conv2d_37[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n activation_32 (Activation)  (None, 17, 17, 128)          0         ['batch_normalization_32[0][0]\n                                                                    ']                            \n                                                                                                  \n activation_37 (Activation)  (None, 17, 17, 128)          0         ['batch_normalization_37[0][0]\n                                                                    ']                            \n                                                                                                  \n average_pooling2d_3 (Avera  (None, 17, 17, 768)          0         ['mixed3[0][0]']              \n gePooling2D)                                                                                     \n                                                                                                  \n conv2d_30 (Conv2D)          (None, 17, 17, 192)          147456    ['mixed3[0][0]']              \n                                                                                                  \n conv2d_33 (Conv2D)          (None, 17, 17, 192)          172032    ['activation_32[0][0]']       \n                                                                                                  \n conv2d_38 (Conv2D)          (None, 17, 17, 192)          172032    ['activation_37[0][0]']       \n                                                                                                  \n conv2d_39 (Conv2D)          (None, 17, 17, 192)          147456    ['average_pooling2d_3[0][0]'] \n                                                                                                  \n batch_normalization_30 (Ba  (None, 17, 17, 192)          576       ['conv2d_30[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n batch_normalization_33 (Ba  (None, 17, 17, 192)          576       ['conv2d_33[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n batch_normalization_38 (Ba  (None, 17, 17, 192)          576       ['conv2d_38[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n batch_normalization_39 (Ba  (None, 17, 17, 192)          576       ['conv2d_39[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n activation_30 (Activation)  (None, 17, 17, 192)          0         ['batch_normalization_30[0][0]\n                                                                    ']                            \n                                                                                                  \n activation_33 (Activation)  (None, 17, 17, 192)          0         ['batch_normalization_33[0][0]\n                                                                    ']                            \n                                                                                                  \n activation_38 (Activation)  (None, 17, 17, 192)          0         ['batch_normalization_38[0][0]\n                                                                    ']                            \n                                                                                                  \n activation_39 (Activation)  (None, 17, 17, 192)          0         ['batch_normalization_39[0][0]\n                                                                    ']                            \n                                                                                                  \n mixed4 (Concatenate)        (None, 17, 17, 768)          0         ['activation_30[0][0]',       \n                                                                     'activation_33[0][0]',       \n                                                                     'activation_38[0][0]',       \n                                                                     'activation_39[0][0]']       \n                                                                                                  \n conv2d_44 (Conv2D)          (None, 17, 17, 160)          122880    ['mixed4[0][0]']              \n                                                                                                  \n batch_normalization_44 (Ba  (None, 17, 17, 160)          480       ['conv2d_44[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n activation_44 (Activation)  (None, 17, 17, 160)          0         ['batch_normalization_44[0][0]\n                                                                    ']                            \n                                                                                                  \n conv2d_45 (Conv2D)          (None, 17, 17, 160)          179200    ['activation_44[0][0]']       \n                                                                                                  \n batch_normalization_45 (Ba  (None, 17, 17, 160)          480       ['conv2d_45[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n activation_45 (Activation)  (None, 17, 17, 160)          0         ['batch_normalization_45[0][0]\n                                                                    ']                            \n                                                                                                  \n conv2d_41 (Conv2D)          (None, 17, 17, 160)          122880    ['mixed4[0][0]']              \n                                                                                                  \n conv2d_46 (Conv2D)          (None, 17, 17, 160)          179200    ['activation_45[0][0]']       \n                                                                                                  \n batch_normalization_41 (Ba  (None, 17, 17, 160)          480       ['conv2d_41[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n batch_normalization_46 (Ba  (None, 17, 17, 160)          480       ['conv2d_46[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n activation_41 (Activation)  (None, 17, 17, 160)          0         ['batch_normalization_41[0][0]\n                                                                    ']                            \n                                                                                                  \n activation_46 (Activation)  (None, 17, 17, 160)          0         ['batch_normalization_46[0][0]\n                                                                    ']                            \n                                                                                                  \n conv2d_42 (Conv2D)          (None, 17, 17, 160)          179200    ['activation_41[0][0]']       \n                                                                                                  \n conv2d_47 (Conv2D)          (None, 17, 17, 160)          179200    ['activation_46[0][0]']       \n                                                                                                  \n batch_normalization_42 (Ba  (None, 17, 17, 160)          480       ['conv2d_42[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n batch_normalization_47 (Ba  (None, 17, 17, 160)          480       ['conv2d_47[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n activation_42 (Activation)  (None, 17, 17, 160)          0         ['batch_normalization_42[0][0]\n                                                                    ']                            \n                                                                                                  \n activation_47 (Activation)  (None, 17, 17, 160)          0         ['batch_normalization_47[0][0]\n                                                                    ']                            \n                                                                                                  \n average_pooling2d_4 (Avera  (None, 17, 17, 768)          0         ['mixed4[0][0]']              \n gePooling2D)                                                                                     \n                                                                                                  \n conv2d_40 (Conv2D)          (None, 17, 17, 192)          147456    ['mixed4[0][0]']              \n                                                                                                  \n conv2d_43 (Conv2D)          (None, 17, 17, 192)          215040    ['activation_42[0][0]']       \n                                                                                                  \n conv2d_48 (Conv2D)          (None, 17, 17, 192)          215040    ['activation_47[0][0]']       \n                                                                                                  \n conv2d_49 (Conv2D)          (None, 17, 17, 192)          147456    ['average_pooling2d_4[0][0]'] \n                                                                                                  \n batch_normalization_40 (Ba  (None, 17, 17, 192)          576       ['conv2d_40[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n batch_normalization_43 (Ba  (None, 17, 17, 192)          576       ['conv2d_43[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n batch_normalization_48 (Ba  (None, 17, 17, 192)          576       ['conv2d_48[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n batch_normalization_49 (Ba  (None, 17, 17, 192)          576       ['conv2d_49[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n activation_40 (Activation)  (None, 17, 17, 192)          0         ['batch_normalization_40[0][0]\n                                                                    ']                            \n                                                                                                  \n activation_43 (Activation)  (None, 17, 17, 192)          0         ['batch_normalization_43[0][0]\n                                                                    ']                            \n                                                                                                  \n activation_48 (Activation)  (None, 17, 17, 192)          0         ['batch_normalization_48[0][0]\n                                                                    ']                            \n                                                                                                  \n activation_49 (Activation)  (None, 17, 17, 192)          0         ['batch_normalization_49[0][0]\n                                                                    ']                            \n                                                                                                  \n mixed5 (Concatenate)        (None, 17, 17, 768)          0         ['activation_40[0][0]',       \n                                                                     'activation_43[0][0]',       \n                                                                     'activation_48[0][0]',       \n                                                                     'activation_49[0][0]']       \n                                                                                                  \n conv2d_54 (Conv2D)          (None, 17, 17, 160)          122880    ['mixed5[0][0]']              \n                                                                                                  \n batch_normalization_54 (Ba  (None, 17, 17, 160)          480       ['conv2d_54[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n activation_54 (Activation)  (None, 17, 17, 160)          0         ['batch_normalization_54[0][0]\n                                                                    ']                            \n                                                                                                  \n conv2d_55 (Conv2D)          (None, 17, 17, 160)          179200    ['activation_54[0][0]']       \n                                                                                                  \n batch_normalization_55 (Ba  (None, 17, 17, 160)          480       ['conv2d_55[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n activation_55 (Activation)  (None, 17, 17, 160)          0         ['batch_normalization_55[0][0]\n                                                                    ']                            \n                                                                                                  \n conv2d_51 (Conv2D)          (None, 17, 17, 160)          122880    ['mixed5[0][0]']              \n                                                                                                  \n conv2d_56 (Conv2D)          (None, 17, 17, 160)          179200    ['activation_55[0][0]']       \n                                                                                                  \n batch_normalization_51 (Ba  (None, 17, 17, 160)          480       ['conv2d_51[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n batch_normalization_56 (Ba  (None, 17, 17, 160)          480       ['conv2d_56[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n activation_51 (Activation)  (None, 17, 17, 160)          0         ['batch_normalization_51[0][0]\n                                                                    ']                            \n                                                                                                  \n activation_56 (Activation)  (None, 17, 17, 160)          0         ['batch_normalization_56[0][0]\n                                                                    ']                            \n                                                                                                  \n conv2d_52 (Conv2D)          (None, 17, 17, 160)          179200    ['activation_51[0][0]']       \n                                                                                                  \n conv2d_57 (Conv2D)          (None, 17, 17, 160)          179200    ['activation_56[0][0]']       \n                                                                                                  \n batch_normalization_52 (Ba  (None, 17, 17, 160)          480       ['conv2d_52[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n batch_normalization_57 (Ba  (None, 17, 17, 160)          480       ['conv2d_57[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n activation_52 (Activation)  (None, 17, 17, 160)          0         ['batch_normalization_52[0][0]\n                                                                    ']                            \n                                                                                                  \n activation_57 (Activation)  (None, 17, 17, 160)          0         ['batch_normalization_57[0][0]\n                                                                    ']                            \n                                                                                                  \n average_pooling2d_5 (Avera  (None, 17, 17, 768)          0         ['mixed5[0][0]']              \n gePooling2D)                                                                                     \n                                                                                                  \n conv2d_50 (Conv2D)          (None, 17, 17, 192)          147456    ['mixed5[0][0]']              \n                                                                                                  \n conv2d_53 (Conv2D)          (None, 17, 17, 192)          215040    ['activation_52[0][0]']       \n                                                                                                  \n conv2d_58 (Conv2D)          (None, 17, 17, 192)          215040    ['activation_57[0][0]']       \n                                                                                                  \n conv2d_59 (Conv2D)          (None, 17, 17, 192)          147456    ['average_pooling2d_5[0][0]'] \n                                                                                                  \n batch_normalization_50 (Ba  (None, 17, 17, 192)          576       ['conv2d_50[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n batch_normalization_53 (Ba  (None, 17, 17, 192)          576       ['conv2d_53[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n batch_normalization_58 (Ba  (None, 17, 17, 192)          576       ['conv2d_58[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n batch_normalization_59 (Ba  (None, 17, 17, 192)          576       ['conv2d_59[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n activation_50 (Activation)  (None, 17, 17, 192)          0         ['batch_normalization_50[0][0]\n                                                                    ']                            \n                                                                                                  \n activation_53 (Activation)  (None, 17, 17, 192)          0         ['batch_normalization_53[0][0]\n                                                                    ']                            \n                                                                                                  \n activation_58 (Activation)  (None, 17, 17, 192)          0         ['batch_normalization_58[0][0]\n                                                                    ']                            \n                                                                                                  \n activation_59 (Activation)  (None, 17, 17, 192)          0         ['batch_normalization_59[0][0]\n                                                                    ']                            \n                                                                                                  \n mixed6 (Concatenate)        (None, 17, 17, 768)          0         ['activation_50[0][0]',       \n                                                                     'activation_53[0][0]',       \n                                                                     'activation_58[0][0]',       \n                                                                     'activation_59[0][0]']       \n                                                                                                  \n conv2d_64 (Conv2D)          (None, 17, 17, 192)          147456    ['mixed6[0][0]']              \n                                                                                                  \n batch_normalization_64 (Ba  (None, 17, 17, 192)          576       ['conv2d_64[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n activation_64 (Activation)  (None, 17, 17, 192)          0         ['batch_normalization_64[0][0]\n                                                                    ']                            \n                                                                                                  \n conv2d_65 (Conv2D)          (None, 17, 17, 192)          258048    ['activation_64[0][0]']       \n                                                                                                  \n batch_normalization_65 (Ba  (None, 17, 17, 192)          576       ['conv2d_65[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n activation_65 (Activation)  (None, 17, 17, 192)          0         ['batch_normalization_65[0][0]\n                                                                    ']                            \n                                                                                                  \n conv2d_61 (Conv2D)          (None, 17, 17, 192)          147456    ['mixed6[0][0]']              \n                                                                                                  \n conv2d_66 (Conv2D)          (None, 17, 17, 192)          258048    ['activation_65[0][0]']       \n                                                                                                  \n batch_normalization_61 (Ba  (None, 17, 17, 192)          576       ['conv2d_61[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n batch_normalization_66 (Ba  (None, 17, 17, 192)          576       ['conv2d_66[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n activation_61 (Activation)  (None, 17, 17, 192)          0         ['batch_normalization_61[0][0]\n                                                                    ']                            \n                                                                                                  \n activation_66 (Activation)  (None, 17, 17, 192)          0         ['batch_normalization_66[0][0]\n                                                                    ']                            \n                                                                                                  \n conv2d_62 (Conv2D)          (None, 17, 17, 192)          258048    ['activation_61[0][0]']       \n                                                                                                  \n conv2d_67 (Conv2D)          (None, 17, 17, 192)          258048    ['activation_66[0][0]']       \n                                                                                                  \n batch_normalization_62 (Ba  (None, 17, 17, 192)          576       ['conv2d_62[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n batch_normalization_67 (Ba  (None, 17, 17, 192)          576       ['conv2d_67[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n activation_62 (Activation)  (None, 17, 17, 192)          0         ['batch_normalization_62[0][0]\n                                                                    ']                            \n                                                                                                  \n activation_67 (Activation)  (None, 17, 17, 192)          0         ['batch_normalization_67[0][0]\n                                                                    ']                            \n                                                                                                  \n average_pooling2d_6 (Avera  (None, 17, 17, 768)          0         ['mixed6[0][0]']              \n gePooling2D)                                                                                     \n                                                                                                  \n conv2d_60 (Conv2D)          (None, 17, 17, 192)          147456    ['mixed6[0][0]']              \n                                                                                                  \n conv2d_63 (Conv2D)          (None, 17, 17, 192)          258048    ['activation_62[0][0]']       \n                                                                                                  \n conv2d_68 (Conv2D)          (None, 17, 17, 192)          258048    ['activation_67[0][0]']       \n                                                                                                  \n conv2d_69 (Conv2D)          (None, 17, 17, 192)          147456    ['average_pooling2d_6[0][0]'] \n                                                                                                  \n batch_normalization_60 (Ba  (None, 17, 17, 192)          576       ['conv2d_60[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n batch_normalization_63 (Ba  (None, 17, 17, 192)          576       ['conv2d_63[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n batch_normalization_68 (Ba  (None, 17, 17, 192)          576       ['conv2d_68[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n batch_normalization_69 (Ba  (None, 17, 17, 192)          576       ['conv2d_69[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n activation_60 (Activation)  (None, 17, 17, 192)          0         ['batch_normalization_60[0][0]\n                                                                    ']                            \n                                                                                                  \n activation_63 (Activation)  (None, 17, 17, 192)          0         ['batch_normalization_63[0][0]\n                                                                    ']                            \n                                                                                                  \n activation_68 (Activation)  (None, 17, 17, 192)          0         ['batch_normalization_68[0][0]\n                                                                    ']                            \n                                                                                                  \n activation_69 (Activation)  (None, 17, 17, 192)          0         ['batch_normalization_69[0][0]\n                                                                    ']                            \n                                                                                                  \n mixed7 (Concatenate)        (None, 17, 17, 768)          0         ['activation_60[0][0]',       \n                                                                     'activation_63[0][0]',       \n                                                                     'activation_68[0][0]',       \n                                                                     'activation_69[0][0]']       \n                                                                                                  \n conv2d_72 (Conv2D)          (None, 17, 17, 192)          147456    ['mixed7[0][0]']              \n                                                                                                  \n batch_normalization_72 (Ba  (None, 17, 17, 192)          576       ['conv2d_72[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n activation_72 (Activation)  (None, 17, 17, 192)          0         ['batch_normalization_72[0][0]\n                                                                    ']                            \n                                                                                                  \n conv2d_73 (Conv2D)          (None, 17, 17, 192)          258048    ['activation_72[0][0]']       \n                                                                                                  \n batch_normalization_73 (Ba  (None, 17, 17, 192)          576       ['conv2d_73[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n activation_73 (Activation)  (None, 17, 17, 192)          0         ['batch_normalization_73[0][0]\n                                                                    ']                            \n                                                                                                  \n conv2d_70 (Conv2D)          (None, 17, 17, 192)          147456    ['mixed7[0][0]']              \n                                                                                                  \n conv2d_74 (Conv2D)          (None, 17, 17, 192)          258048    ['activation_73[0][0]']       \n                                                                                                  \n batch_normalization_70 (Ba  (None, 17, 17, 192)          576       ['conv2d_70[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n batch_normalization_74 (Ba  (None, 17, 17, 192)          576       ['conv2d_74[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n activation_70 (Activation)  (None, 17, 17, 192)          0         ['batch_normalization_70[0][0]\n                                                                    ']                            \n                                                                                                  \n activation_74 (Activation)  (None, 17, 17, 192)          0         ['batch_normalization_74[0][0]\n                                                                    ']                            \n                                                                                                  \n conv2d_71 (Conv2D)          (None, 8, 8, 320)            552960    ['activation_70[0][0]']       \n                                                                                                  \n conv2d_75 (Conv2D)          (None, 8, 8, 192)            331776    ['activation_74[0][0]']       \n                                                                                                  \n batch_normalization_71 (Ba  (None, 8, 8, 320)            960       ['conv2d_71[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n batch_normalization_75 (Ba  (None, 8, 8, 192)            576       ['conv2d_75[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n activation_71 (Activation)  (None, 8, 8, 320)            0         ['batch_normalization_71[0][0]\n                                                                    ']                            \n                                                                                                  \n activation_75 (Activation)  (None, 8, 8, 192)            0         ['batch_normalization_75[0][0]\n                                                                    ']                            \n                                                                                                  \n max_pooling2d_3 (MaxPoolin  (None, 8, 8, 768)            0         ['mixed7[0][0]']              \n g2D)                                                                                             \n                                                                                                  \n mixed8 (Concatenate)        (None, 8, 8, 1280)           0         ['activation_71[0][0]',       \n                                                                     'activation_75[0][0]',       \n                                                                     'max_pooling2d_3[0][0]']     \n                                                                                                  \n conv2d_80 (Conv2D)          (None, 8, 8, 448)            573440    ['mixed8[0][0]']              \n                                                                                                  \n batch_normalization_80 (Ba  (None, 8, 8, 448)            1344      ['conv2d_80[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n activation_80 (Activation)  (None, 8, 8, 448)            0         ['batch_normalization_80[0][0]\n                                                                    ']                            \n                                                                                                  \n conv2d_77 (Conv2D)          (None, 8, 8, 384)            491520    ['mixed8[0][0]']              \n                                                                                                  \n conv2d_81 (Conv2D)          (None, 8, 8, 384)            1548288   ['activation_80[0][0]']       \n                                                                                                  \n batch_normalization_77 (Ba  (None, 8, 8, 384)            1152      ['conv2d_77[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n batch_normalization_81 (Ba  (None, 8, 8, 384)            1152      ['conv2d_81[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n activation_77 (Activation)  (None, 8, 8, 384)            0         ['batch_normalization_77[0][0]\n                                                                    ']                            \n                                                                                                  \n activation_81 (Activation)  (None, 8, 8, 384)            0         ['batch_normalization_81[0][0]\n                                                                    ']                            \n                                                                                                  \n conv2d_78 (Conv2D)          (None, 8, 8, 384)            442368    ['activation_77[0][0]']       \n                                                                                                  \n conv2d_79 (Conv2D)          (None, 8, 8, 384)            442368    ['activation_77[0][0]']       \n                                                                                                  \n conv2d_82 (Conv2D)          (None, 8, 8, 384)            442368    ['activation_81[0][0]']       \n                                                                                                  \n conv2d_83 (Conv2D)          (None, 8, 8, 384)            442368    ['activation_81[0][0]']       \n                                                                                                  \n average_pooling2d_7 (Avera  (None, 8, 8, 1280)           0         ['mixed8[0][0]']              \n gePooling2D)                                                                                     \n                                                                                                  \n conv2d_76 (Conv2D)          (None, 8, 8, 320)            409600    ['mixed8[0][0]']              \n                                                                                                  \n batch_normalization_78 (Ba  (None, 8, 8, 384)            1152      ['conv2d_78[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n batch_normalization_79 (Ba  (None, 8, 8, 384)            1152      ['conv2d_79[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n batch_normalization_82 (Ba  (None, 8, 8, 384)            1152      ['conv2d_82[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n batch_normalization_83 (Ba  (None, 8, 8, 384)            1152      ['conv2d_83[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n conv2d_84 (Conv2D)          (None, 8, 8, 192)            245760    ['average_pooling2d_7[0][0]'] \n                                                                                                  \n batch_normalization_76 (Ba  (None, 8, 8, 320)            960       ['conv2d_76[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n activation_78 (Activation)  (None, 8, 8, 384)            0         ['batch_normalization_78[0][0]\n                                                                    ']                            \n                                                                                                  \n activation_79 (Activation)  (None, 8, 8, 384)            0         ['batch_normalization_79[0][0]\n                                                                    ']                            \n                                                                                                  \n activation_82 (Activation)  (None, 8, 8, 384)            0         ['batch_normalization_82[0][0]\n                                                                    ']                            \n                                                                                                  \n activation_83 (Activation)  (None, 8, 8, 384)            0         ['batch_normalization_83[0][0]\n                                                                    ']                            \n                                                                                                  \n batch_normalization_84 (Ba  (None, 8, 8, 192)            576       ['conv2d_84[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n activation_76 (Activation)  (None, 8, 8, 320)            0         ['batch_normalization_76[0][0]\n                                                                    ']                            \n                                                                                                  \n mixed9_0 (Concatenate)      (None, 8, 8, 768)            0         ['activation_78[0][0]',       \n                                                                     'activation_79[0][0]']       \n                                                                                                  \n concatenate (Concatenate)   (None, 8, 8, 768)            0         ['activation_82[0][0]',       \n                                                                     'activation_83[0][0]']       \n                                                                                                  \n activation_84 (Activation)  (None, 8, 8, 192)            0         ['batch_normalization_84[0][0]\n                                                                    ']                            \n                                                                                                  \n mixed9 (Concatenate)        (None, 8, 8, 2048)           0         ['activation_76[0][0]',       \n                                                                     'mixed9_0[0][0]',            \n                                                                     'concatenate[0][0]',         \n                                                                     'activation_84[0][0]']       \n                                                                                                  \n conv2d_89 (Conv2D)          (None, 8, 8, 448)            917504    ['mixed9[0][0]']              \n                                                                                                  \n batch_normalization_89 (Ba  (None, 8, 8, 448)            1344      ['conv2d_89[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n activation_89 (Activation)  (None, 8, 8, 448)            0         ['batch_normalization_89[0][0]\n                                                                    ']                            \n                                                                                                  \n conv2d_86 (Conv2D)          (None, 8, 8, 384)            786432    ['mixed9[0][0]']              \n                                                                                                  \n conv2d_90 (Conv2D)          (None, 8, 8, 384)            1548288   ['activation_89[0][0]']       \n                                                                                                  \n batch_normalization_86 (Ba  (None, 8, 8, 384)            1152      ['conv2d_86[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n batch_normalization_90 (Ba  (None, 8, 8, 384)            1152      ['conv2d_90[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n activation_86 (Activation)  (None, 8, 8, 384)            0         ['batch_normalization_86[0][0]\n                                                                    ']                            \n                                                                                                  \n activation_90 (Activation)  (None, 8, 8, 384)            0         ['batch_normalization_90[0][0]\n                                                                    ']                            \n                                                                                                  \n conv2d_87 (Conv2D)          (None, 8, 8, 384)            442368    ['activation_86[0][0]']       \n                                                                                                  \n conv2d_88 (Conv2D)          (None, 8, 8, 384)            442368    ['activation_86[0][0]']       \n                                                                                                  \n conv2d_91 (Conv2D)          (None, 8, 8, 384)            442368    ['activation_90[0][0]']       \n                                                                                                  \n conv2d_92 (Conv2D)          (None, 8, 8, 384)            442368    ['activation_90[0][0]']       \n                                                                                                  \n average_pooling2d_8 (Avera  (None, 8, 8, 2048)           0         ['mixed9[0][0]']              \n gePooling2D)                                                                                     \n                                                                                                  \n conv2d_85 (Conv2D)          (None, 8, 8, 320)            655360    ['mixed9[0][0]']              \n                                                                                                  \n batch_normalization_87 (Ba  (None, 8, 8, 384)            1152      ['conv2d_87[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n batch_normalization_88 (Ba  (None, 8, 8, 384)            1152      ['conv2d_88[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n batch_normalization_91 (Ba  (None, 8, 8, 384)            1152      ['conv2d_91[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n batch_normalization_92 (Ba  (None, 8, 8, 384)            1152      ['conv2d_92[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n conv2d_93 (Conv2D)          (None, 8, 8, 192)            393216    ['average_pooling2d_8[0][0]'] \n                                                                                                  \n batch_normalization_85 (Ba  (None, 8, 8, 320)            960       ['conv2d_85[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n activation_87 (Activation)  (None, 8, 8, 384)            0         ['batch_normalization_87[0][0]\n                                                                    ']                            \n                                                                                                  \n activation_88 (Activation)  (None, 8, 8, 384)            0         ['batch_normalization_88[0][0]\n                                                                    ']                            \n                                                                                                  \n activation_91 (Activation)  (None, 8, 8, 384)            0         ['batch_normalization_91[0][0]\n                                                                    ']                            \n                                                                                                  \n activation_92 (Activation)  (None, 8, 8, 384)            0         ['batch_normalization_92[0][0]\n                                                                    ']                            \n                                                                                                  \n batch_normalization_93 (Ba  (None, 8, 8, 192)            576       ['conv2d_93[0][0]']           \n tchNormalization)                                                                                \n                                                                                                  \n activation_85 (Activation)  (None, 8, 8, 320)            0         ['batch_normalization_85[0][0]\n                                                                    ']                            \n                                                                                                  \n mixed9_1 (Concatenate)      (None, 8, 8, 768)            0         ['activation_87[0][0]',       \n                                                                     'activation_88[0][0]']       \n                                                                                                  \n concatenate_1 (Concatenate  (None, 8, 8, 768)            0         ['activation_91[0][0]',       \n )                                                                   'activation_92[0][0]']       \n                                                                                                  \n activation_93 (Activation)  (None, 8, 8, 192)            0         ['batch_normalization_93[0][0]\n                                                                    ']                            \n                                                                                                  \n mixed10 (Concatenate)       (None, 8, 8, 2048)           0         ['activation_85[0][0]',       \n                                                                     'mixed9_1[0][0]',            \n                                                                     'concatenate_1[0][0]',       \n                                                                     'activation_93[0][0]']       \n                                                                                                  \n global_average_pooling2d (  (None, 2048)                 0         ['mixed10[0][0]']             \n GlobalAveragePooling2D)                                                                          \n                                                                                                  \n dense (Dense)               (None, 3)                    6147      ['global_average_pooling2d[0][\n                                                                    0]']                          \n                                                                                                  \n==================================================================================================\nTotal params: 21808931 (83.19 MB)\nTrainable params: 21774499 (83.06 MB)\nNon-trainable params: 34432 (134.50 KB)\n__________________________________________________________________________________________________\n\n\n\nfrom tensorflow.keras.utils import plot_model\n\n\nplot_model(model, show_shapes=True, show_layer_names=True)\n\nOutput hidden; open in https://colab.research.google.com to view.\n\n\n\nprint(f'모델의 레이어 수 : {len(model.layers)}')\n\n모델의 레이어 수 : 313"
  },
  {
    "objectID": "posts/image/2021-02-08-08. PretrainedModel_and_Tuning.html#fine-tuning",
    "href": "posts/image/2021-02-08-08. PretrainedModel_and_Tuning.html#fine-tuning",
    "title": "07. pretrained Model (2)",
    "section": "",
    "text": "모델의 가중치를 그대로 사용할 레이어와 추가 학습할 레이어를 결정합니다.\n\n\nmodel.layers\n\n\nfor idx, layer in enumerate(model.layers) :\n    if idx &lt; 213 :\n        layer.trainable = False\n    else :\n        layer.trainable = True\n\n\n# 처음부터 학습시키는 것도 아니고,\n# 마지막 100개의 레이어만 튜닝 할 것이므로 learning rate를 조금 크게 잡아본다.\n\nmodel.compile(loss='categorical_crossentropy', metrics=['accuracy'],\n             optimizer=keras.optimizers.Adam(learning_rate=0.001) )"
  },
  {
    "objectID": "posts/image/2021-02-08-08. PretrainedModel_and_Tuning.html#image-data-augmentation-callbacks",
    "href": "posts/image/2021-02-08-08. PretrainedModel_and_Tuning.html#image-data-augmentation-callbacks",
    "title": "07. pretrained Model (2)",
    "section": "",
    "text": "lr_reduction = ReduceLROnPlateau(monitor='val_loss',\n                                 patience=4,\n                                 verbose=1,\n                                 factor=0.5,\n                                 min_lr=0.000001)\n\nes = EarlyStopping(monitor='val_loss',\n                   min_delta=0, # 개선되고 있다고 판단하기 위한 최소 변화량\n                   patience=8,  # 개선 없는 epoch 얼마나 기달려 줄거야\n                   verbose=1,\n                   restore_best_weights=True)\n\n\ntrainIDG = ImageDataGenerator(\n    featurewise_center=False,  # set input mean to 0 over the dataset\n    samplewise_center=False,  # set each sample mean to 0\n    featurewise_std_normalization=False,  # divide inputs by std of the dataset\n    samplewise_std_normalization=False,  # divide each input by its std\n    zca_whitening=False,  # apply ZCA whitening\n    rotation_range=180, # randomly rotate images in the range (degrees, 0 to 180)\n    zoom_range = 0.3, # Randomly zoom image\n    width_shift_range=0.3,  # randomly shift images horizontally (fraction of total width)\n    height_shift_range=0.3,  # randomly shift images vertically (fraction of total height)\n    horizontal_flip=True,  # randomly flip images\n    vertical_flip=True)  # randomly flip images\n\nvalidIDG = ImageDataGenerator()\n\n\ntrainIDG.fit(train_x)\nvalidIDG.fit(valid_x)\n\n\nflow_trainIDG = trainIDG.flow(train_x, train_y)\nflow_validIDG = validIDG.flow(valid_x, valid_y)"
  },
  {
    "objectID": "posts/image/2021-02-08-08. PretrainedModel_and_Tuning.html#fit",
    "href": "posts/image/2021-02-08-08. PretrainedModel_and_Tuning.html#fit",
    "title": "07. pretrained Model (2)",
    "section": "",
    "text": "# 데이터를 넣어서 학습시키자!\nhist = model.fit(flow_trainIDG, validation_data=flow_validIDG,\n                 epochs=1000, verbose=1,\n                 callbacks=[es, lr_reduction]\n                 )\n\nEpoch 1/1000\n1/1 [==============================] - 31s 31s/step - loss: 0.9249 - accuracy: 0.7500 - val_loss: 14.0317 - val_accuracy: 0.0000e+00 - lr: 0.0010\nEpoch 2/1000\n1/1 [==============================] - 1s 602ms/step - loss: 0.5820 - accuracy: 0.7500 - val_loss: 0.0033 - val_accuracy: 1.0000 - lr: 0.0010\nEpoch 3/1000\n1/1 [==============================] - 1s 523ms/step - loss: 0.1278 - accuracy: 1.0000 - val_loss: 0.0026 - val_accuracy: 1.0000 - lr: 0.0010\nEpoch 4/1000\n1/1 [==============================] - 0s 422ms/step - loss: 0.0316 - accuracy: 1.0000 - val_loss: 0.0032 - val_accuracy: 1.0000 - lr: 0.0010\nEpoch 5/1000\n1/1 [==============================] - 1s 517ms/step - loss: 0.0355 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - lr: 0.0010\nEpoch 6/1000\n1/1 [==============================] - 0s 371ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - lr: 0.0010\nEpoch 7/1000\n1/1 [==============================] - 0s 353ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - lr: 0.0010\nEpoch 8/1000\n1/1 [==============================] - 0s 351ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - lr: 0.0010\nEpoch 9/1000\n1/1 [==============================] - ETA: 0s - loss: 0.0031 - accuracy: 1.0000\nEpoch 9: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n1/1 [==============================] - 0s 362ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - lr: 0.0010\nEpoch 10/1000\n1/1 [==============================] - 0s 355ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - lr: 5.0000e-04\nEpoch 11/1000\n1/1 [==============================] - 0s 395ms/step - loss: 6.8561e-04 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - lr: 5.0000e-04\nEpoch 12/1000\n1/1 [==============================] - 0s 381ms/step - loss: 7.2360e-04 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - lr: 5.0000e-04\nEpoch 13/1000\n1/1 [==============================] - ETA: 0s - loss: 4.2742e-04 - accuracy: 1.0000Restoring model weights from the end of the best epoch: 5.\n\nEpoch 13: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n1/1 [==============================] - 1s 620ms/step - loss: 4.2742e-04 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - lr: 5.0000e-04\nEpoch 13: early stopping"
  },
  {
    "objectID": "posts/image/2021-02-08-08. PretrainedModel_and_Tuning.html#result",
    "href": "posts/image/2021-02-08-08. PretrainedModel_and_Tuning.html#result",
    "title": "07. pretrained Model (2)",
    "section": "",
    "text": "model.evaluate(test_x, test_y) ## [loss, accuracy]\n\n1/1 [==============================] - 1s 1s/step - loss: 0.0000e+00 - accuracy: 1.0000\n\n\n[0.0, 1.0]\n\n\n\ny_pred = model.predict(test_x)\ny_pred\n\n1/1 [==============================] - 1s 1s/step\n\n\narray([[2.1487143e-30, 4.1730422e-24, 1.0000000e+00],\n       [5.7259425e-10, 8.6654088e-09, 1.0000000e+00],\n       [8.9091756e-35, 1.0757881e-26, 1.0000000e+00],\n       [4.2603377e-15, 1.1493484e-10, 1.0000000e+00]], dtype=float32)\n\n\n\nto_names = { v:k for k,v in names.items() }\n\n\nfor i in range(len(test_x)) :\n    print('------------------------------------------------------')\n    print(f'실제 정답 : {to_names[test_y[i].argmax()]} vs 모델의 예측 : {to_names[y_pred[i].argmax()]} ')\n    prob = ''\n\n    for j in to_names :\n        string = f'{to_names[j]} : {y_pred[i][j]*100:.2f}%  '\n        prob = prob + string\n    print(prob)\n    plt.imshow(test_xv[i].reshape([299,299,3])/255)\n    plt.show()\n\n------------------------------------------------------\n실제 정답 : bleach vs 모델의 예측 : bleach \nopm : 0.00%  armstrong : 0.00%  bleach : 100.00%  \n------------------------------------------------------\n실제 정답 : bleach vs 모델의 예측 : bleach \nopm : 0.00%  armstrong : 0.00%  bleach : 100.00%  \n------------------------------------------------------\n실제 정답 : bleach vs 모델의 예측 : bleach \nopm : 0.00%  armstrong : 0.00%  bleach : 100.00%  \n------------------------------------------------------\n실제 정답 : bleach vs 모델의 예측 : bleach \nopm : 0.00%  armstrong : 0.00%  bleach : 100.00%"
  }
]